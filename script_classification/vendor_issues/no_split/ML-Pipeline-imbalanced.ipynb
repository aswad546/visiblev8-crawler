{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2229 scripts from database\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Database Connection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import psycopg2\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database connection\n",
    "def load_data():\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=5434,\n",
    "        database=\"vv8_backend\",\n",
    "        user=\"vv8\",\n",
    "        password=\"vv8\"\n",
    "    )\n",
    "    \n",
    "    query = \"SELECT * FROM multicore_static_info_known_companies\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Loaded {len(df)} scripts from database\")\n",
    "    return df\n",
    "\n",
    "df = load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove negative labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "Total scripts: 2229\n",
      "Positive scripts: 232\n",
      "Negative scripts: 1997\n",
      "Unique vendors in positives: 18\n",
      "Null vendors in negatives: 1997\n",
      "\n",
      "Vendor Distribution (Positive Scripts Only):\n",
      "vendor\n",
      "Iovation      81\n",
      "Forter        53\n",
      "Human         27\n",
      "BioCatch      21\n",
      "Behaviosec     9\n",
      "Yofi           8\n",
      "Sardine        6\n",
      "Nudata         6\n",
      "PingOne        5\n",
      "Cheq           4\n",
      "Accertify      3\n",
      "Feedzai        2\n",
      "Transmit       2\n",
      "Datadome       1\n",
      "Callsign       1\n",
      "Threatmark     1\n",
      "GroupIB        1\n",
      "Utarget        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Vendor Categories:\n",
      "High volume (>20 scripts): 4 vendors\n",
      "  - ['Iovation', 'Forter', 'Human', 'BioCatch']\n",
      "Medium volume (5-20 scripts): 5 vendors\n",
      "  - ['Behaviosec', 'Yofi', 'Sardine', 'Nudata', 'PingOne']\n",
      "Low volume (<5 scripts): 9 vendors\n",
      "  - ['Cheq', 'Accertify', 'Feedzai', 'Transmit', 'Datadome', 'Callsign', 'Threatmark', 'GroupIB', 'Utarget']\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Analyze Vendor Distribution (Positives Only)\n",
    "# Filter positive scripts to analyze vendor distribution\n",
    "df.loc[df['label'] == -1, 'label'] = 0\n",
    "positive_df = df[df['label'] == 1].copy()\n",
    "negative_df = df[df['label'] == 0].copy()\n",
    "\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Total scripts: {len(df)}\")\n",
    "print(f\"Positive scripts: {len(positive_df)}\")\n",
    "print(f\"Negative scripts: {len(negative_df)}\")\n",
    "print(f\"Unique vendors in positives: {positive_df['vendor'].nunique()}\")\n",
    "print(f\"Null vendors in negatives: {negative_df['vendor'].isnull().sum()}\")\n",
    "\n",
    "# Vendor distribution analysis (positives only)\n",
    "vendor_counts = positive_df['vendor'].value_counts()\n",
    "print(f\"\\nVendor Distribution (Positive Scripts Only):\")\n",
    "print(vendor_counts)\n",
    "\n",
    "# Categorize vendors by frequency\n",
    "high_volume_vendors = vendor_counts[vendor_counts > 20].index.tolist()\n",
    "medium_volume_vendors = vendor_counts[(vendor_counts >= 5) & (vendor_counts <= 20)].index.tolist()\n",
    "low_volume_vendors = vendor_counts[vendor_counts < 5].index.tolist()\n",
    "\n",
    "print(f\"\\nVendor Categories:\")\n",
    "print(f\"High volume (>20 scripts): {len(high_volume_vendors)} vendors\")\n",
    "print(f\"  - {high_volume_vendors}\")\n",
    "print(f\"Medium volume (5-20 scripts): {len(medium_volume_vendors)} vendors\") \n",
    "print(f\"  - {medium_volume_vendors}\")\n",
    "print(f\"Low volume (<5 scripts): {len(low_volume_vendors)} vendors\")\n",
    "print(f\"  - {low_volume_vendors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vendor-agnostic features (fixed version)...\n",
      "Created 25 vendor-agnostic features for 2229 scripts\n",
      "\n",
      "Feature variance check:\n",
      "behavioral_focus_ratio: mean=0.504, var=0.035, unique=94\n",
      "fp_focus_ratio: mean=0.496, var=0.035, unique=94\n",
      "interaction_diversity: mean=4.194, var=2.677, unique=7\n",
      "has_multi_input_types: mean=0.737, var=0.195, unique=2\n",
      "tracks_coordinates: mean=0.974, var=0.025, unique=2\n",
      "tracks_timing: mean=0.741, var=0.193, unique=2\n",
      "tracks_device_motion: mean=0.470, var=0.250, unique=2\n",
      "sophistication_score: mean=2.185, var=0.671, unique=4\n",
      "uses_navigator_fp: mean=0.996, var=0.004, unique=2\n",
      "uses_screen_fp: mean=0.987, var=0.013, unique=2\n",
      "\n",
      "Positive vs Negative comparison:\n",
      "Feature | Pos_Mean | Neg_Mean | Difference\n",
      "--------------------------------------------------\n",
      "behavioral_focus_rat |    0.504 |    0.622 |     -0.118\n",
      "fp_focus_ratio       |    0.496 |    0.378 |      0.118\n",
      "interaction_diversit |    4.194 |    2.083 |      2.111\n",
      "has_multi_input_type |    0.737 |    0.295 |      0.442\n",
      "tracks_coordinates   |    0.974 |    0.261 |      0.713\n",
      "tracks_timing        |    0.741 |    0.287 |      0.454\n",
      "tracks_device_motion |    0.470 |    0.043 |      0.427\n",
      "sophistication_score |    2.185 |    0.591 |      1.594\n",
      "uses_navigator_fp    |    0.996 |    0.716 |      0.280\n",
      "uses_screen_fp       |    0.987 |    0.300 |      0.687\n"
     ]
    }
   ],
   "source": [
    "# Fixed Cell: Proper handling of pandas arrays in pd.isna()\n",
    "def create_working_vendor_agnostic_features(df):\n",
    "    \"\"\"\n",
    "    Create vendor-agnostic features with proper handling of pandas list fields\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    \n",
    "    def is_null_or_empty(value):\n",
    "        \"\"\"Properly check if a value is null/empty, handling pandas arrays\"\"\"\n",
    "        if value is None:\n",
    "            return True\n",
    "        try:\n",
    "            # For pandas arrays, check if all elements are null\n",
    "            if hasattr(value, '__len__') and not isinstance(value, (str, dict)):\n",
    "                if len(value) == 0:\n",
    "                    return True\n",
    "                # Check if it's a pandas null check result array\n",
    "                if hasattr(value, 'dtype') and 'bool' in str(value.dtype):\n",
    "                    return False  # It's a boolean array from pd.isna(), so original value exists\n",
    "                return False\n",
    "            return pd.isna(value)\n",
    "        except:\n",
    "            return value is None\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            features = {}\n",
    "            \n",
    "            # Safe extraction without pd.isna() on lists\n",
    "            behavioral_access = row['behavioral_apis_access_count'] if row['behavioral_apis_access_count'] is not None else {}\n",
    "            fp_access = row['fingerprinting_api_access_count'] if row['fingerprinting_api_access_count'] is not None else {}\n",
    "            behavioral_sources = row['behavioral_source_apis'] if row['behavioral_source_apis'] is not None else []\n",
    "            fp_sources = row['fingerprinting_source_apis'] if row['fingerprinting_source_apis'] is not None else []\n",
    "            sink_data = row['apis_going_to_sink'] if row['apis_going_to_sink'] is not None else {}\n",
    "            \n",
    "            # === VENDOR-AGNOSTIC BEHAVIORAL PATTERNS ===\n",
    "            \n",
    "            # 1. RELATIVE COMPLEXITY\n",
    "            total_behavioral = len(behavioral_sources) if behavioral_sources is not None else 0\n",
    "            total_fp = len(fp_sources) if fp_sources is not None else 0\n",
    "            total_apis = total_behavioral + total_fp\n",
    "            \n",
    "            if total_apis > 0:\n",
    "                features['behavioral_focus_ratio'] = total_behavioral / total_apis\n",
    "                features['fp_focus_ratio'] = total_fp / total_apis\n",
    "            else:\n",
    "                features['behavioral_focus_ratio'] = 0\n",
    "                features['fp_focus_ratio'] = 0\n",
    "            \n",
    "            # 2. INTERACTION PATTERN DIVERSITY\n",
    "            event_types = set()\n",
    "            if behavioral_sources is not None:\n",
    "                for api in behavioral_sources:\n",
    "                    api_str = str(api)\n",
    "                    if 'MouseEvent' in api_str:\n",
    "                        event_types.add('mouse')\n",
    "                    elif 'KeyboardEvent' in api_str:\n",
    "                        event_types.add('keyboard')\n",
    "                    elif 'TouchEvent' in api_str or 'Touch.' in api_str:\n",
    "                        event_types.add('touch')\n",
    "                    elif 'PointerEvent' in api_str:\n",
    "                        event_types.add('pointer')\n",
    "                    elif 'DeviceMotion' in api_str or 'DeviceOrientation' in api_str:\n",
    "                        event_types.add('device')\n",
    "                    elif 'WheelEvent' in api_str:\n",
    "                        event_types.add('wheel')\n",
    "                    elif 'FocusEvent' in api_str:\n",
    "                        event_types.add('focus')\n",
    "            \n",
    "            features['interaction_diversity'] = len(event_types)\n",
    "            features['has_multi_input_types'] = int(len(event_types) >= 3)\n",
    "            \n",
    "            # 3. SOPHISTICATION PATTERNS\n",
    "            coordinate_apis = 0\n",
    "            timing_apis = 0\n",
    "            device_apis = 0\n",
    "            \n",
    "            if behavioral_sources is not None:\n",
    "                for api in behavioral_sources:\n",
    "                    api_str = str(api)\n",
    "                    if any(coord in api_str for coord in ['clientX', 'clientY', 'screenX', 'screenY', 'pageX', 'pageY']):\n",
    "                        coordinate_apis += 1\n",
    "                    if any(timing in api_str for timing in ['timeStamp', 'interval']):\n",
    "                        timing_apis += 1\n",
    "                    if 'DeviceMotion' in api_str or 'DeviceOrientation' in api_str:\n",
    "                        device_apis += 1\n",
    "            \n",
    "            features['tracks_coordinates'] = int(coordinate_apis > 0)\n",
    "            features['tracks_timing'] = int(timing_apis > 0)\n",
    "            features['tracks_device_motion'] = int(device_apis > 0)\n",
    "            features['sophistication_score'] = features['tracks_coordinates'] + features['tracks_timing'] + features['tracks_device_motion']\n",
    "            \n",
    "            # 4. FINGERPRINTING CATEGORIES\n",
    "            navigator_apis = 0\n",
    "            screen_apis = 0\n",
    "            canvas_apis = 0\n",
    "            audio_apis = 0\n",
    "            \n",
    "            if fp_sources is not None:\n",
    "                for api in fp_sources:\n",
    "                    api_str = str(api)\n",
    "                    if 'Navigator.' in api_str:\n",
    "                        navigator_apis += 1\n",
    "                    if 'Screen.' in api_str:\n",
    "                        screen_apis += 1\n",
    "                    if 'Canvas' in api_str or 'WebGL' in api_str:\n",
    "                        canvas_apis += 1\n",
    "                    if 'Audio' in api_str:\n",
    "                        audio_apis += 1\n",
    "            \n",
    "            features['uses_navigator_fp'] = int(navigator_apis > 0)\n",
    "            features['uses_screen_fp'] = int(screen_apis > 0)\n",
    "            features['uses_canvas_fp'] = int(canvas_apis > 0)\n",
    "            features['uses_audio_fp'] = int(audio_apis > 0)\n",
    "            features['fp_approach_diversity'] = features['uses_navigator_fp'] + features['uses_screen_fp'] + features['uses_canvas_fp'] + features['uses_audio_fp']\n",
    "            \n",
    "            # 5. ACCESS INTENSITY\n",
    "            total_behavioral_accesses = sum(behavioral_access.values()) if behavioral_access else 0\n",
    "            total_fp_accesses = sum(fp_access.values()) if fp_access else 0\n",
    "            total_accesses = total_behavioral_accesses + total_fp_accesses\n",
    "            \n",
    "            features['collection_intensity'] = total_accesses / max(total_apis, 1)\n",
    "            features['behavioral_access_ratio'] = total_behavioral_accesses / max(total_accesses, 1) if total_accesses > 0 else 0\n",
    "            \n",
    "            # 6. DATA FLOW PATTERNS\n",
    "            features['has_data_collection'] = int(len(sink_data) > 0) if sink_data else 0\n",
    "            features['collection_method_diversity'] = len(sink_data) if sink_data else 0\n",
    "            \n",
    "            # 7. BINARY TRACKING CAPABILITIES\n",
    "            features['tracks_mouse'] = int(any('MouseEvent' in str(api) for api in behavioral_sources)) if behavioral_sources else 0\n",
    "            features['tracks_keyboard'] = int(any('KeyboardEvent' in str(api) for api in behavioral_sources)) if behavioral_sources else 0\n",
    "            features['tracks_touch'] = int(any('TouchEvent' in str(api) or 'Touch.' in str(api) for api in behavioral_sources)) if behavioral_sources else 0\n",
    "            features['tracks_pointer'] = int(any('PointerEvent' in str(api) for api in behavioral_sources)) if behavioral_sources else 0\n",
    "            # features['performs_fingerprinting'] = int(len(fp_sources) > 0) if fp_sources else 0 # Has no varaince pointless feature\n",
    "            \n",
    "            # 8. COMPLEXITY CLASSIFICATION\n",
    "            if total_apis == 0:\n",
    "                features['complexity_tier'] = 0\n",
    "            elif total_apis <= 5:\n",
    "                features['complexity_tier'] = 1\n",
    "            elif total_apis <= 15:\n",
    "                features['complexity_tier'] = 2\n",
    "            else:\n",
    "                features['complexity_tier'] = 3\n",
    "            \n",
    "            # 9. BALANCE METRICS\n",
    "            features['is_behavioral_heavy'] = int(total_behavioral > total_fp and total_behavioral > 5)\n",
    "            features['is_fp_heavy'] = int(total_fp > total_behavioral and total_fp > 5)\n",
    "            features['is_balanced_tracker'] = int(abs(total_behavioral - total_fp) <= 3 and total_apis > 5)\n",
    "            \n",
    "            # Store metadata (these are simple types, no array issues)\n",
    "            features['script_id'] = int(row['script_id'])\n",
    "            features['label'] = int(row['label'])\n",
    "            features['vendor'] = row['vendor'] if row['vendor'] is not None else 'negative'\n",
    "            \n",
    "            features_list.append(features)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing script {row.get('script_id', 'unknown')}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "# Create the working features\n",
    "print(\"Creating vendor-agnostic features (fixed version)...\")\n",
    "agnostic_features_df = create_working_vendor_agnostic_features(df)\n",
    "feature_cols = [col for col in agnostic_features_df.columns if col not in ['script_id', 'label', 'vendor']]\n",
    "print(f\"Created {len(feature_cols)} vendor-agnostic features for {len(agnostic_features_df)} scripts\")\n",
    "\n",
    "# Check variance and distributions\n",
    "print(f\"\\nFeature variance check:\")\n",
    "positive_samples = agnostic_features_df[agnostic_features_df['label'] == 1]\n",
    "for col in feature_cols[:10]:\n",
    "    if len(positive_samples) > 0:\n",
    "        variance = positive_samples[col].var()\n",
    "        unique_vals = positive_samples[col].nunique()\n",
    "        mean_val = positive_samples[col].mean()\n",
    "        print(f\"{col}: mean={mean_val:.3f}, var={variance:.3f}, unique={unique_vals}\")\n",
    "\n",
    "# Compare positive vs negative\n",
    "print(f\"\\nPositive vs Negative comparison:\")\n",
    "neg_samples = agnostic_features_df[agnostic_features_df['label'] == 0]\n",
    "print(\"Feature | Pos_Mean | Neg_Mean | Difference\")\n",
    "print(\"-\" * 50)\n",
    "for col in feature_cols[:10]:\n",
    "    if len(positive_samples) > 0 and len(neg_samples) > 0:\n",
    "        pos_mean = positive_samples[col].mean()\n",
    "        neg_mean = neg_samples[col].mean()\n",
    "        diff = pos_mean - neg_mean\n",
    "        print(f\"{col[:20]:20} | {pos_mean:8.3f} | {neg_mean:8.3f} | {diff:10.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simple feature selection...\n",
      "🔍 SIMPLE FEATURE SELECTION\n",
      "========================================\n",
      "Starting features: 25\n",
      "\n",
      "🔧 Step 1: Variance Filter\n",
      "   Removed 0 low variance features\n",
      "   Remaining: 25\n",
      "\n",
      "🔧 Step 2: Statistical Significance\n",
      "   Selected top 17 by F-test\n",
      "\n",
      "🔧 Step 3: Random Forest Importance\n",
      "   Selected top 12 by RF importance\n",
      "   Final features: ['fp_approach_diversity', 'collection_intensity', 'sophistication_score', 'uses_canvas_fp', 'uses_audio_fp', 'collection_method_diversity', 'interaction_diversity', 'tracks_device_motion', 'tracks_coordinates', 'tracks_timing', 'complexity_tier', 'uses_screen_fp']\n",
      "\n",
      "🔧 Step 4: Validation\n",
      "   Original features (25): 0.9966\n",
      "   Selected features (12): 0.9951\n",
      "   Difference: -0.0015\n",
      "   ✅ Feature selection successful!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 SELECTED FEATURES FOR MODELING:\n",
      " 1. fp_approach_diversity     (importance: 0.1922)\n",
      " 2. collection_intensity      (importance: 0.1519)\n",
      " 3. sophistication_score      (importance: 0.1326)\n",
      " 4. uses_canvas_fp            (importance: 0.1114)\n",
      " 5. uses_audio_fp             (importance: 0.0918)\n",
      " 6. collection_method_diversity (importance: 0.0596)\n",
      " 7. interaction_diversity     (importance: 0.0482)\n",
      " 8. tracks_device_motion      (importance: 0.0465)\n",
      " 9. tracks_coordinates        (importance: 0.0406)\n",
      "10. tracks_timing             (importance: 0.0349)\n",
      "11. complexity_tier           (importance: 0.0219)\n",
      "12. uses_screen_fp            (importance: 0.0196)\n",
      "\n",
      "✅ Feature selection complete!\n",
      "Reduced from 25 to 12 features\n"
     ]
    }
   ],
   "source": [
    "# Cell: Simple Feature Selection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simple_feature_selection(features_df, target_col='label', \n",
    "                           metadata_cols=['script_id', 'label', 'vendor'],\n",
    "                           max_features=15, random_state=42):\n",
    "    \"\"\"\n",
    "    Simple 3-step feature selection: Variance -> Statistical -> Importance\n",
    "    \"\"\"\n",
    "    print(\"🔍 SIMPLE FEATURE SELECTION\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Prepare data\n",
    "    feature_cols = [col for col in features_df.columns if col not in metadata_cols]\n",
    "    X = features_df[feature_cols].copy()\n",
    "    y = features_df[target_col].copy()\n",
    "    \n",
    "    print(f\"Starting features: {len(feature_cols)}\")\n",
    "    \n",
    "    # STEP 1: Remove low variance features\n",
    "    print(f\"\\n🔧 Step 1: Variance Filter\")\n",
    "    variance_selector = VarianceThreshold(threshold=0.01)\n",
    "    X_var = variance_selector.fit_transform(X)\n",
    "    features_after_variance = X.columns[variance_selector.get_support()].tolist()\n",
    "    \n",
    "    removed_variance = len(feature_cols) - len(features_after_variance)\n",
    "    print(f\"   Removed {removed_variance} low variance features\")\n",
    "    print(f\"   Remaining: {len(features_after_variance)}\")\n",
    "    \n",
    "    X = X[features_after_variance]\n",
    "    \n",
    "    # STEP 2: Statistical significance (F-test)\n",
    "    print(f\"\\n🔧 Step 2: Statistical Significance\")\n",
    "    k_best = min(max_features + 5, len(features_after_variance))  # Select a few extra\n",
    "    stat_selector = SelectKBest(score_func=f_classif, k=k_best)\n",
    "    X_stat = stat_selector.fit_transform(X, y)\n",
    "    features_after_stats = X.columns[stat_selector.get_support()].tolist()\n",
    "    \n",
    "    print(f\"   Selected top {len(features_after_stats)} by F-test\")\n",
    "    \n",
    "    X = X[features_after_stats]\n",
    "    \n",
    "    # STEP 3: Random Forest Importance\n",
    "    print(f\"\\n🔧 Step 3: Random Forest Importance\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=random_state, n_jobs=-1)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = rf.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Select top features by importance\n",
    "    final_features = feature_importance_df.head(max_features)['feature'].tolist()\n",
    "    \n",
    "    print(f\"   Selected top {len(final_features)} by RF importance\")\n",
    "    print(f\"   Final features: {final_features}\")\n",
    "    \n",
    "    # STEP 4: Quick validation\n",
    "    print(f\"\\n🔧 Step 4: Validation\")\n",
    "    X_original = features_df[feature_cols]\n",
    "    X_selected = features_df[final_features]\n",
    "    \n",
    "    # Compare performance\n",
    "    rf_validator = RandomForestClassifier(n_estimators=50, random_state=random_state)\n",
    "    \n",
    "    score_original = cross_val_score(rf_validator, X_original, y, cv=3, scoring='roc_auc').mean()\n",
    "    score_selected = cross_val_score(rf_validator, X_selected, y, cv=3, scoring='roc_auc').mean()\n",
    "    \n",
    "    print(f\"   Original features ({len(feature_cols)}): {score_original:.4f}\")\n",
    "    print(f\"   Selected features ({len(final_features)}): {score_selected:.4f}\")\n",
    "    print(f\"   Difference: {score_selected - score_original:+.4f}\")\n",
    "    \n",
    "    if score_selected >= score_original - 0.02:\n",
    "        print(f\"   ✅ Feature selection successful!\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  Performance dropped significantly\")\n",
    "    \n",
    "    return final_features, feature_importance_df\n",
    "\n",
    "def plot_feature_importance(feature_importance_df, top_n=15):\n",
    "    \"\"\"Simple visualization of feature importance\"\"\"\n",
    "    top_features = feature_importance_df.head(top_n)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(top_features)), top_features['importance'], alpha=0.7)\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Random Forest Importance')\n",
    "    plt.title(f'Top {top_n} Features by Importance')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run simple feature selection\n",
    "print(\"Running simple feature selection...\")\n",
    "\n",
    "# Use binary dataset\n",
    "if 'binary_df' in globals():\n",
    "    df_for_selection = binary_df.reset_index(drop=True)\n",
    "else:\n",
    "    df_for_selection = agnostic_features_df[agnostic_features_df['label'].isin([0, 1])].copy().reset_index(drop=True)\n",
    "\n",
    "# Select features\n",
    "selected_features, importance_df = simple_feature_selection(\n",
    "    df_for_selection,\n",
    "    target_col='label',\n",
    "    max_features=12,  # Adjust this number as needed\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "plot_feature_importance(importance_df, top_n=15)\n",
    "\n",
    "# Update feature list for modeling\n",
    "feature_cols_selected = selected_features\n",
    "\n",
    "print(f\"\\n🎯 SELECTED FEATURES FOR MODELING:\")\n",
    "for i, feature in enumerate(selected_features, 1):\n",
    "    importance = importance_df[importance_df['feature'] == feature]['importance'].iloc[0]\n",
    "    print(f\"{i:2d}. {feature:<25} (importance: {importance:.4f})\")\n",
    "\n",
    "print(f\"\\n✅ Feature selection complete!\")\n",
    "print(f\"Reduced from {len([col for col in df_for_selection.columns if col not in ['script_id', 'label', 'vendor']])} to {len(selected_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Test Vendor Correlation of New Features\n",
    "def test_vendor_agnostic_correlation(features_df, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Rigorously test if features are truly vendor-agnostic\n",
    "    \"\"\"\n",
    "    print(\"=== TESTING VENDOR CORRELATION OF NEW FEATURES ===\")\n",
    "    \n",
    "    # Only analyze positive samples (with vendor info)\n",
    "    positive_features = features_df[features_df['label'] == 1].copy()\n",
    "    \n",
    "    # Get our new feature columns\n",
    "    feature_cols = [col for col in features_df.columns if col not in ['script_id', 'label', 'vendor']]\n",
    "    \n",
    "    # One-hot encode vendors for correlation analysis\n",
    "    vendor_dummies = pd.get_dummies(positive_features['vendor'], prefix='vendor')\n",
    "    \n",
    "    print(f\"Testing {len(feature_cols)} features against {len(vendor_dummies.columns)} vendors\")\n",
    "    print(f\"Correlation threshold: {threshold}\")\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations_matrix = []\n",
    "    feature_vendor_pairs = []\n",
    "    \n",
    "    for feature in feature_cols:\n",
    "        feature_correlations = []\n",
    "        max_correlation = 0\n",
    "        max_vendor = \"\"\n",
    "        \n",
    "        for vendor_col in vendor_dummies.columns:\n",
    "            vendor_name = vendor_col.replace('vendor_', '')\n",
    "            \n",
    "            # Calculate correlation\n",
    "            corr = positive_features[feature].corr(vendor_dummies[vendor_col])\n",
    "            if not np.isnan(corr):\n",
    "                feature_correlations.append(abs(corr))\n",
    "                if abs(corr) > max_correlation:\n",
    "                    max_correlation = abs(corr)\n",
    "                    max_vendor = vendor_name\n",
    "            else:\n",
    "                feature_correlations.append(0)\n",
    "        \n",
    "        correlations_matrix.append(feature_correlations)\n",
    "        feature_vendor_pairs.append({\n",
    "            'feature': feature,\n",
    "            'max_correlation': max_correlation,\n",
    "            'worst_vendor': max_vendor,\n",
    "            'avg_correlation': np.mean(feature_correlations),\n",
    "            'is_vendor_agnostic': max_correlation < threshold\n",
    "        })\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(feature_vendor_pairs).sort_values('max_correlation', ascending=False)\n",
    "    \n",
    "    # Summary statistics\n",
    "    truly_agnostic = results_df[results_df['is_vendor_agnostic'] == True]\n",
    "    vendor_specific = results_df[results_df['is_vendor_agnostic'] == False]\n",
    "    \n",
    "    print(f\"\\n=== CORRELATION ANALYSIS RESULTS ===\")\n",
    "    print(f\"Features with max correlation < {threshold}: {len(truly_agnostic)}/{len(results_df)} ({len(truly_agnostic)/len(results_df)*100:.1f}%)\")\n",
    "    print(f\"Features with max correlation >= {threshold}: {len(vendor_specific)}/{len(results_df)} ({len(vendor_specific)/len(results_df)*100:.1f}%)\")\n",
    "    \n",
    "    if len(vendor_specific) > 0:\n",
    "        print(f\"\\n⚠️  VENDOR-SPECIFIC FEATURES (correlation >= {threshold}):\")\n",
    "        for _, row in vendor_specific.iterrows():\n",
    "            print(f\"   {row['feature']}: {row['max_correlation']:.3f} (worst: {row['worst_vendor']})\")\n",
    "    \n",
    "    if len(truly_agnostic) > 0:\n",
    "        print(f\"\\n✅ TRULY VENDOR-AGNOSTIC FEATURES (correlation < {threshold}):\")\n",
    "        for _, row in truly_agnostic.head(10).iterrows():\n",
    "            print(f\"   {row['feature']}: {row['max_correlation']:.3f} (avg: {row['avg_correlation']:.3f})\")\n",
    "    \n",
    "    return results_df, correlations_matrix, vendor_dummies.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Vendor-Aware Split (Positives Only)\n",
    "def create_vendor_aware_split(features_df, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Create train/test split where:\n",
    "    - Negatives are split randomly\n",
    "    - Positives are split with vendor awareness to prevent leakage\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Separate positives and negatives\n",
    "    positives = features_df[features_df['label'] == 1].copy()\n",
    "    negatives = features_df[features_df['label'] == 0].copy()\n",
    "    \n",
    "    print(f\"Splitting {len(positives)} positives and {len(negatives)} negatives...\")\n",
    "    \n",
    "    # Analyze positive vendor distribution\n",
    "    vendor_counts = positives['vendor'].value_counts()\n",
    "    high_volume_vendors = vendor_counts[vendor_counts > 20].index.tolist()\n",
    "    medium_volume_vendors = vendor_counts[(vendor_counts >= 5) & (vendor_counts <= 20)].index.tolist()\n",
    "    low_volume_vendors = vendor_counts[vendor_counts < 5].index.tolist()\n",
    "    \n",
    "    train_pos_indices = []\n",
    "    test_pos_indices = []\n",
    "    \n",
    "    # High volume vendors: Split scripts within vendor (70-30)\n",
    "    for vendor in high_volume_vendors:\n",
    "        vendor_scripts = positives[positives['vendor'] == vendor].index.tolist()\n",
    "        np.random.shuffle(vendor_scripts)\n",
    "        \n",
    "        n_test = max(1, int(len(vendor_scripts) * test_size))\n",
    "        test_pos_indices.extend(vendor_scripts[:n_test])\n",
    "        train_pos_indices.extend(vendor_scripts[n_test:])\n",
    "        \n",
    "        print(f\"High volume vendor '{vendor}': {len(vendor_scripts)} scripts -> {len(vendor_scripts)-n_test} train, {n_test} test\")\n",
    "    \n",
    "    # Medium volume vendors: 60% vendors to train, 40% vendors to test\n",
    "    np.random.shuffle(medium_volume_vendors)\n",
    "    n_train_vendors = max(1, int(len(medium_volume_vendors) * 0.6))\n",
    "    \n",
    "    train_medium_vendors = medium_volume_vendors[:n_train_vendors]\n",
    "    test_medium_vendors = medium_volume_vendors[n_train_vendors:]\n",
    "    \n",
    "    for vendor in train_medium_vendors:\n",
    "        vendor_scripts = positives[positives['vendor'] == vendor].index.tolist()\n",
    "        train_pos_indices.extend(vendor_scripts)\n",
    "        print(f\"Medium volume vendor '{vendor}': {len(vendor_scripts)} scripts -> all to train\")\n",
    "    \n",
    "    for vendor in test_medium_vendors:\n",
    "        vendor_scripts = positives[positives['vendor'] == vendor].index.tolist()\n",
    "        test_pos_indices.extend(vendor_scripts)\n",
    "        print(f\"Medium volume vendor '{vendor}': {len(vendor_scripts)} scripts -> all to test\")\n",
    "    \n",
    "    # Low volume vendors: 50% to train, 50% to test (by vendor)\n",
    "    np.random.shuffle(low_volume_vendors)\n",
    "    n_test_low_vendors = len(low_volume_vendors) // 2\n",
    "    \n",
    "    train_low_vendors = low_volume_vendors[n_test_low_vendors:]\n",
    "    test_low_vendors = low_volume_vendors[:n_test_low_vendors]\n",
    "    \n",
    "    for vendor in train_low_vendors:\n",
    "        vendor_scripts = positives[positives['vendor'] == vendor].index.tolist()\n",
    "        train_pos_indices.extend(vendor_scripts)\n",
    "        print(f\"Low volume vendor '{vendor}': {len(vendor_scripts)} scripts -> all to train\")\n",
    "    \n",
    "    for vendor in test_low_vendors:\n",
    "        vendor_scripts = positives[positives['vendor'] == vendor].index.tolist()\n",
    "        test_pos_indices.extend(vendor_scripts)\n",
    "        print(f\"Low volume vendor '{vendor}': {len(vendor_scripts)} scripts -> all to test\")\n",
    "    \n",
    "    # Split negatives randomly\n",
    "    neg_indices = negatives.index.tolist()\n",
    "    np.random.shuffle(neg_indices)\n",
    "    n_test_neg = int(len(neg_indices) * test_size)\n",
    "    \n",
    "    train_neg_indices = neg_indices[n_test_neg:]\n",
    "    test_neg_indices = neg_indices[:n_test_neg]\n",
    "    \n",
    "    # Combine indices\n",
    "    train_indices = train_pos_indices + train_neg_indices\n",
    "    test_indices = test_pos_indices + test_neg_indices\n",
    "    \n",
    "    print(f\"\\nFinal split:\")\n",
    "    print(f\"Train: {len(train_pos_indices)} positives + {len(train_neg_indices)} negatives = {len(train_indices)} total\")\n",
    "    print(f\"Test: {len(test_pos_indices)} positives + {len(test_neg_indices)} negatives = {len(test_indices)} total\")\n",
    "    \n",
    "    return train_indices, test_indices, {\n",
    "        'train_vendors': {\n",
    "            'high_volume_partial': high_volume_vendors,\n",
    "            'medium_volume': train_medium_vendors,\n",
    "            'low_volume': train_low_vendors\n",
    "        },\n",
    "        'test_vendors': {\n",
    "            'high_volume_partial': high_volume_vendors,  # Same vendors, different scripts\n",
    "            'medium_volume': test_medium_vendors,\n",
    "            'low_volume': test_low_vendors\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Create Vendor Weights and Train Model\n",
    "def create_vendor_weights(features_df, train_idx):\n",
    "    \"\"\"Create inverse frequency weights for positive vendors only\"\"\"\n",
    "    train_df = features_df.loc[train_idx]\n",
    "    train_positives = train_df[train_df['label'] == 1]\n",
    "    \n",
    "    if len(train_positives) == 0:\n",
    "        return np.ones(len(train_idx))\n",
    "    \n",
    "    vendor_counts = train_positives['vendor'].value_counts()\n",
    "    \n",
    "    # Inverse square root for gentler weighting\n",
    "    vendor_weights = 1 / np.sqrt(vendor_counts)\n",
    "    vendor_weights = vendor_weights / vendor_weights.sum() * len(vendor_weights)\n",
    "    \n",
    "    print(\"Vendor weights for positive scripts:\")\n",
    "    for vendor, weight in vendor_weights.items():\n",
    "        count = vendor_counts[vendor]\n",
    "        print(f\"  {vendor}: {weight:.3f} (count: {count})\")\n",
    "    \n",
    "    # Create sample weights\n",
    "    sample_weights = np.ones(len(train_idx))\n",
    "    \n",
    "    for i, idx in enumerate(train_idx):\n",
    "        row = features_df.loc[idx]\n",
    "        if row['label'] == 1:  # Only weight positive samples\n",
    "            vendor = row['vendor']\n",
    "            if vendor in vendor_weights:\n",
    "                sample_weights[i] = vendor_weights[vendor]\n",
    "    \n",
    "    return sample_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running vendor-aware feature selection...\n",
      "🔍 VENDOR-AWARE FEATURE SELECTION\n",
      "==================================================\n",
      "Splitting 232 positives and 1997 negatives...\n",
      "High volume vendor 'Iovation': 81 scripts -> 57 train, 24 test\n",
      "High volume vendor 'Forter': 53 scripts -> 38 train, 15 test\n",
      "High volume vendor 'Human': 27 scripts -> 19 train, 8 test\n",
      "High volume vendor 'BioCatch': 21 scripts -> 15 train, 6 test\n",
      "Medium volume vendor 'PingOne': 5 scripts -> all to train\n",
      "Medium volume vendor 'Nudata': 6 scripts -> all to train\n",
      "Medium volume vendor 'Yofi': 8 scripts -> all to train\n",
      "Medium volume vendor 'Sardine': 6 scripts -> all to test\n",
      "Medium volume vendor 'Behaviosec': 9 scripts -> all to test\n",
      "Low volume vendor 'Cheq': 4 scripts -> all to train\n",
      "Low volume vendor 'Callsign': 1 scripts -> all to train\n",
      "Low volume vendor 'Feedzai': 2 scripts -> all to train\n",
      "Low volume vendor 'Threatmark': 1 scripts -> all to train\n",
      "Low volume vendor 'GroupIB': 1 scripts -> all to train\n",
      "Low volume vendor 'Utarget': 1 scripts -> all to test\n",
      "Low volume vendor 'Accertify': 3 scripts -> all to test\n",
      "Low volume vendor 'Datadome': 1 scripts -> all to test\n",
      "Low volume vendor 'Transmit': 2 scripts -> all to test\n",
      "\n",
      "Final split:\n",
      "Train: 157 positives + 1398 negatives = 1555 total\n",
      "Test: 75 positives + 599 negatives = 674 total\n",
      "Starting features: 25\n",
      "Training set: 1555 samples\n",
      "Test set: 674 samples\n",
      "✅ Using YOUR vendor-aware train/test split!\n",
      "\n",
      "🔧 Step 1: Variance Filter (Training Data Only)\n",
      "   Removed 0 low variance features\n",
      "   Remaining: 25\n",
      "\n",
      "🔧 Step 2: Statistical Significance (Training Data Only)\n",
      "   Selected top 17 by F-test\n",
      "\n",
      "🔧 Step 3: Random Forest Importance (Training Data Only)\n",
      "   Selected top 12 by RF importance\n",
      "   Final features: ['fp_approach_diversity', 'collection_intensity', 'sophistication_score', 'uses_audio_fp', 'uses_canvas_fp', 'collection_method_diversity', 'tracks_coordinates', 'interaction_diversity', 'tracks_timing', 'tracks_device_motion', 'complexity_tier', 'is_fp_heavy']\n",
      "\n",
      "🔧 Step 4: Vendor-Aware Validation\n",
      "   Original features (17): 0.9792\n",
      "   Selected features (12): 0.9703\n",
      "   Difference: -0.0089\n",
      "\n",
      "📊 Vendor-Aware Test Set Details:\n",
      "   Test vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Datadome', 'Forter', 'Human', 'Iovation', 'Sardine', 'Transmit', 'Utarget']\n",
      "   High-volume vendors in test: 4\n",
      "   Unseen vendors in test: 6\n",
      "   ✅ Feature selection successful with vendor-aware validation!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 SELECTED FEATURES FOR MODELING:\n",
      " 1. fp_approach_diversity     (importance: 0.1974)\n",
      " 2. collection_intensity      (importance: 0.1587)\n",
      " 3. sophistication_score      (importance: 0.1280)\n",
      " 4. uses_audio_fp             (importance: 0.1206)\n",
      " 5. uses_canvas_fp            (importance: 0.1053)\n",
      " 6. collection_method_diversity (importance: 0.0508)\n",
      " 7. tracks_coordinates        (importance: 0.0451)\n",
      " 8. interaction_diversity     (importance: 0.0420)\n",
      " 9. tracks_timing             (importance: 0.0410)\n",
      "10. tracks_device_motion      (importance: 0.0284)\n",
      "11. complexity_tier           (importance: 0.0244)\n",
      "12. is_fp_heavy               (importance: 0.0154)\n",
      "\n",
      "🔄 UPDATING MAIN DATAFRAMES...\n",
      "   ✅ Updated agnostic_features_df: (2229, 15)\n",
      "   ✅ Updated feature_cols list: 12 features\n",
      "   📉 Reduced features from 25 to 12\n",
      "\n",
      "✅ Feature selection complete!\n",
      "🎯 All subsequent modeling will use 12 selected features\n",
      "📝 Selected features: ['fp_approach_diversity', 'collection_intensity', 'sophistication_score', 'uses_audio_fp', 'uses_canvas_fp', 'collection_method_diversity', 'tracks_coordinates', 'interaction_diversity', 'tracks_timing', 'tracks_device_motion', 'complexity_tier', 'is_fp_heavy']\n"
     ]
    }
   ],
   "source": [
    "# Cell: Simple Feature Selection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simple_feature_selection(features_df, target_col='label', \n",
    "                           metadata_cols=['script_id', 'label', 'vendor'],\n",
    "                           max_features=15, random_state=42, test_size=0.3):\n",
    "    \"\"\"\n",
    "    Simple 3-step feature selection: Variance -> Statistical -> Importance\n",
    "    ONLY uses training data to avoid data leakage\n",
    "    \"\"\"\n",
    "    print(\"🔍 SIMPLE FEATURE SELECTION (TRAINING DATA ONLY)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Prepare data\n",
    "    feature_cols = [col for col in features_df.columns if col not in metadata_cols]\n",
    "    X = features_df[feature_cols].copy()\n",
    "    y = features_df[target_col].copy()\n",
    "    \n",
    "    print(f\"Starting features: {len(feature_cols)}\")\n",
    "    \n",
    "    # Split data FIRST to avoid leakage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set: {len(X_train)} samples\")\n",
    "    print(f\"Test set: {len(X_test)} samples\")\n",
    "    print(\"⚠️  Feature selection uses ONLY training data!\")\n",
    "    \n",
    "    # STEP 1: Remove low variance features (training data only)\n",
    "    print(f\"\\n🔧 Step 1: Variance Filter (Training Data)\")\n",
    "    variance_selector = VarianceThreshold(threshold=0.01)\n",
    "    X_train_var = variance_selector.fit_transform(X_train)\n",
    "    features_after_variance = X_train.columns[variance_selector.get_support()].tolist()\n",
    "    \n",
    "    removed_variance = len(feature_cols) - len(features_after_variance)\n",
    "    print(f\"   Removed {removed_variance} low variance features\")\n",
    "    print(f\"   Remaining: {len(features_after_variance)}\")\n",
    "    \n",
    "    X_train = X_train[features_after_variance]\n",
    "    X_test = X_test[features_after_variance]  # Apply same selection to test\n",
    "    \n",
    "    # STEP 2: Statistical significance (F-test on training data only)\n",
    "    print(f\"\\n🔧 Step 2: Statistical Significance (Training Data)\")\n",
    "    k_best = min(max_features + 5, len(features_after_variance))\n",
    "    stat_selector = SelectKBest(score_func=f_classif, k=k_best)\n",
    "    X_train_stat = stat_selector.fit_transform(X_train, y_train)\n",
    "    features_after_stats = X_train.columns[stat_selector.get_support()].tolist()\n",
    "    \n",
    "    print(f\"   Selected top {len(features_after_stats)} by F-test\")\n",
    "    \n",
    "    X_train = X_train[features_after_stats]\n",
    "    X_test = X_test[features_after_stats]  # Apply same selection to test\n",
    "    \n",
    "    # STEP 3: Random Forest Importance (training data only)\n",
    "    print(f\"\\n🔧 Step 3: Random Forest Importance (Training Data)\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=random_state, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)  # ONLY training data!\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = rf.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Select top features by importance\n",
    "    final_features = feature_importance_df.head(max_features)['feature'].tolist()\n",
    "    \n",
    "    print(f\"   Selected top {len(final_features)} by RF importance\")\n",
    "    print(f\"   Final features: {final_features}\")\n",
    "    \n",
    "    # STEP 4: Validation on held-out test set\n",
    "    print(f\"\\n🔧 Step 4: Validation (Test Set Performance)\")\n",
    "    X_train_selected = X_train[final_features]\n",
    "    X_test_selected = X_test[final_features]\n",
    "    \n",
    "    # Compare performance on test set\n",
    "    rf_validator = RandomForestClassifier(n_estimators=50, random_state=random_state)\n",
    "    \n",
    "    # Train on training set, test on test set\n",
    "    rf_validator.fit(X_train, y_train)\n",
    "    score_original = rf_validator.score(X_test, y_test)\n",
    "    \n",
    "    rf_validator.fit(X_train_selected, y_train)\n",
    "    score_selected = rf_validator.score(X_test_selected, y_test)\n",
    "    \n",
    "    print(f\"   Original features ({len(X_train.columns)}): {score_original:.4f}\")\n",
    "    print(f\"   Selected features ({len(final_features)}): {score_selected:.4f}\")\n",
    "    print(f\"   Difference: {score_selected - score_original:+.4f}\")\n",
    "    \n",
    "    if score_selected >= score_original - 0.02:\n",
    "        print(f\"   ✅ Feature selection successful!\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  Performance dropped significantly\")\n",
    "    \n",
    "    return final_features, feature_importance_df\n",
    "\n",
    "def plot_feature_importance(feature_importance_df, top_n=15):\n",
    "    \"\"\"Simple visualization of feature importance\"\"\"\n",
    "    top_features = feature_importance_df.head(top_n)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(top_features)), top_features['importance'], alpha=0.7)\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Random Forest Importance')\n",
    "    plt.title(f'Top {top_n} Features by Importance')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def simple_feature_selection_vendor_aware(features_df, target_col='label', \n",
    "                                        metadata_cols=['script_id', 'label', 'vendor'],\n",
    "                                        max_features=15, random_state=42):\n",
    "    \"\"\"\n",
    "    Feature selection that respects vendor-aware splitting\n",
    "    Uses vendor-aware train/test split to avoid data leakage\n",
    "    \"\"\"\n",
    "    print(\"🔍 VENDOR-AWARE FEATURE SELECTION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Use your existing vendor-aware split function\n",
    "    train_idx, test_idx, split_info = create_vendor_aware_split(features_df)\n",
    "    \n",
    "    # Prepare data using YOUR splits\n",
    "    feature_cols = [col for col in features_df.columns if col not in metadata_cols]\n",
    "    \n",
    "    # Extract training and test data using your indices\n",
    "    X_train = features_df.loc[train_idx, feature_cols].copy()\n",
    "    y_train = features_df.loc[train_idx, target_col].copy()\n",
    "    X_test = features_df.loc[test_idx, feature_cols].copy()\n",
    "    y_test = features_df.loc[test_idx, target_col].copy()\n",
    "    \n",
    "    print(f\"Starting features: {len(feature_cols)}\")\n",
    "    print(f\"Training set: {len(X_train)} samples\")\n",
    "    print(f\"Test set: {len(X_test)} samples\")\n",
    "    print(\"✅ Using YOUR vendor-aware train/test split!\")\n",
    "    \n",
    "    # STEP 1: Remove low variance features (training data only)\n",
    "    print(f\"\\n🔧 Step 1: Variance Filter (Training Data Only)\")\n",
    "    variance_selector = VarianceThreshold(threshold=0.01)\n",
    "    X_train_var = variance_selector.fit_transform(X_train)\n",
    "    features_after_variance = X_train.columns[variance_selector.get_support()].tolist()\n",
    "    \n",
    "    removed_variance = len(feature_cols) - len(features_after_variance)\n",
    "    print(f\"   Removed {removed_variance} low variance features\")\n",
    "    print(f\"   Remaining: {len(features_after_variance)}\")\n",
    "    \n",
    "    X_train = X_train[features_after_variance]\n",
    "    X_test = X_test[features_after_variance]  # Apply same selection to test\n",
    "    \n",
    "    # STEP 2: Statistical significance (F-test on training data only)\n",
    "    print(f\"\\n🔧 Step 2: Statistical Significance (Training Data Only)\")\n",
    "    k_best = min(max_features + 5, len(features_after_variance))\n",
    "    stat_selector = SelectKBest(score_func=f_classif, k=k_best)\n",
    "    X_train_stat = stat_selector.fit_transform(X_train, y_train)\n",
    "    features_after_stats = X_train.columns[stat_selector.get_support()].tolist()\n",
    "    \n",
    "    print(f\"   Selected top {len(features_after_stats)} by F-test\")\n",
    "    \n",
    "    X_train = X_train[features_after_stats]\n",
    "    X_test = X_test[features_after_stats]  # Apply same selection to test\n",
    "    \n",
    "    # STEP 3: Random Forest Importance (training data only)\n",
    "    print(f\"\\n🔧 Step 3: Random Forest Importance (Training Data Only)\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=random_state, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)  # ONLY training data!\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = rf.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Select top features by importance\n",
    "    final_features = feature_importance_df.head(max_features)['feature'].tolist()\n",
    "    \n",
    "    print(f\"   Selected top {len(final_features)} by RF importance\")\n",
    "    print(f\"   Final features: {final_features}\")\n",
    "    \n",
    "    # STEP 4: Validation using vendor-aware test set\n",
    "    print(f\"\\n🔧 Step 4: Vendor-Aware Validation\")\n",
    "    X_train_selected = X_train[final_features]\n",
    "    X_test_selected = X_test[final_features]\n",
    "    \n",
    "    # Compare performance on YOUR test set\n",
    "    rf_validator = RandomForestClassifier(n_estimators=50, random_state=random_state)\n",
    "    \n",
    "    # Train on training set, test on YOUR test set\n",
    "    rf_validator.fit(X_train, y_train)\n",
    "    score_original = rf_validator.score(X_test, y_test)\n",
    "    \n",
    "    rf_validator.fit(X_train_selected, y_train)\n",
    "    score_selected = rf_validator.score(X_test_selected, y_test)\n",
    "    \n",
    "    print(f\"   Original features ({len(X_train.columns)}): {score_original:.4f}\")\n",
    "    print(f\"   Selected features ({len(final_features)}): {score_selected:.4f}\")\n",
    "    print(f\"   Difference: {score_selected - score_original:+.4f}\")\n",
    "    \n",
    "    # Show vendor-specific performance\n",
    "    test_df = features_df.loc[test_idx].copy()\n",
    "    test_positives = test_df[test_df['label'] == 1]\n",
    "    \n",
    "    print(f\"\\n📊 Vendor-Aware Test Set Details:\")\n",
    "    print(f\"   Test vendors: {sorted(test_positives['vendor'].unique())}\")\n",
    "    print(f\"   High-volume vendors in test: {len([v for v in split_info['train_vendors']['high_volume_partial']])}\")\n",
    "    print(f\"   Unseen vendors in test: {len(split_info['test_vendors']['medium_volume']) + len(split_info['test_vendors']['low_volume'])}\")\n",
    "    \n",
    "    if score_selected >= score_original - 0.02:\n",
    "        print(f\"   ✅ Feature selection successful with vendor-aware validation!\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  Performance dropped significantly\")\n",
    "    \n",
    "    return final_features, feature_importance_df\n",
    "\n",
    "# Run vendor-aware feature selection\n",
    "print(\"Running vendor-aware feature selection...\")\n",
    "\n",
    "# Use the main features DataFrame\n",
    "df_for_selection = agnostic_features_df.copy()\n",
    "\n",
    "# Select features using vendor-aware approach\n",
    "selected_features, importance_df = simple_feature_selection_vendor_aware(\n",
    "    df_for_selection,\n",
    "    target_col='label',\n",
    "    max_features=12,  # Adjust this number as needed\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "plot_feature_importance(importance_df, top_n=15)\n",
    "\n",
    "print(f\"\\n🎯 SELECTED FEATURES FOR MODELING:\")\n",
    "for i, feature in enumerate(selected_features, 1):\n",
    "    importance = importance_df[importance_df['feature'] == feature]['importance'].iloc[0]\n",
    "    print(f\"{i:2d}. {feature:<25} (importance: {importance:.4f})\")\n",
    "\n",
    "# =================================================================\n",
    "# UPDATE MAIN DATAFRAMES WITH SELECTED FEATURES\n",
    "# =================================================================\n",
    "print(f\"\\n🔄 UPDATING MAIN DATAFRAMES...\")\n",
    "\n",
    "# Keep only selected features plus metadata\n",
    "selected_columns = ['script_id', 'label', 'vendor'] + selected_features\n",
    "\n",
    "# Update main agnostic_features_df\n",
    "original_feature_count = len([col for col in agnostic_features_df.columns if col not in ['script_id', 'label', 'vendor']])\n",
    "agnostic_features_df = agnostic_features_df[selected_columns].copy()\n",
    "\n",
    "# Update binary_df if it exists\n",
    "if 'binary_df' in globals():\n",
    "    binary_df = binary_df[selected_columns].copy()\n",
    "    print(f\"   ✅ Updated binary_df: {binary_df.shape}\")\n",
    "\n",
    "# Update feature_cols list for all subsequent cells\n",
    "feature_cols = selected_features.copy()\n",
    "\n",
    "print(f\"   ✅ Updated agnostic_features_df: {agnostic_features_df.shape}\")\n",
    "print(f\"   ✅ Updated feature_cols list: {len(feature_cols)} features\")\n",
    "print(f\"   📉 Reduced features from {original_feature_count} to {len(selected_features)}\")\n",
    "\n",
    "print(f\"\\n✅ Feature selection complete!\")\n",
    "print(f\"🎯 All subsequent modeling will use {len(selected_features)} selected features\")\n",
    "print(f\"📝 Selected features: {selected_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vendor aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting 232 positives and 1997 negatives...\n",
      "High volume vendor 'Iovation': 81 scripts -> 57 train, 24 test\n",
      "High volume vendor 'Forter': 53 scripts -> 38 train, 15 test\n",
      "High volume vendor 'Human': 27 scripts -> 19 train, 8 test\n",
      "High volume vendor 'BioCatch': 21 scripts -> 15 train, 6 test\n",
      "Medium volume vendor 'PingOne': 5 scripts -> all to train\n",
      "Medium volume vendor 'Nudata': 6 scripts -> all to train\n",
      "Medium volume vendor 'Yofi': 8 scripts -> all to train\n",
      "Medium volume vendor 'Sardine': 6 scripts -> all to test\n",
      "Medium volume vendor 'Behaviosec': 9 scripts -> all to test\n",
      "Low volume vendor 'Cheq': 4 scripts -> all to train\n",
      "Low volume vendor 'Callsign': 1 scripts -> all to train\n",
      "Low volume vendor 'Feedzai': 2 scripts -> all to train\n",
      "Low volume vendor 'Threatmark': 1 scripts -> all to train\n",
      "Low volume vendor 'GroupIB': 1 scripts -> all to train\n",
      "Low volume vendor 'Utarget': 1 scripts -> all to test\n",
      "Low volume vendor 'Accertify': 3 scripts -> all to test\n",
      "Low volume vendor 'Datadome': 1 scripts -> all to test\n",
      "Low volume vendor 'Transmit': 2 scripts -> all to test\n",
      "\n",
      "Final split:\n",
      "Train: 157 positives + 1398 negatives = 1555 total\n",
      "Test: 75 positives + 599 negatives = 674 total\n",
      "Training with 12 vendor-agnostic features\n",
      "Training set: 1555 samples\n",
      "Test set: 674 samples\n",
      "\n",
      "=== NEW FEATURES PERFORMANCE ===\n",
      "Overall Accuracy: 0.969\n",
      "ROC AUC: 0.971\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       599\n",
      "           1       0.89      0.83      0.86        75\n",
      "\n",
      "    accuracy                           0.97       674\n",
      "   macro avg       0.93      0.91      0.92       674\n",
      "weighted avg       0.97      0.97      0.97       674\n",
      "\n",
      "\n",
      "=== VENDOR-SPECIFIC PERFORMANCE ===\n",
      "       vendor  accuracy  count         category\n",
      "0    Iovation      1.00     24      high (seen)\n",
      "1      Forter      1.00     15      high (seen)\n",
      "3    BioCatch      1.00      6      high (seen)\n",
      "5  Behaviosec      1.00      9  medium (unseen)\n",
      "6     Utarget      1.00      1     low (unseen)\n",
      "8    Datadome      1.00      1     low (unseen)\n",
      "2       Human      0.75      8      high (seen)\n",
      "4     Sardine      0.00      6  medium (unseen)\n",
      "7   Accertify      0.00      3     low (unseen)\n",
      "9    Transmit      0.00      2     low (unseen)\n",
      "\n",
      "=== CATEGORY PERFORMANCE ===\n",
      "                 accuracy  count\n",
      "category                        \n",
      "high (seen)         0.938     53\n",
      "low (unseen)        0.500      7\n",
      "medium (unseen)     0.500     15\n",
      "\n",
      "=== TOP 10 MOST IMPORTANT FEATURES ===\n",
      "                        feature  importance\n",
      "0         fp_approach_diversity    0.283744\n",
      "4                uses_canvas_fp    0.189267\n",
      "1          collection_intensity    0.137694\n",
      "6            tracks_coordinates    0.084976\n",
      "2          sophistication_score    0.084720\n",
      "10              complexity_tier    0.074402\n",
      "3                 uses_audio_fp    0.036242\n",
      "7         interaction_diversity    0.034740\n",
      "8                 tracks_timing    0.028747\n",
      "5   collection_method_diversity    0.016587\n"
     ]
    }
   ],
   "source": [
    "# Cell: Test New Features with Vendor-Aware Training\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Use your existing vendor-aware split function with new features\n",
    "train_idx, test_idx, split_info = create_vendor_aware_split(agnostic_features_df)\n",
    "\n",
    "# Get features (exclude metadata)\n",
    "feature_cols = [col for col in agnostic_features_df.columns if col not in ['script_id', 'label', 'vendor']]\n",
    "X_train = agnostic_features_df.loc[train_idx, feature_cols]\n",
    "y_train = agnostic_features_df.loc[train_idx, 'label']\n",
    "X_test = agnostic_features_df.loc[test_idx, feature_cols]\n",
    "y_test = agnostic_features_df.loc[test_idx, 'label']\n",
    "\n",
    "print(f\"Training with {len(feature_cols)} vendor-agnostic features\")\n",
    "print(f\"Training set: {len(train_idx)} samples\")\n",
    "print(f\"Test set: {len(test_idx)} samples\")\n",
    "\n",
    "# Create vendor weights for training\n",
    "def create_vendor_weights_fixed(features_df, train_idx):\n",
    "    \"\"\"Create inverse frequency weights for positive vendors\"\"\"\n",
    "    train_df = features_df.loc[train_idx]\n",
    "    train_positives = train_df[train_df['label'] == 1]\n",
    "    \n",
    "    if len(train_positives) == 0:\n",
    "        return np.ones(len(train_idx))\n",
    "    \n",
    "    vendor_counts = train_positives['vendor'].value_counts()\n",
    "    vendor_weights = 1 / np.sqrt(vendor_counts)\n",
    "    vendor_weights = vendor_weights / vendor_weights.sum() * len(vendor_weights)\n",
    "    \n",
    "    sample_weights = np.ones(len(train_idx))\n",
    "    for i, idx in enumerate(train_idx):\n",
    "        row = features_df.loc[idx]\n",
    "        if row['label'] == 1 and row['vendor'] in vendor_weights:\n",
    "            sample_weights[i] = vendor_weights[row['vendor']]\n",
    "    \n",
    "    return sample_weights\n",
    "\n",
    "# Get sample weights\n",
    "sample_weights = create_vendor_weights_fixed(agnostic_features_df, train_idx)\n",
    "\n",
    "# Train model with new features\n",
    "rf_new = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf_new.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_new.predict(X_test)\n",
    "y_pred_proba = rf_new.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"\\n=== NEW FEATURES PERFORMANCE ===\")\n",
    "print(f\"Overall Accuracy: {rf_new.score(X_test, y_test):.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Vendor-specific analysis\n",
    "test_df = agnostic_features_df.loc[test_idx].copy()\n",
    "test_df['predictions'] = y_pred\n",
    "test_df['pred_proba'] = y_pred_proba\n",
    "\n",
    "test_positives = test_df[test_df['label'] == 1]\n",
    "if len(test_positives) > 0:\n",
    "    print(f\"\\n=== VENDOR-SPECIFIC PERFORMANCE ===\")\n",
    "    \n",
    "    vendor_performance = []\n",
    "    for vendor in test_positives['vendor'].unique():\n",
    "        vendor_data = test_positives[test_positives['vendor'] == vendor]\n",
    "        accuracy = (vendor_data['predictions'] == vendor_data['label']).mean()\n",
    "        count = len(vendor_data)\n",
    "        \n",
    "        # Determine vendor category\n",
    "        if vendor in split_info['train_vendors']['high_volume_partial']:\n",
    "            category = 'high (seen)'\n",
    "        elif vendor in split_info['test_vendors']['medium_volume']:\n",
    "            category = 'medium (unseen)'\n",
    "        elif vendor in split_info['test_vendors']['low_volume']:\n",
    "            category = 'low (unseen)'\n",
    "        else:\n",
    "            category = 'unknown'\n",
    "        \n",
    "        vendor_performance.append({\n",
    "            'vendor': vendor,\n",
    "            'accuracy': accuracy,\n",
    "            'count': count,\n",
    "            'category': category\n",
    "        })\n",
    "    \n",
    "    vendor_perf_df = pd.DataFrame(vendor_performance).sort_values('accuracy', ascending=False)\n",
    "    print(vendor_perf_df)\n",
    "    \n",
    "    # Category performance\n",
    "    category_perf = vendor_perf_df.groupby('category').agg({\n",
    "        'accuracy': 'mean',\n",
    "        'count': 'sum'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(f\"\\n=== CATEGORY PERFORMANCE ===\")\n",
    "    print(category_perf)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_new.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\n=== TOP 10 MOST IMPORTANT FEATURES ===\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FILTERING TO BINARY CLASSIFICATION (0 and 1 only) ===\n",
      "Original dataset:\n",
      "  Total samples: 2229\n",
      "  Label distribution: {0: 1997, 1: 232}\n",
      "\n",
      "Filtered binary dataset:\n",
      "  Total samples: 2229\n",
      "  Label distribution: {0: 1997, 1: 232}\n",
      "  Positive rate: 0.104\n",
      "Splitting 232 positives and 1997 negatives...\n",
      "High volume vendor 'Iovation': 81 scripts -> 57 train, 24 test\n",
      "High volume vendor 'Forter': 53 scripts -> 38 train, 15 test\n",
      "High volume vendor 'Human': 27 scripts -> 19 train, 8 test\n",
      "High volume vendor 'BioCatch': 21 scripts -> 15 train, 6 test\n",
      "Medium volume vendor 'PingOne': 5 scripts -> all to train\n",
      "Medium volume vendor 'Nudata': 6 scripts -> all to train\n",
      "Medium volume vendor 'Yofi': 8 scripts -> all to train\n",
      "Medium volume vendor 'Sardine': 6 scripts -> all to test\n",
      "Medium volume vendor 'Behaviosec': 9 scripts -> all to test\n",
      "Low volume vendor 'Cheq': 4 scripts -> all to train\n",
      "Low volume vendor 'Callsign': 1 scripts -> all to train\n",
      "Low volume vendor 'Feedzai': 2 scripts -> all to train\n",
      "Low volume vendor 'Threatmark': 1 scripts -> all to train\n",
      "Low volume vendor 'GroupIB': 1 scripts -> all to train\n",
      "Low volume vendor 'Utarget': 1 scripts -> all to test\n",
      "Low volume vendor 'Accertify': 3 scripts -> all to test\n",
      "Low volume vendor 'Datadome': 1 scripts -> all to test\n",
      "Low volume vendor 'Transmit': 2 scripts -> all to test\n",
      "\n",
      "Final split:\n",
      "Train: 157 positives + 1398 negatives = 1555 total\n",
      "Test: 75 positives + 599 negatives = 674 total\n",
      "\n",
      "Binary train/test split:\n",
      "  Training: 1555 samples\n",
      "  Test: 674 samples\n",
      "  Train labels: {0: 1398, 1: 157}\n",
      "  Test labels: {0: 599, 1: 75}\n",
      "\n",
      "=== BINARY CLASSIFICATION RESULTS ===\n",
      "Overall Accuracy: 0.969\n",
      "ROC AUC: 0.971\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       599\n",
      "           1       0.89      0.83      0.86        75\n",
      "\n",
      "    accuracy                           0.97       674\n",
      "   macro avg       0.93      0.91      0.92       674\n",
      "weighted avg       0.97      0.97      0.97       674\n",
      "\n",
      "\n",
      "=== VENDOR-SPECIFIC PERFORMANCE (Binary) ===\n",
      "       vendor  accuracy  count         category\n",
      "0    Iovation      1.00     24      high (seen)\n",
      "1      Forter      1.00     15      high (seen)\n",
      "3    BioCatch      1.00      6      high (seen)\n",
      "5  Behaviosec      1.00      9  medium (unseen)\n",
      "6     Utarget      1.00      1     low (unseen)\n",
      "8    Datadome      1.00      1     low (unseen)\n",
      "2       Human      0.75      8      high (seen)\n",
      "4     Sardine      0.00      6  medium (unseen)\n",
      "7   Accertify      0.00      3     low (unseen)\n",
      "9    Transmit      0.00      2     low (unseen)\n",
      "\n",
      "=== CATEGORY PERFORMANCE (Binary) ===\n",
      "                 accuracy  count\n",
      "category                        \n",
      "high (seen)         0.938     53\n",
      "low (unseen)        0.500      7\n",
      "medium (unseen)     0.500     15\n",
      "\n",
      "=== CROSS-VALIDATION ON BINARY DATA ===\n",
      "Standard CV (Binary): 0.977 ± 0.006\n",
      "ROC AUC CV (Binary):  0.995 ± 0.003\n",
      "\n",
      "=== PERFORMANCE COMPARISON ===\n",
      "Standard CV (binary data):     0.977\n",
      "Vendor-aware (binary data):    0.969\n",
      "Previous vendor-aware (3-class): 0.926\n",
      "Vendor-aware improvement: +-0.008\n",
      "⚠️  Vendor-aware splitting may not be critical for this binary problem\n"
     ]
    }
   ],
   "source": [
    "# Cell: Filter to Binary Classification (0 and 1 only)\n",
    "print(\"=== FILTERING TO BINARY CLASSIFICATION (0 and 1 only) ===\")\n",
    "\n",
    "# Filter out label -1, keep only 0 and 1\n",
    "binary_df = agnostic_features_df[agnostic_features_df['label'].isin([0, 1])].copy()\n",
    "\n",
    "print(\"Original dataset:\")\n",
    "print(f\"  Total samples: {len(agnostic_features_df)}\")\n",
    "print(f\"  Label distribution: {agnostic_features_df['label'].value_counts().to_dict()}\")\n",
    "\n",
    "print(\"\\nFiltered binary dataset:\")\n",
    "print(f\"  Total samples: {len(binary_df)}\")\n",
    "print(f\"  Label distribution: {binary_df['label'].value_counts().to_dict()}\")\n",
    "print(f\"  Positive rate: {(binary_df['label'] == 1).mean():.3f}\")\n",
    "binary_df = binary_df.reset_index(drop=True)\n",
    "\n",
    "# Re-run your vendor-aware analysis with binary data\n",
    "train_idx_binary, test_idx_binary, split_info_binary = create_vendor_aware_split(binary_df)\n",
    "\n",
    "X_train_binary = binary_df.loc[train_idx_binary, feature_cols]\n",
    "y_train_binary = binary_df.loc[train_idx_binary, 'label']\n",
    "X_test_binary = binary_df.loc[test_idx_binary, feature_cols]\n",
    "y_test_binary = binary_df.loc[test_idx_binary, 'label']\n",
    "\n",
    "print(f\"\\nBinary train/test split:\")\n",
    "print(f\"  Training: {len(train_idx_binary)} samples\")\n",
    "print(f\"  Test: {len(test_idx_binary)} samples\")\n",
    "print(f\"  Train labels: {y_train_binary.value_counts().to_dict()}\")\n",
    "print(f\"  Test labels: {y_test_binary.value_counts().to_dict()}\")\n",
    "\n",
    "sample_weights_binary = create_vendor_weights_fixed(binary_df, train_idx_binary)\n",
    "\n",
    "# Train binary model\n",
    "rf_binary = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf_binary.fit(X_train_binary, y_train_binary, sample_weight=sample_weights_binary)\n",
    "\n",
    "# Predictions\n",
    "y_pred_binary = rf_binary.predict(X_test_binary)\n",
    "y_pred_proba_binary = rf_binary.predict_proba(X_test_binary)[:, 1]\n",
    "\n",
    "print(f\"\\n=== BINARY CLASSIFICATION RESULTS ===\")\n",
    "print(f\"Overall Accuracy: {rf_binary.score(X_test_binary, y_test_binary):.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test_binary, y_pred_proba_binary):.3f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary))\n",
    "\n",
    "# Vendor-specific analysis for binary data\n",
    "test_df_binary = binary_df.loc[test_idx_binary].copy()\n",
    "test_df_binary['predictions'] = y_pred_binary\n",
    "test_df_binary['pred_proba'] = y_pred_proba_binary\n",
    "\n",
    "test_positives_binary = test_df_binary[test_df_binary['label'] == 1]\n",
    "if len(test_positives_binary) > 0:\n",
    "    print(f\"\\n=== VENDOR-SPECIFIC PERFORMANCE (Binary) ===\")\n",
    "    \n",
    "    vendor_performance_binary = []\n",
    "    for vendor in test_positives_binary['vendor'].unique():\n",
    "        vendor_data = test_positives_binary[test_positives_binary['vendor'] == vendor]\n",
    "        accuracy = (vendor_data['predictions'] == vendor_data['label']).mean()\n",
    "        count = len(vendor_data)\n",
    "        \n",
    "        # Determine vendor category\n",
    "        if vendor in split_info_binary['train_vendors']['high_volume_partial']:\n",
    "            category = 'high (seen)'\n",
    "        elif vendor in split_info_binary['test_vendors']['medium_volume']:\n",
    "            category = 'medium (unseen)'\n",
    "        elif vendor in split_info_binary['test_vendors']['low_volume']:\n",
    "            category = 'low (unseen)'\n",
    "        else:\n",
    "            category = 'unknown'\n",
    "        \n",
    "        vendor_performance_binary.append({\n",
    "            'vendor': vendor,\n",
    "            'accuracy': accuracy,\n",
    "            'count': count,\n",
    "            'category': category\n",
    "        })\n",
    "    \n",
    "    vendor_perf_df_binary = pd.DataFrame(vendor_performance_binary).sort_values('accuracy', ascending=False)\n",
    "    print(vendor_perf_df_binary)\n",
    "    \n",
    "    # Category performance\n",
    "    category_perf_binary = vendor_perf_df_binary.groupby('category').agg({\n",
    "        'accuracy': 'mean',\n",
    "        'count': 'sum'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(f\"\\n=== CATEGORY PERFORMANCE (Binary) ===\")\n",
    "    print(category_perf_binary)\n",
    "\n",
    "# Now test CV on binary data\n",
    "print(f\"\\n=== CROSS-VALIDATION ON BINARY DATA ===\")\n",
    "cv_scores_binary = cross_val_score(rf_binary, \n",
    "                                  binary_df[feature_cols], \n",
    "                                  binary_df['label'], \n",
    "                                  cv=5, scoring='accuracy')\n",
    "\n",
    "cv_roc_binary = cross_val_score(rf_binary, \n",
    "                               binary_df[feature_cols], \n",
    "                               binary_df['label'], \n",
    "                               cv=5, scoring='roc_auc')\n",
    "\n",
    "print(f\"Standard CV (Binary): {cv_scores_binary.mean():.3f} ± {cv_scores_binary.std():.3f}\")\n",
    "print(f\"ROC AUC CV (Binary):  {cv_roc_binary.mean():.3f} ± {cv_roc_binary.std():.3f}\")\n",
    "\n",
    "# Compare performance metrics\n",
    "print(f\"\\n=== PERFORMANCE COMPARISON ===\")\n",
    "print(f\"Standard CV (binary data):     {cv_scores_binary.mean():.3f}\")\n",
    "print(f\"Vendor-aware (binary data):    {rf_binary.score(X_test_binary, y_test_binary):.3f}\")\n",
    "print(f\"Previous vendor-aware (3-class): 0.926\")\n",
    "\n",
    "gap = rf_binary.score(X_test_binary, y_test_binary) - cv_scores_binary.mean()\n",
    "print(f\"Vendor-aware improvement: +{gap:.3f}\")\n",
    "\n",
    "if gap > 0.05:\n",
    "    print(\"✅ Vendor-aware splitting provides significant improvement!\")\n",
    "elif gap > 0.02:\n",
    "    print(\"✅ Vendor-aware splitting provides modest improvement\")\n",
    "else:\n",
    "    print(\"⚠️  Vendor-aware splitting may not be critical for this binary problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INVESTIGATING WHY STANDARD CV PERFORMS BETTER ===\n",
      "Fold 1:\n",
      "  Accuracy: 0.975\n",
      "  Train vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Callsign', 'Cheq', 'Datadome', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Sardine', 'Threatmark', 'Transmit', 'Yofi']\n",
      "  Val vendors: ['Behaviosec', 'BioCatch', 'Cheq', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Sardine', 'Utarget', 'Yofi']\n",
      "  Vendor overlap: 10/11 (90.9%)\n",
      "\n",
      "Fold 2:\n",
      "  Accuracy: 0.978\n",
      "  Train vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Cheq', 'Datadome', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Sardine', 'Threatmark', 'Transmit', 'Utarget', 'Yofi']\n",
      "  Val vendors: ['Behaviosec', 'BioCatch', 'Callsign', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Sardine', 'Yofi']\n",
      "  Vendor overlap: 10/11 (90.9%)\n",
      "\n",
      "Fold 3:\n",
      "  Accuracy: 0.975\n",
      "  Train vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Sardine', 'Threatmark', 'Utarget', 'Yofi']\n",
      "  Val vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Datadome', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Sardine', 'Transmit', 'Yofi']\n",
      "  Vendor overlap: 11/13 (84.6%)\n",
      "\n",
      "Fold 4:\n",
      "  Accuracy: 0.989\n",
      "  Train vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Callsign', 'Cheq', 'Datadome', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Sardine', 'Threatmark', 'Transmit', 'Utarget', 'Yofi']\n",
      "  Val vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Cheq', 'Forter', 'Human', 'Iovation', 'PingOne', 'Sardine', 'Yofi']\n",
      "  Vendor overlap: 10/10 (100.0%)\n",
      "\n",
      "Fold 5:\n",
      "  Accuracy: 0.984\n",
      "  Train vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Callsign', 'Cheq', 'Datadome', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Sardine', 'Transmit', 'Utarget', 'Yofi']\n",
      "  Val vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Cheq', 'Forter', 'GroupIB', 'Human', 'Iovation', 'PingOne', 'Sardine', 'Threatmark', 'Yofi']\n",
      "  Vendor overlap: 10/12 (83.3%)\n",
      "\n",
      "=== STANDARD CV FOLD ANALYSIS ===\n",
      "   fold  accuracy  train_vendors  val_vendors  vendor_overlap  overlap_rate  \\\n",
      "0     1  0.975336             17           11              10      0.909091   \n",
      "1     2  0.977578             17           11              10      0.909091   \n",
      "2     3  0.975336             16           13              11      0.846154   \n",
      "3     4  0.988789             18           10              10      1.000000   \n",
      "4     5  0.984270             16           12              10      0.833333   \n",
      "\n",
      "   train_pos  val_pos  \n",
      "0        186       46  \n",
      "1        186       46  \n",
      "2        185       47  \n",
      "3        185       47  \n",
      "4        186       46  \n",
      "\n",
      "Average vendor overlap rate: 0.900\n",
      "Average accuracy: 0.980\n",
      "\n",
      "=== COMPARISON ===\n",
      "Standard CV (with vendor overlap): 0.980\n",
      "Vendor-aware (no vendor overlap):  0.926\n",
      "Difference: 0.054\n",
      "✅ Standard CV works well because most validation vendors are seen in training\n",
      "   → This suggests your features DO generalize within vendors\n",
      "   → Cross-vendor challenge is real but maybe not your main concern\n"
     ]
    }
   ],
   "source": [
    "# Cell: Investigate Why Standard CV is Betterx\n",
    "print(\"=== INVESTIGATING WHY STANDARD CV PERFORMS BETTER ===\")\n",
    "\n",
    "# Let's see what happens in standard CV folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X_binary = binary_df[feature_cols]\n",
    "y_binary = binary_df['label']\n",
    "\n",
    "fold_results = []\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_binary, y_binary)):\n",
    "    \n",
    "    # Get train/val data for this fold\n",
    "    train_data = binary_df.iloc[train_idx]\n",
    "    val_data = binary_df.iloc[val_idx]\n",
    "    \n",
    "    # Analyze vendor distribution in this fold\n",
    "    train_positives = train_data[train_data['label'] == 1]\n",
    "    val_positives = val_data[val_data['label'] == 1]\n",
    "    \n",
    "    train_vendors = set(train_positives['vendor'].dropna().unique())\n",
    "    val_vendors = set(val_positives['vendor'].dropna().unique())\n",
    "    \n",
    "    # Check vendor overlap\n",
    "    vendor_overlap = len(train_vendors.intersection(val_vendors))\n",
    "    total_val_vendors = len(val_vendors)\n",
    "    \n",
    "    # Train and test this fold\n",
    "    X_fold_train = X_binary.iloc[train_idx]\n",
    "    y_fold_train = y_binary.iloc[train_idx]\n",
    "    X_fold_val = X_binary.iloc[val_idx]\n",
    "    y_fold_val = y_binary.iloc[val_idx]\n",
    "    fold_weights = create_vendor_weights_fixed(binary_df, train_idx)\n",
    "\n",
    "    fold_model = RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=15, min_samples_split=5,\n",
    "        min_samples_leaf=2, random_state=42, class_weight='balanced'\n",
    "    )\n",
    "    fold_model.fit(X_fold_train, y_fold_train, sample_weight=fold_weights)\n",
    "    fold_accuracy = fold_model.score(X_fold_val, y_fold_val)\n",
    "    \n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'accuracy': fold_accuracy,\n",
    "        'train_vendors': len(train_vendors),\n",
    "        'val_vendors': len(val_vendors),\n",
    "        'vendor_overlap': vendor_overlap,\n",
    "        'overlap_rate': vendor_overlap / max(total_val_vendors, 1),\n",
    "        'train_pos': len(train_positives),\n",
    "        'val_pos': len(val_positives)\n",
    "    })\n",
    "    \n",
    "    print(f\"Fold {fold + 1}:\")\n",
    "    print(f\"  Accuracy: {fold_accuracy:.3f}\")\n",
    "    print(f\"  Train vendors: {sorted(train_vendors)}\")\n",
    "    print(f\"  Val vendors: {sorted(val_vendors)}\")\n",
    "    print(f\"  Vendor overlap: {vendor_overlap}/{total_val_vendors} ({vendor_overlap/max(total_val_vendors,1)*100:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "# Summary\n",
    "fold_df = pd.DataFrame(fold_results)\n",
    "print(\"=== STANDARD CV FOLD ANALYSIS ===\")\n",
    "print(fold_df)\n",
    "print(f\"\\nAverage vendor overlap rate: {fold_df['overlap_rate'].mean():.3f}\")\n",
    "print(f\"Average accuracy: {fold_df['accuracy'].mean():.3f}\")\n",
    "\n",
    "# Compare to your vendor-aware split\n",
    "print(f\"\\n=== COMPARISON ===\")\n",
    "print(f\"Standard CV (with vendor overlap): {fold_df['accuracy'].mean():.3f}\")\n",
    "print(f\"Vendor-aware (no vendor overlap):  0.926\")\n",
    "print(f\"Difference: {fold_df['accuracy'].mean() - 0.926:.3f}\")\n",
    "\n",
    "if fold_df['overlap_rate'].mean() > 0.7:\n",
    "    print(\"✅ Standard CV works well because most validation vendors are seen in training\")\n",
    "    print(\"   → This suggests your features DO generalize within vendors\")\n",
    "    print(\"   → Cross-vendor challenge is real but maybe not your main concern\")\n",
    "elif fold_df['overlap_rate'].mean() > 0.3:\n",
    "    print(\"⚠️  Standard CV has moderate vendor overlap\")\n",
    "    print(\"   → Mixed generalization scenario\")\n",
    "else:\n",
    "    print(\"❌ Standard CV has little vendor overlap\")\n",
    "    print(\"   → Something else is causing the performance difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VENDOR-AWARE CROSS-VALIDATION ===\n",
      "Vendor categories:\n",
      "  High volume (>20): ['Iovation', 'Forter', 'Human', 'BioCatch']\n",
      "  Medium volume (5-20): ['Behaviosec', 'Yofi', 'Sardine', 'Nudata', 'PingOne']\n",
      "  Low volume (<5): ['Cheq', 'Accertify', 'Feedzai', 'Transmit', 'Datadome', 'Callsign', 'Threatmark', 'GroupIB', 'Utarget']\n",
      "\n",
      "=== FOLD 1/5 ===\n",
      "  Overall accuracy: 0.969\n",
      "  ROC AUC: 0.971\n",
      "  Unseen vendor accuracy: 0.500\n",
      "  Test vendors: ['Sardine', 'Behaviosec', 'Utarget', 'Accertify', 'Datadome', 'Transmit']\n",
      "  Unseen vendors in test: ['Sardine', 'Behaviosec', 'Utarget', 'Accertify', 'Datadome', 'Transmit']\n",
      "  Seen vendors in test: ['Iovation', 'Forter', 'Human', 'BioCatch']\n",
      "\n",
      "=== FOLD 2/5 ===\n",
      "  Overall accuracy: 0.966\n",
      "  ROC AUC: 0.993\n",
      "  Unseen vendor accuracy: 0.579\n",
      "  Test vendors: ['Yofi', 'Sardine', 'Transmit', 'Datadome', 'Threatmark', 'GroupIB']\n",
      "  Unseen vendors in test: ['Yofi', 'Sardine', 'Transmit', 'Datadome', 'Threatmark', 'GroupIB']\n",
      "  Seen vendors in test: ['Iovation', 'Forter', 'Human', 'BioCatch']\n",
      "\n",
      "=== FOLD 3/5 ===\n",
      "  Overall accuracy: 0.970\n",
      "  ROC AUC: 0.992\n",
      "  Unseen vendor accuracy: 0.389\n",
      "  Test vendors: ['PingOne', 'Nudata', 'Cheq', 'Utarget', 'Datadome', 'Callsign']\n",
      "  Unseen vendors in test: ['PingOne', 'Nudata', 'Cheq', 'Utarget', 'Datadome', 'Callsign']\n",
      "  Seen vendors in test: ['Iovation', 'Forter', 'Human', 'BioCatch']\n",
      "\n",
      "=== FOLD 4/5 ===\n",
      "  Overall accuracy: 0.961\n",
      "  ROC AUC: 0.991\n",
      "  Unseen vendor accuracy: 0.391\n",
      "  Test vendors: ['Nudata', 'Yofi', 'Threatmark', 'Cheq', 'Feedzai', 'Transmit']\n",
      "  Unseen vendors in test: ['Nudata', 'Yofi', 'Threatmark', 'Cheq', 'Feedzai', 'Transmit']\n",
      "  Seen vendors in test: ['Iovation', 'Forter', 'Human', 'BioCatch']\n",
      "\n",
      "=== FOLD 5/5 ===\n",
      "  Overall accuracy: 0.964\n",
      "  ROC AUC: 0.985\n",
      "  Unseen vendor accuracy: 0.333\n",
      "  Test vendors: ['Sardine', 'PingOne', 'Callsign', 'Accertify', 'Feedzai', 'Cheq']\n",
      "  Unseen vendors in test: ['Sardine', 'PingOne', 'Callsign', 'Accertify', 'Feedzai', 'Cheq']\n",
      "  Seen vendors in test: ['Iovation', 'Forter', 'Human', 'BioCatch']\n",
      "\n",
      "=== VENDOR-AWARE CV RESULTS ===\n",
      "   fold  overall_accuracy   roc_auc  train_size  test_size  \\\n",
      "0     1          0.968843  0.971052        1555        674   \n",
      "1     2          0.965723  0.992882        1558        671   \n",
      "2     3          0.970149  0.991700        1559        670   \n",
      "3     4          0.961481  0.991104        1554        675   \n",
      "4     5          0.964339  0.984625        1556        673   \n",
      "\n",
      "                                        test_vendors  unseen_vendor_accuracy  \\\n",
      "0  [Sardine, Behaviosec, Utarget, Accertify, Data...                0.500000   \n",
      "1  [Yofi, Sardine, Transmit, Datadome, Threatmark...                0.578947   \n",
      "2  [PingOne, Nudata, Cheq, Utarget, Datadome, Cal...                0.388889   \n",
      "3  [Nudata, Yofi, Threatmark, Cheq, Feedzai, Tran...                0.391304   \n",
      "4  [Sardine, PingOne, Callsign, Accertify, Feedza...                0.333333   \n",
      "\n",
      "   seen_vendor_accuracy  n_unseen_vendors  n_seen_vendors  \n",
      "0              0.962264                 6               4  \n",
      "1              0.981132                 6               4  \n",
      "2              0.943396                 6               4  \n",
      "3              0.943396                 6               4  \n",
      "4              0.962264                 6               4  \n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Overall Accuracy: 0.966 ± 0.003\n",
      "ROC AUC: 0.986 ± 0.009\n",
      "Unseen Vendor Accuracy: 0.438 ± 0.099\n",
      "  (Based on 5 folds with unseen vendors)\n",
      "Seen Vendor Accuracy: 0.958 ± 0.016\n",
      "\n",
      "=== COMPARISON WITH OTHER APPROACHES ===\n",
      "Standard CV (random splits):     0.950 ± 0.020\n",
      "Vendor-aware CV (this approach): 0.966 ± 0.003\n",
      "Single vendor-aware split:       0.926\n",
      "\n",
      "=== DETAILED FOLD BREAKDOWN ===\n",
      "Fold 1: 0.969 accuracy, 6 unseen vendors, 4 seen vendors\n",
      "Fold 2: 0.966 accuracy, 6 unseen vendors, 4 seen vendors\n",
      "Fold 3: 0.970 accuracy, 6 unseen vendors, 4 seen vendors\n",
      "Fold 4: 0.961 accuracy, 6 unseen vendors, 4 seen vendors\n",
      "Fold 5: 0.964 accuracy, 6 unseen vendors, 4 seen vendors\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed Vendor-Aware Cross-Validation\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "\n",
    "def vendor_aware_cross_validation(features_df, model, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform cross-validation while maintaining vendor-aware splitting in each fold\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Get positive samples with vendors\n",
    "    positive_samples = features_df[features_df['label'] == 1].copy()\n",
    "    negative_samples = features_df[features_df['label'] == 0].copy()\n",
    "    \n",
    "    # Categorize vendors by volume (same logic as your original split)\n",
    "    vendor_counts = positive_samples['vendor'].value_counts()\n",
    "    high_volume_vendors = vendor_counts[vendor_counts > 20].index.tolist()\n",
    "    medium_volume_vendors = vendor_counts[(vendor_counts >= 5) & (vendor_counts <= 20)].index.tolist()\n",
    "    low_volume_vendors = vendor_counts[vendor_counts < 5].index.tolist()\n",
    "    \n",
    "    print(f\"Vendor categories:\")\n",
    "    print(f\"  High volume (>20): {high_volume_vendors}\")\n",
    "    print(f\"  Medium volume (5-20): {medium_volume_vendors}\")\n",
    "    print(f\"  Low volume (<5): {low_volume_vendors}\")\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "        print(f\"\\n=== FOLD {fold + 1}/{n_splits} ===\")\n",
    "        \n",
    "        # Set random seed for this fold\n",
    "        fold_seed = random_state + fold\n",
    "        np.random.seed(fold_seed)\n",
    "        \n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        \n",
    "        # HIGH VOLUME VENDORS: Split scripts within vendor (same as before)\n",
    "        for vendor in high_volume_vendors:\n",
    "            vendor_scripts = positive_samples[positive_samples['vendor'] == vendor].index.tolist()\n",
    "            np.random.shuffle(vendor_scripts)\n",
    "            \n",
    "            n_test = max(1, int(len(vendor_scripts) * 0.3))\n",
    "            test_indices.extend(vendor_scripts[:n_test])\n",
    "            train_indices.extend(vendor_scripts[n_test:])\n",
    "        \n",
    "        # MEDIUM VOLUME VENDORS: Rotate which vendors go to train vs test\n",
    "        if len(medium_volume_vendors) > 0:\n",
    "            np.random.shuffle(medium_volume_vendors)\n",
    "            n_train_vendors = max(1, int(len(medium_volume_vendors) * 0.6))\n",
    "            \n",
    "            # Rotate the split based on fold number\n",
    "            rotation = fold % len(medium_volume_vendors)\n",
    "            rotated_vendors = medium_volume_vendors[rotation:] + medium_volume_vendors[:rotation]\n",
    "            \n",
    "            train_medium = rotated_vendors[:n_train_vendors]\n",
    "            test_medium = rotated_vendors[n_train_vendors:]\n",
    "        else:\n",
    "            train_medium = []\n",
    "            test_medium = []\n",
    "        \n",
    "        for vendor in train_medium:\n",
    "            train_indices.extend(positive_samples[positive_samples['vendor'] == vendor].index.tolist())\n",
    "        \n",
    "        for vendor in test_medium:\n",
    "            test_indices.extend(positive_samples[positive_samples['vendor'] == vendor].index.tolist())\n",
    "        \n",
    "        # LOW VOLUME VENDORS: Rotate between train and test\n",
    "        if len(low_volume_vendors) > 0:\n",
    "            np.random.shuffle(low_volume_vendors)\n",
    "            n_test_low = len(low_volume_vendors) // 2\n",
    "            \n",
    "            # Rotate based on fold\n",
    "            low_rotation = fold % len(low_volume_vendors)\n",
    "            rotated_low = low_volume_vendors[low_rotation:] + low_volume_vendors[:low_rotation]\n",
    "            \n",
    "            test_low = rotated_low[:n_test_low]\n",
    "            train_low = rotated_low[n_test_low:]\n",
    "        else:\n",
    "            test_low = []\n",
    "            train_low = []\n",
    "        \n",
    "        for vendor in train_low:\n",
    "            train_indices.extend(positive_samples[positive_samples['vendor'] == vendor].index.tolist())\n",
    "        \n",
    "        for vendor in test_low:\n",
    "            test_indices.extend(positive_samples[positive_samples['vendor'] == vendor].index.tolist())\n",
    "        \n",
    "        # NEGATIVE SAMPLES: Random split\n",
    "        neg_indices = negative_samples.index.tolist()\n",
    "        np.random.shuffle(neg_indices)\n",
    "        n_test_neg = int(len(neg_indices) * 0.3)\n",
    "        \n",
    "        train_indices.extend(neg_indices[n_test_neg:])\n",
    "        test_indices.extend(neg_indices[:n_test_neg])\n",
    "        \n",
    "        # Create train/test sets for this fold\n",
    "        X_train_fold = features_df.loc[train_indices, feature_cols]\n",
    "        y_train_fold = features_df.loc[train_indices, 'label']\n",
    "        X_test_fold = features_df.loc[test_indices, feature_cols]\n",
    "        y_test_fold = features_df.loc[test_indices, 'label']\n",
    "        fold_weights = create_vendor_weights_fixed(features_df, train_indices)\n",
    "        # Train model\n",
    "        fold_model = clone(model)\n",
    "        fold_model.fit(X_train_fold, y_train_fold, sample_weight=fold_weights)\n",
    "        \n",
    "        # Evaluate\n",
    "        fold_accuracy = fold_model.score(X_test_fold, y_test_fold)\n",
    "        y_pred_fold = fold_model.predict(X_test_fold)\n",
    "        y_proba_fold = fold_model.predict_proba(X_test_fold)[:, 1]\n",
    "        fold_roc = roc_auc_score(y_test_fold, y_proba_fold)\n",
    "        \n",
    "        # Analyze vendor performance in this fold\n",
    "        test_df_fold = features_df.loc[test_indices].copy()\n",
    "        test_df_fold['predictions'] = y_pred_fold\n",
    "        \n",
    "        test_positives_fold = test_df_fold[test_df_fold['label'] == 1]\n",
    "        unseen_vendors = []\n",
    "        seen_vendors = []\n",
    "        \n",
    "        # Classify vendors as seen/unseen for this fold\n",
    "        train_vendors = set()\n",
    "        for vendor in high_volume_vendors:\n",
    "            train_vendors.add(vendor)  # High volume vendors are always partially in training\n",
    "        train_vendors.update(train_medium)\n",
    "        train_vendors.update(train_low)\n",
    "        \n",
    "        for vendor in test_positives_fold['vendor'].unique():\n",
    "            if vendor in train_vendors:\n",
    "                seen_vendors.append(vendor)\n",
    "            else:\n",
    "                unseen_vendors.append(vendor)\n",
    "        \n",
    "        # Calculate unseen vendor performance\n",
    "        if unseen_vendors:\n",
    "            unseen_data = test_positives_fold[test_positives_fold['vendor'].isin(unseen_vendors)]\n",
    "            unseen_accuracy = (unseen_data['predictions'] == unseen_data['label']).mean()\n",
    "        else:\n",
    "            unseen_accuracy = np.nan\n",
    "        \n",
    "        # Calculate seen vendor performance  \n",
    "        if seen_vendors:\n",
    "            seen_data = test_positives_fold[test_positives_fold['vendor'].isin(seen_vendors)]\n",
    "            seen_accuracy = (seen_data['predictions'] == seen_data['label']).mean()\n",
    "        else:\n",
    "            seen_accuracy = np.nan\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold + 1,\n",
    "            'overall_accuracy': fold_accuracy,\n",
    "            'roc_auc': fold_roc,\n",
    "            'train_size': len(train_indices),\n",
    "            'test_size': len(test_indices),\n",
    "            'test_vendors': test_medium + test_low,\n",
    "            'unseen_vendor_accuracy': unseen_accuracy,\n",
    "            'seen_vendor_accuracy': seen_accuracy,\n",
    "            'n_unseen_vendors': len(unseen_vendors),\n",
    "            'n_seen_vendors': len(seen_vendors)\n",
    "        })\n",
    "        \n",
    "        print(f\"  Overall accuracy: {fold_accuracy:.3f}\")\n",
    "        print(f\"  ROC AUC: {fold_roc:.3f}\")\n",
    "        \n",
    "        # Fixed formatting for unseen accuracy\n",
    "        if not np.isnan(unseen_accuracy):\n",
    "            print(f\"  Unseen vendor accuracy: {unseen_accuracy:.3f}\")\n",
    "        else:\n",
    "            print(f\"  Unseen vendor accuracy: N/A\")\n",
    "            \n",
    "        print(f\"  Test vendors: {test_medium + test_low}\")\n",
    "        print(f\"  Unseen vendors in test: {unseen_vendors}\")\n",
    "        print(f\"  Seen vendors in test: {seen_vendors}\")\n",
    "    \n",
    "    return pd.DataFrame(fold_results)\n",
    "\n",
    "# Run vendor-aware CV\n",
    "print(\"=== VENDOR-AWARE CROSS-VALIDATION ===\")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "cv_results = vendor_aware_cross_validation(binary_df, rf_model, n_splits=5, random_state=42)\n",
    "\n",
    "# Analyze results\n",
    "print(f\"\\n=== VENDOR-AWARE CV RESULTS ===\")\n",
    "print(cv_results)\n",
    "\n",
    "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
    "print(f\"Overall Accuracy: {cv_results['overall_accuracy'].mean():.3f} ± {cv_results['overall_accuracy'].std():.3f}\")\n",
    "print(f\"ROC AUC: {cv_results['roc_auc'].mean():.3f} ± {cv_results['roc_auc'].std():.3f}\")\n",
    "\n",
    "# Unseen vendor performance (excluding NaN values)\n",
    "unseen_scores = cv_results['unseen_vendor_accuracy'].dropna()\n",
    "if len(unseen_scores) > 0:\n",
    "    print(f\"Unseen Vendor Accuracy: {unseen_scores.mean():.3f} ± {unseen_scores.std():.3f}\")\n",
    "    print(f\"  (Based on {len(unseen_scores)} folds with unseen vendors)\")\n",
    "else:\n",
    "    print(f\"Unseen Vendor Accuracy: No folds had purely unseen vendors\")\n",
    "\n",
    "# Seen vendor performance\n",
    "seen_scores = cv_results['seen_vendor_accuracy'].dropna()\n",
    "if len(seen_scores) > 0:\n",
    "    print(f\"Seen Vendor Accuracy: {seen_scores.mean():.3f} ± {seen_scores.std():.3f}\")\n",
    "\n",
    "print(f\"\\n=== COMPARISON WITH OTHER APPROACHES ===\")\n",
    "print(f\"Standard CV (random splits):     0.950 ± 0.020\")\n",
    "print(f\"Vendor-aware CV (this approach): {cv_results['overall_accuracy'].mean():.3f} ± {cv_results['overall_accuracy'].std():.3f}\")\n",
    "print(f\"Single vendor-aware split:       0.926\")\n",
    "\n",
    "# Show detailed fold breakdown\n",
    "print(f\"\\n=== DETAILED FOLD BREAKDOWN ===\")\n",
    "for _, row in cv_results.iterrows():\n",
    "    print(f\"Fold {row['fold']}: {row['overall_accuracy']:.3f} accuracy, \"\n",
    "          f\"{row['n_unseen_vendors']} unseen vendors, {row['n_seen_vendors']} seen vendors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED VENDOR-AWARE CV WITH ERROR TRACKING ===\n",
      "Vendor categories:\n",
      "  High volume (>20): ['Iovation', 'Forter', 'Human', 'BioCatch']\n",
      "  Medium volume (5-20): ['Behaviosec', 'Yofi', 'Sardine', 'Nudata', 'PingOne']\n",
      "  Low volume (<5): ['Cheq', 'Accertify', 'Feedzai', 'Transmit', 'Datadome', 'Callsign', 'Threatmark', 'GroupIB', 'Utarget']\n",
      "\n",
      "============================================================\n",
      "FOLD 1/5\n",
      "============================================================\n",
      "Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "Test vendors: ['Accertify', 'Behaviosec', 'Datadome', 'Sardine', 'Transmit', 'Utarget']\n",
      "\n",
      "📊 VENDOR PERFORMANCE BREAKDOWN:\n",
      "  Accertify (UNSEEN): 0/3 = 0.000\n",
      "    ❌ ERRORS (3):\n",
      "      Script 7403113: predicted=0, actual=1, confidence=0.000\n",
      "      Script 7396662: predicted=0, actual=1, confidence=0.000\n",
      "      Script 7407196: predicted=0, actual=1, confidence=0.000\n",
      "  Behaviosec (UNSEEN): 9/9 = 1.000\n",
      "    ✅ No errors\n",
      "  BioCatch (SEEN): 6/6 = 1.000\n",
      "    ✅ No errors\n",
      "  Datadome (UNSEEN): 1/1 = 1.000\n",
      "    ✅ No errors\n",
      "  Forter (SEEN): 15/15 = 1.000\n",
      "    ✅ No errors\n",
      "  Human (SEEN): 6/8 = 0.750\n",
      "    ❌ ERRORS (2):\n",
      "      Script 7412870: predicted=0, actual=1, confidence=0.343\n",
      "      Script 7403037: predicted=0, actual=1, confidence=0.314\n",
      "  Iovation (SEEN): 24/24 = 1.000\n",
      "    ✅ No errors\n",
      "  Sardine (UNSEEN): 0/6 = 0.000\n",
      "    ❌ ERRORS (6):\n",
      "      Script 7397523: predicted=0, actual=1, confidence=0.294\n",
      "      Script 7400006: predicted=0, actual=1, confidence=0.008\n",
      "      Script 7397443: predicted=0, actual=1, confidence=0.378\n",
      "      Script 7397588: predicted=0, actual=1, confidence=0.381\n",
      "      Script 7397369: predicted=0, actual=1, confidence=0.381\n",
      "      Script 7401805: predicted=0, actual=1, confidence=0.294\n",
      "  Transmit (UNSEEN): 0/2 = 0.000\n",
      "    ❌ ERRORS (2):\n",
      "      Script 7403362: predicted=0, actual=1, confidence=0.485\n",
      "      Script 7407709: predicted=0, actual=1, confidence=0.475\n",
      "  Utarget (UNSEEN): 1/1 = 1.000\n",
      "    ✅ No errors\n",
      "\n",
      "❌ FALSE POSITIVES (8):\n",
      "    Script 7392031: predicted=1, actual=0, confidence=0.515\n",
      "    Script 7392038: predicted=1, actual=0, confidence=0.927\n",
      "    Script 7400797: predicted=1, actual=0, confidence=0.626\n",
      "    Script 7397937: predicted=1, actual=0, confidence=0.665\n",
      "    Script 7412821: predicted=1, actual=0, confidence=0.998\n",
      "    Script 7411552: predicted=1, actual=0, confidence=0.566\n",
      "    Script 7395582: predicted=1, actual=0, confidence=0.524\n",
      "    Script 7400941: predicted=1, actual=0, confidence=0.845\n",
      "\n",
      "📈 FOLD SUMMARY:\n",
      "  Overall accuracy: 0.969\n",
      "  Unseen vendor accuracy: 0.500\n",
      "  Total errors: 21\n",
      "\n",
      "============================================================\n",
      "FOLD 2/5\n",
      "============================================================\n",
      "Training vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Utarget']\n",
      "Test vendors: ['Datadome', 'GroupIB', 'Sardine', 'Threatmark', 'Transmit', 'Yofi']\n",
      "\n",
      "📊 VENDOR PERFORMANCE BREAKDOWN:\n",
      "  BioCatch (SEEN): 6/6 = 1.000\n",
      "    ✅ No errors\n",
      "  Datadome (UNSEEN): 1/1 = 1.000\n",
      "    ✅ No errors\n",
      "  Forter (SEEN): 15/15 = 1.000\n",
      "    ✅ No errors\n",
      "  GroupIB (UNSEEN): 1/1 = 1.000\n",
      "    ✅ No errors\n",
      "  Human (SEEN): 7/8 = 0.875\n",
      "    ❌ ERRORS (1):\n",
      "      Script 7412668: predicted=0, actual=1, confidence=0.426\n",
      "  Iovation (SEEN): 24/24 = 1.000\n",
      "    ✅ No errors\n",
      "  Sardine (UNSEEN): 0/6 = 0.000\n",
      "    ❌ ERRORS (6):\n",
      "      Script 7397523: predicted=0, actual=1, confidence=0.310\n",
      "      Script 7400006: predicted=0, actual=1, confidence=0.007\n",
      "      Script 7397443: predicted=0, actual=1, confidence=0.463\n",
      "      Script 7397588: predicted=0, actual=1, confidence=0.420\n",
      "      Script 7397369: predicted=0, actual=1, confidence=0.420\n",
      "      Script 7401805: predicted=0, actual=1, confidence=0.310\n",
      "  Threatmark (UNSEEN): 1/1 = 1.000\n",
      "    ✅ No errors\n",
      "  Transmit (UNSEEN): 0/2 = 0.000\n",
      "    ❌ ERRORS (2):\n",
      "      Script 7403362: predicted=0, actual=1, confidence=0.452\n",
      "      Script 7407709: predicted=0, actual=1, confidence=0.467\n",
      "  Yofi (UNSEEN): 8/8 = 1.000\n",
      "    ✅ No errors\n",
      "\n",
      "❌ FALSE POSITIVES (14):\n",
      "    Script 7417519: predicted=1, actual=0, confidence=0.895\n",
      "    Script 7392215: predicted=1, actual=0, confidence=0.617\n",
      "    Script 7411552: predicted=1, actual=0, confidence=0.740\n",
      "    Script 7392273: predicted=1, actual=0, confidence=0.617\n",
      "    Script 7403225: predicted=1, actual=0, confidence=0.609\n",
      "    Script 7393460: predicted=1, actual=0, confidence=0.617\n",
      "    Script 7400941: predicted=1, actual=0, confidence=0.859\n",
      "    Script 7395579: predicted=1, actual=0, confidence=0.689\n",
      "    Script 7392031: predicted=1, actual=0, confidence=0.553\n",
      "    Script 7392038: predicted=1, actual=0, confidence=0.920\n",
      "    Script 7403206: predicted=1, actual=0, confidence=0.617\n",
      "    Script 7395905: predicted=1, actual=0, confidence=0.995\n",
      "    Script 7412042: predicted=1, actual=0, confidence=0.765\n",
      "    Script 7392289: predicted=1, actual=0, confidence=0.598\n",
      "\n",
      "📈 FOLD SUMMARY:\n",
      "  Overall accuracy: 0.966\n",
      "  Unseen vendor accuracy: 0.579\n",
      "  Total errors: 23\n",
      "\n",
      "============================================================\n",
      "FOLD 3/5\n",
      "============================================================\n",
      "Training vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Sardine', 'Threatmark', 'Transmit', 'Yofi']\n",
      "Test vendors: ['Callsign', 'Cheq', 'Datadome', 'Nudata', 'PingOne', 'Utarget']\n",
      "\n",
      "📊 VENDOR PERFORMANCE BREAKDOWN:\n",
      "  BioCatch (SEEN): 6/6 = 1.000\n",
      "    ✅ No errors\n",
      "  Callsign (UNSEEN): 0/1 = 0.000\n",
      "    ❌ ERRORS (1):\n",
      "      Script 7413095: predicted=0, actual=1, confidence=0.085\n",
      "  Cheq (UNSEEN): 0/4 = 0.000\n",
      "    ❌ ERRORS (4):\n",
      "      Script 7412576: predicted=0, actual=1, confidence=0.275\n",
      "      Script 7413032: predicted=0, actual=1, confidence=0.185\n",
      "      Script 7410200: predicted=0, actual=1, confidence=0.246\n",
      "      Script 7417129: predicted=0, actual=1, confidence=0.281\n",
      "  Datadome (UNSEEN): 1/1 = 1.000\n",
      "    ✅ No errors\n",
      "  Forter (SEEN): 14/15 = 0.933\n",
      "    ❌ ERRORS (1):\n",
      "      Script 7402161: predicted=0, actual=1, confidence=0.170\n",
      "  Human (SEEN): 7/8 = 0.875\n",
      "    ❌ ERRORS (1):\n",
      "      Script 7403037: predicted=0, actual=1, confidence=0.232\n",
      "  Iovation (SEEN): 23/24 = 0.958\n",
      "    ❌ ERRORS (1):\n",
      "      Script 7397641: predicted=0, actual=1, confidence=0.261\n",
      "  Nudata (UNSEEN): 0/6 = 0.000\n",
      "    ❌ ERRORS (6):\n",
      "      Script 7399703: predicted=0, actual=1, confidence=0.071\n",
      "      Script 7398772: predicted=0, actual=1, confidence=0.022\n",
      "      Script 7396421: predicted=0, actual=1, confidence=0.045\n",
      "      Script 7395290: predicted=0, actual=1, confidence=0.076\n",
      "      Script 7394638: predicted=0, actual=1, confidence=0.242\n",
      "      Script 7395604: predicted=0, actual=1, confidence=0.054\n",
      "  PingOne (UNSEEN): 5/5 = 1.000\n",
      "    ✅ No errors\n",
      "  Utarget (UNSEEN): 1/1 = 1.000\n",
      "    ✅ No errors\n",
      "\n",
      "❌ FALSE POSITIVES (6):\n",
      "    Script 7406055: predicted=1, actual=0, confidence=0.924\n",
      "    Script 7392194: predicted=1, actual=0, confidence=0.607\n",
      "    Script 7399742: predicted=1, actual=0, confidence=0.802\n",
      "    Script 7392273: predicted=1, actual=0, confidence=0.607\n",
      "    Script 7399114: predicted=1, actual=0, confidence=0.887\n",
      "    Script 7399565: predicted=1, actual=0, confidence=0.887\n",
      "\n",
      "📈 FOLD SUMMARY:\n",
      "  Overall accuracy: 0.970\n",
      "  Unseen vendor accuracy: 0.389\n",
      "  Total errors: 20\n",
      "\n",
      "============================================================\n",
      "FOLD 4/5\n",
      "============================================================\n",
      "Training vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Callsign', 'Datadome', 'Forter', 'GroupIB', 'Human', 'Iovation', 'PingOne', 'Sardine', 'Utarget']\n",
      "Test vendors: ['Cheq', 'Feedzai', 'Nudata', 'Threatmark', 'Transmit', 'Yofi']\n",
      "\n",
      "📊 VENDOR PERFORMANCE BREAKDOWN:\n",
      "  BioCatch (SEEN): 6/6 = 1.000\n",
      "    ✅ No errors\n",
      "  Cheq (UNSEEN): 0/4 = 0.000\n",
      "    ❌ ERRORS (4):\n",
      "      Script 7412576: predicted=0, actual=1, confidence=0.298\n",
      "      Script 7413032: predicted=0, actual=1, confidence=0.284\n",
      "      Script 7410200: predicted=0, actual=1, confidence=0.341\n",
      "      Script 7417129: predicted=0, actual=1, confidence=0.314\n",
      "  Feedzai (UNSEEN): 0/2 = 0.000\n",
      "    ❌ ERRORS (2):\n",
      "      Script 7406593: predicted=0, actual=1, confidence=0.341\n",
      "      Script 7404903: predicted=0, actual=1, confidence=0.408\n",
      "  Forter (SEEN): 15/15 = 1.000\n",
      "    ✅ No errors\n",
      "  Human (SEEN): 5/8 = 0.625\n",
      "    ❌ ERRORS (3):\n",
      "      Script 7412613: predicted=0, actual=1, confidence=0.383\n",
      "      Script 7403910: predicted=0, actual=1, confidence=0.491\n",
      "      Script 7403037: predicted=0, actual=1, confidence=0.254\n",
      "  Iovation (SEEN): 24/24 = 1.000\n",
      "    ✅ No errors\n",
      "  Nudata (UNSEEN): 0/6 = 0.000\n",
      "    ❌ ERRORS (6):\n",
      "      Script 7399703: predicted=0, actual=1, confidence=0.257\n",
      "      Script 7398772: predicted=0, actual=1, confidence=0.050\n",
      "      Script 7396421: predicted=0, actual=1, confidence=0.043\n",
      "      Script 7395290: predicted=0, actual=1, confidence=0.144\n",
      "      Script 7394638: predicted=0, actual=1, confidence=0.264\n",
      "      Script 7395604: predicted=0, actual=1, confidence=0.051\n",
      "  Threatmark (UNSEEN): 1/1 = 1.000\n",
      "    ✅ No errors\n",
      "  Transmit (UNSEEN): 0/2 = 0.000\n",
      "    ❌ ERRORS (2):\n",
      "      Script 7403362: predicted=0, actual=1, confidence=0.482\n",
      "      Script 7407709: predicted=0, actual=1, confidence=0.481\n",
      "  Yofi (UNSEEN): 8/8 = 1.000\n",
      "    ✅ No errors\n",
      "\n",
      "❌ FALSE POSITIVES (9):\n",
      "    Script 7399114: predicted=1, actual=0, confidence=0.602\n",
      "    Script 7399529: predicted=1, actual=0, confidence=0.793\n",
      "    Script 7412821: predicted=1, actual=0, confidence=0.957\n",
      "    Script 7395905: predicted=1, actual=0, confidence=0.994\n",
      "    Script 7411552: predicted=1, actual=0, confidence=0.655\n",
      "    Script 7392215: predicted=1, actual=0, confidence=0.557\n",
      "    Script 7392289: predicted=1, actual=0, confidence=0.560\n",
      "    Script 7392194: predicted=1, actual=0, confidence=0.557\n",
      "    Script 7412042: predicted=1, actual=0, confidence=0.525\n",
      "\n",
      "📈 FOLD SUMMARY:\n",
      "  Overall accuracy: 0.961\n",
      "  Unseen vendor accuracy: 0.391\n",
      "  Total errors: 26\n",
      "\n",
      "============================================================\n",
      "FOLD 5/5\n",
      "============================================================\n",
      "Training vendors: ['Behaviosec', 'BioCatch', 'Datadome', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'Threatmark', 'Transmit', 'Utarget', 'Yofi']\n",
      "Test vendors: ['Accertify', 'Callsign', 'Cheq', 'Feedzai', 'PingOne', 'Sardine']\n",
      "\n",
      "📊 VENDOR PERFORMANCE BREAKDOWN:\n",
      "  Accertify (UNSEEN): 0/3 = 0.000\n",
      "    ❌ ERRORS (3):\n",
      "      Script 7403113: predicted=0, actual=1, confidence=0.001\n",
      "      Script 7396662: predicted=0, actual=1, confidence=0.001\n",
      "      Script 7407196: predicted=0, actual=1, confidence=0.001\n",
      "  BioCatch (SEEN): 6/6 = 1.000\n",
      "    ✅ No errors\n",
      "  Callsign (UNSEEN): 0/1 = 0.000\n",
      "    ❌ ERRORS (1):\n",
      "      Script 7413095: predicted=0, actual=1, confidence=0.381\n",
      "  Cheq (UNSEEN): 0/4 = 0.000\n",
      "    ❌ ERRORS (4):\n",
      "      Script 7412576: predicted=0, actual=1, confidence=0.371\n",
      "      Script 7413032: predicted=0, actual=1, confidence=0.341\n",
      "      Script 7410200: predicted=0, actual=1, confidence=0.379\n",
      "      Script 7417129: predicted=0, actual=1, confidence=0.405\n",
      "  Feedzai (UNSEEN): 0/2 = 0.000\n",
      "    ❌ ERRORS (2):\n",
      "      Script 7406593: predicted=0, actual=1, confidence=0.449\n",
      "      Script 7404903: predicted=0, actual=1, confidence=0.487\n",
      "  Forter (SEEN): 15/15 = 1.000\n",
      "    ✅ No errors\n",
      "  Human (SEEN): 6/8 = 0.750\n",
      "    ❌ ERRORS (2):\n",
      "      Script 7412870: predicted=0, actual=1, confidence=0.318\n",
      "      Script 7403037: predicted=0, actual=1, confidence=0.218\n",
      "  Iovation (SEEN): 24/24 = 1.000\n",
      "    ✅ No errors\n",
      "  PingOne (UNSEEN): 5/5 = 1.000\n",
      "    ✅ No errors\n",
      "  Sardine (UNSEEN): 2/6 = 0.333\n",
      "    ❌ ERRORS (4):\n",
      "      Script 7397523: predicted=0, actual=1, confidence=0.342\n",
      "      Script 7400006: predicted=0, actual=1, confidence=0.025\n",
      "      Script 7397588: predicted=0, actual=1, confidence=0.499\n",
      "      Script 7401805: predicted=0, actual=1, confidence=0.342\n",
      "\n",
      "❌ FALSE POSITIVES (8):\n",
      "    Script 7392289: predicted=1, actual=0, confidence=0.555\n",
      "    Script 7392031: predicted=1, actual=0, confidence=0.542\n",
      "    Script 7399565: predicted=1, actual=0, confidence=0.737\n",
      "    Script 7411552: predicted=1, actual=0, confidence=0.636\n",
      "    Script 7406163: predicted=1, actual=0, confidence=0.621\n",
      "    Script 7399114: predicted=1, actual=0, confidence=0.737\n",
      "    Script 7395582: predicted=1, actual=0, confidence=0.523\n",
      "    Script 7395579: predicted=1, actual=0, confidence=0.770\n",
      "\n",
      "📈 FOLD SUMMARY:\n",
      "  Overall accuracy: 0.964\n",
      "  Unseen vendor accuracy: 0.333\n",
      "  Total errors: 24\n",
      "\n",
      "================================================================================\n",
      "QUICK ERROR SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total errors tracked: 69\n",
      "Most problematic vendors:\n",
      "  Sardine: 16 errors\n",
      "  Cheq: 12 errors\n",
      "  Nudata: 12 errors\n",
      "  Human: 9 errors\n",
      "  Accertify: 6 errors\n",
      "  Transmit: 6 errors\n",
      "  Feedzai: 4 errors\n",
      "  Callsign: 2 errors\n",
      "  Forter: 1 errors\n",
      "  Iovation: 1 errors\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed Detailed Vendor Misclassification Analysis\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "\n",
    "def vendor_aware_cv_with_detailed_errors(features_df, model, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Vendor-aware CV with detailed error tracking by vendor and script\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    \n",
    "    # Get positive samples with vendors\n",
    "    positive_samples = features_df[features_df['label'] == 1].copy()\n",
    "    negative_samples = features_df[features_df['label'] == 0].copy()\n",
    "    \n",
    "    # Categorize vendors by volume\n",
    "    vendor_counts = positive_samples['vendor'].value_counts()\n",
    "    high_volume_vendors = vendor_counts[vendor_counts > 20].index.tolist()\n",
    "    medium_volume_vendors = vendor_counts[(vendor_counts >= 5) & (vendor_counts <= 20)].index.tolist()\n",
    "    low_volume_vendors = vendor_counts[vendor_counts < 5].index.tolist()\n",
    "    \n",
    "    print(f\"Vendor categories:\")\n",
    "    print(f\"  High volume (>20): {high_volume_vendors}\")\n",
    "    print(f\"  Medium volume (5-20): {medium_volume_vendors}\")\n",
    "    print(f\"  Low volume (<5): {low_volume_vendors}\")\n",
    "    \n",
    "    fold_results = []\n",
    "    all_vendor_errors = []\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"FOLD {fold + 1}/{n_splits}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Set random seed for this fold\n",
    "        fold_seed = random_state + fold\n",
    "        np.random.seed(fold_seed)\n",
    "        \n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        \n",
    "        # HIGH VOLUME VENDORS: Split scripts within vendor\n",
    "        for vendor in high_volume_vendors:\n",
    "            vendor_scripts = positive_samples[positive_samples['vendor'] == vendor].index.tolist()\n",
    "            np.random.shuffle(vendor_scripts)\n",
    "            \n",
    "            n_test = max(1, int(len(vendor_scripts) * 0.3))\n",
    "            test_indices.extend(vendor_scripts[:n_test])\n",
    "            train_indices.extend(vendor_scripts[n_test:])\n",
    "        \n",
    "        # MEDIUM VOLUME VENDORS: Rotate vendors\n",
    "        if len(medium_volume_vendors) > 0:\n",
    "            np.random.shuffle(medium_volume_vendors)\n",
    "            n_train_vendors = max(1, int(len(medium_volume_vendors) * 0.6))\n",
    "            \n",
    "            rotation = fold % len(medium_volume_vendors)\n",
    "            rotated_vendors = medium_volume_vendors[rotation:] + medium_volume_vendors[:rotation]\n",
    "            \n",
    "            train_medium = rotated_vendors[:n_train_vendors]\n",
    "            test_medium = rotated_vendors[n_train_vendors:]\n",
    "        else:\n",
    "            train_medium = []\n",
    "            test_medium = []\n",
    "        \n",
    "        for vendor in train_medium:\n",
    "            train_indices.extend(positive_samples[positive_samples['vendor'] == vendor].index.tolist())\n",
    "        \n",
    "        for vendor in test_medium:\n",
    "            test_indices.extend(positive_samples[positive_samples['vendor'] == vendor].index.tolist())\n",
    "        \n",
    "        # LOW VOLUME VENDORS: Rotate vendors\n",
    "        if len(low_volume_vendors) > 0:\n",
    "            np.random.shuffle(low_volume_vendors)\n",
    "            n_test_low = len(low_volume_vendors) // 2\n",
    "            \n",
    "            low_rotation = fold % len(low_volume_vendors)\n",
    "            rotated_low = low_volume_vendors[low_rotation:] + low_volume_vendors[:low_rotation]\n",
    "            \n",
    "            test_low = rotated_low[:n_test_low]\n",
    "            train_low = rotated_low[n_test_low:]\n",
    "        else:\n",
    "            test_low = []\n",
    "            train_low = []\n",
    "        \n",
    "        for vendor in train_low:\n",
    "            train_indices.extend(positive_samples[positive_samples['vendor'] == vendor].index.tolist())\n",
    "        \n",
    "        for vendor in test_low:\n",
    "            test_indices.extend(positive_samples[positive_samples['vendor'] == vendor].index.tolist())\n",
    "        \n",
    "        # NEGATIVE SAMPLES: Random split\n",
    "        neg_indices = negative_samples.index.tolist()\n",
    "        np.random.shuffle(neg_indices)\n",
    "        n_test_neg = int(len(neg_indices) * 0.3)\n",
    "        \n",
    "        train_indices.extend(neg_indices[n_test_neg:])\n",
    "        test_indices.extend(neg_indices[:n_test_neg])\n",
    "        \n",
    "        # Create train/test sets for this fold\n",
    "        X_train_fold = features_df.loc[train_indices, feature_cols]\n",
    "        y_train_fold = features_df.loc[train_indices, 'label']\n",
    "        X_test_fold = features_df.loc[test_indices, feature_cols]\n",
    "        y_test_fold = features_df.loc[test_indices, 'label']\n",
    "        \n",
    "        fold_weights = create_vendor_weights_fixed(features_df, train_indices)\n",
    "        # Train model\n",
    "        fold_model = clone(model)\n",
    "        fold_model.fit(X_train_fold, y_train_fold, sample_weight=fold_weights)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred_fold = fold_model.predict(X_test_fold)\n",
    "        y_proba_fold = fold_model.predict_proba(X_test_fold)[:, 1]\n",
    "        fold_accuracy = fold_model.score(X_test_fold, y_test_fold)\n",
    "        fold_roc = roc_auc_score(y_test_fold, y_proba_fold)\n",
    "        \n",
    "        # Create detailed test results\n",
    "        test_df_fold = features_df.loc[test_indices].copy()\n",
    "        test_df_fold['predictions'] = y_pred_fold\n",
    "        test_df_fold['pred_proba'] = y_proba_fold\n",
    "        test_df_fold['correct'] = (test_df_fold['predictions'] == test_df_fold['label'])\n",
    "        \n",
    "        # Identify training vendors for this fold\n",
    "        train_vendors = set(high_volume_vendors)  # High volume always partially in training\n",
    "        train_vendors.update(train_medium)\n",
    "        train_vendors.update(train_low)\n",
    "        \n",
    "        print(f\"Training vendors: {sorted(train_vendors)}\")\n",
    "        print(f\"Test vendors: {sorted(test_medium + test_low)}\")\n",
    "        \n",
    "        # DETAILED VENDOR ANALYSIS\n",
    "        print(f\"\\n📊 VENDOR PERFORMANCE BREAKDOWN:\")\n",
    "        \n",
    "        vendor_errors_fold = []\n",
    "        test_positives = test_df_fold[test_df_fold['label'] == 1]\n",
    "        \n",
    "        for vendor in sorted(test_positives['vendor'].unique()):\n",
    "            vendor_data = test_positives[test_positives['vendor'] == vendor]\n",
    "            vendor_correct = vendor_data['correct'].sum()\n",
    "            vendor_total = len(vendor_data)\n",
    "            vendor_accuracy = vendor_correct / vendor_total\n",
    "            \n",
    "            # Determine if vendor was seen in training\n",
    "            vendor_status = \"SEEN\" if vendor in train_vendors else \"UNSEEN\"\n",
    "            \n",
    "            print(f\"  {vendor} ({vendor_status}): {vendor_correct}/{vendor_total} = {vendor_accuracy:.3f}\")\n",
    "            \n",
    "            # Track errors for this vendor\n",
    "            vendor_errors = vendor_data[~vendor_data['correct']]\n",
    "            \n",
    "            if len(vendor_errors) > 0:\n",
    "                print(f\"    ❌ ERRORS ({len(vendor_errors)}):\")\n",
    "                for _, error_script in vendor_errors.iterrows():\n",
    "                    confidence = error_script['pred_proba']\n",
    "                    script_id = error_script['script_id']\n",
    "                    print(f\"      Script {script_id}: predicted={error_script['predictions']}, \"\n",
    "                          f\"actual={error_script['label']}, confidence={confidence:.3f}\")\n",
    "                \n",
    "                # Store error details\n",
    "                for _, error_script in vendor_errors.iterrows():\n",
    "                    vendor_errors_fold.append({\n",
    "                        'fold': fold + 1,\n",
    "                        'vendor': vendor,\n",
    "                        'vendor_status': vendor_status,\n",
    "                        'script_id': error_script['script_id'],\n",
    "                        'true_label': error_script['label'],\n",
    "                        'predicted_label': error_script['predictions'],\n",
    "                        'confidence': error_script['pred_proba'],\n",
    "                        'vendor_accuracy': vendor_accuracy,\n",
    "                        'vendor_size': vendor_total\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"    ✅ No errors\")\n",
    "        \n",
    "        # FALSE POSITIVES (negatives predicted as positives)\n",
    "        false_positives = test_df_fold[(test_df_fold['label'] == 0) & (test_df_fold['predictions'] == 1)]\n",
    "        if len(false_positives) > 0:\n",
    "            print(f\"\\n❌ FALSE POSITIVES ({len(false_positives)}):\")\n",
    "            for _, fp_script in false_positives.iterrows():\n",
    "                confidence = fp_script['pred_proba']\n",
    "                script_id = fp_script['script_id']\n",
    "                print(f\"    Script {script_id}: predicted=1, actual=0, confidence={confidence:.3f}\")\n",
    "        \n",
    "        # Store overall fold results\n",
    "        unseen_vendors = [v for v in test_medium + test_low if v not in train_vendors]\n",
    "        seen_vendors = [v for v in test_positives['vendor'].unique() if v in train_vendors]\n",
    "        \n",
    "        if unseen_vendors:\n",
    "            unseen_data = test_positives[test_positives['vendor'].isin(unseen_vendors)]\n",
    "            unseen_accuracy = unseen_data['correct'].mean()\n",
    "        else:\n",
    "            unseen_accuracy = np.nan\n",
    "        \n",
    "        if seen_vendors:\n",
    "            seen_data = test_positives[test_positives['vendor'].isin(seen_vendors)]\n",
    "            seen_accuracy = seen_data['correct'].mean()\n",
    "        else:\n",
    "            seen_accuracy = np.nan\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold + 1,\n",
    "            'overall_accuracy': fold_accuracy,\n",
    "            'roc_auc': fold_roc,\n",
    "            'unseen_vendor_accuracy': unseen_accuracy,\n",
    "            'seen_vendor_accuracy': seen_accuracy,\n",
    "            'total_errors': len(test_df_fold[~test_df_fold['correct']]),\n",
    "            'false_positives': len(false_positives),\n",
    "            'false_negatives': len(test_df_fold[(test_df_fold['label'] == 1) & (test_df_fold['predictions'] == 0)])\n",
    "        })\n",
    "        \n",
    "        all_vendor_errors.extend(vendor_errors_fold)\n",
    "        \n",
    "        print(f\"\\n📈 FOLD SUMMARY:\")\n",
    "        print(f\"  Overall accuracy: {fold_accuracy:.3f}\")\n",
    "        \n",
    "        # Fixed formatting for unseen accuracy\n",
    "        if not np.isnan(unseen_accuracy):\n",
    "            print(f\"  Unseen vendor accuracy: {unseen_accuracy:.3f}\")\n",
    "        else:\n",
    "            print(f\"  Unseen vendor accuracy: N/A\")\n",
    "            \n",
    "        print(f\"  Total errors: {len(test_df_fold[~test_df_fold['correct']])}\")\n",
    "    \n",
    "    return pd.DataFrame(fold_results), pd.DataFrame(all_vendor_errors)\n",
    "\n",
    "# Run detailed analysis\n",
    "print(\"=== DETAILED VENDOR-AWARE CV WITH ERROR TRACKING ===\")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=15, min_samples_split=5,\n",
    "    min_samples_leaf=2, random_state=42, class_weight='balanced'\n",
    ")\n",
    "\n",
    "cv_results, error_details = vendor_aware_cv_with_detailed_errors(\n",
    "    binary_df, rf_model, n_splits=5, random_state=42\n",
    ")\n",
    "\n",
    "# Immediate error summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"QUICK ERROR SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "if len(error_details) > 0:\n",
    "    print(f\"\\nTotal errors tracked: {len(error_details)}\")\n",
    "    print(f\"Most problematic vendors:\")\n",
    "    vendor_error_counts = error_details['vendor'].value_counts()\n",
    "    for vendor, count in vendor_error_counts.head(10).items():\n",
    "        print(f\"  {vendor}: {count} errors\")\n",
    "else:\n",
    "    print(\"No errors to analyze!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_id</th>\n",
       "      <th>label</th>\n",
       "      <th>vendor</th>\n",
       "      <th>fp_approach_diversity</th>\n",
       "      <th>collection_intensity</th>\n",
       "      <th>sophistication_score</th>\n",
       "      <th>uses_audio_fp</th>\n",
       "      <th>uses_canvas_fp</th>\n",
       "      <th>collection_method_diversity</th>\n",
       "      <th>tracks_coordinates</th>\n",
       "      <th>interaction_diversity</th>\n",
       "      <th>tracks_timing</th>\n",
       "      <th>tracks_device_motion</th>\n",
       "      <th>complexity_tier</th>\n",
       "      <th>is_fp_heavy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7392023</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7392036</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7392015</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7392039</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7392076</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>7403607</td>\n",
       "      <td>1</td>\n",
       "      <td>Iovation</td>\n",
       "      <td>4</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>7402719</td>\n",
       "      <td>1</td>\n",
       "      <td>Forter</td>\n",
       "      <td>3</td>\n",
       "      <td>3.130435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>7406891</td>\n",
       "      <td>1</td>\n",
       "      <td>Iovation</td>\n",
       "      <td>4</td>\n",
       "      <td>2.347826</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>7394204</td>\n",
       "      <td>1</td>\n",
       "      <td>Iovation</td>\n",
       "      <td>4</td>\n",
       "      <td>2.804878</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>7396798</td>\n",
       "      <td>1</td>\n",
       "      <td>Iovation</td>\n",
       "      <td>4</td>\n",
       "      <td>2.347826</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2229 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      script_id  label    vendor  fp_approach_diversity  collection_intensity  \\\n",
       "0       7392023      0  negative                      0              1.500000   \n",
       "1       7392036      0  negative                      1              2.000000   \n",
       "2       7392015      0  negative                      0              1.800000   \n",
       "3       7392039      0  negative                      0              1.571429   \n",
       "4       7392076      0  negative                      1              2.000000   \n",
       "...         ...    ...       ...                    ...                   ...   \n",
       "2224    7403607      1  Iovation                      4              2.111111   \n",
       "2225    7402719      1    Forter                      3              3.130435   \n",
       "2226    7406891      1  Iovation                      4              2.347826   \n",
       "2227    7394204      1  Iovation                      4              2.804878   \n",
       "2228    7396798      1  Iovation                      4              2.347826   \n",
       "\n",
       "      sophistication_score  uses_audio_fp  uses_canvas_fp  \\\n",
       "0                        1              0               0   \n",
       "1                        0              0               0   \n",
       "2                        1              0               0   \n",
       "3                        0              0               0   \n",
       "4                        1              0               0   \n",
       "...                    ...            ...             ...   \n",
       "2224                     3              1               1   \n",
       "2225                     1              0               1   \n",
       "2226                     3              1               1   \n",
       "2227                     1              1               1   \n",
       "2228                     3              1               1   \n",
       "\n",
       "      collection_method_diversity  tracks_coordinates  interaction_diversity  \\\n",
       "0                               0                   1                      3   \n",
       "1                               0                   0                      1   \n",
       "2                               0                   0                      3   \n",
       "3                               0                   0                      3   \n",
       "4                               0                   0                      1   \n",
       "...                           ...                 ...                    ...   \n",
       "2224                            0                   1                      3   \n",
       "2225                            3                   1                      2   \n",
       "2226                            0                   1                      5   \n",
       "2227                            0                   1                      5   \n",
       "2228                            0                   1                      5   \n",
       "\n",
       "      tracks_timing  tracks_device_motion  complexity_tier  is_fp_heavy  \n",
       "0                 0                     0                2            0  \n",
       "1                 0                     0                1            0  \n",
       "2                 1                     0                3            0  \n",
       "3                 0                     0                2            0  \n",
       "4                 1                     0                1            0  \n",
       "...             ...                   ...              ...          ...  \n",
       "2224              1                     1                3            0  \n",
       "2225              0                     0                3            1  \n",
       "2226              1                     1                3            0  \n",
       "2227              0                     0                3            0  \n",
       "2228              1                     1                3            0  \n",
       "\n",
       "[2229 rows x 15 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "🔧 HYPERPARAMETER TUNING WITH NESTED CV\n",
      "============================================================\n",
      "📋 Strategy:\n",
      "   1. Use ONLY training data for hyperparameter tuning\n",
      "   2. Inner CV: Find best parameters\n",
      "   3. Outer CV: Evaluate performance with best parameters\n",
      "   4. Final model: Train on all training data with best parameters\n",
      "   5. Test set: Used ONLY for final unbiased evaluation\n",
      "\n",
      "Splitting 232 positives and 1997 negatives...\n",
      "High volume vendor 'Iovation': 81 scripts -> 57 train, 24 test\n",
      "High volume vendor 'Forter': 53 scripts -> 38 train, 15 test\n",
      "High volume vendor 'Human': 27 scripts -> 19 train, 8 test\n",
      "High volume vendor 'BioCatch': 21 scripts -> 15 train, 6 test\n",
      "Medium volume vendor 'PingOne': 5 scripts -> all to train\n",
      "Medium volume vendor 'Nudata': 6 scripts -> all to train\n",
      "Medium volume vendor 'Yofi': 8 scripts -> all to train\n",
      "Medium volume vendor 'Sardine': 6 scripts -> all to test\n",
      "Medium volume vendor 'Behaviosec': 9 scripts -> all to test\n",
      "Low volume vendor 'Cheq': 4 scripts -> all to train\n",
      "Low volume vendor 'Callsign': 1 scripts -> all to train\n",
      "Low volume vendor 'Feedzai': 2 scripts -> all to train\n",
      "Low volume vendor 'Threatmark': 1 scripts -> all to train\n",
      "Low volume vendor 'GroupIB': 1 scripts -> all to train\n",
      "Low volume vendor 'Utarget': 1 scripts -> all to test\n",
      "Low volume vendor 'Accertify': 3 scripts -> all to test\n",
      "Low volume vendor 'Datadome': 1 scripts -> all to test\n",
      "Low volume vendor 'Transmit': 2 scripts -> all to test\n",
      "\n",
      "Final split:\n",
      "Train: 157 positives + 1398 negatives = 1555 total\n",
      "Test: 75 positives + 599 negatives = 674 total\n",
      "Training data: (1555, 12)\n",
      "Test data: (674, 12)\n",
      "Features: 12\n",
      "\n",
      "🎯 STEP 1: Defining Hyperparameter Grid\n",
      "----------------------------------------\n",
      "   n_estimators: [50, 100, 200]\n",
      "   max_depth: [10, 15, 20, None]\n",
      "   min_samples_split: [2, 5, 10]\n",
      "   min_samples_leaf: [1, 2, 4]\n",
      "   max_features: ['sqrt', 'log2', None]\n",
      "   class_weight: ['balanced', None]\n",
      "\n",
      "Total parameter combinations: 648\n",
      "⚠️  This will take some time - using 3-fold CV for speed\n",
      "\n",
      "🔧 STEP 2: Nested Cross-Validation Setup\n",
      "----------------------------------------\n",
      "Outer CV: 3 folds (performance evaluation)\n",
      "Inner CV: 3 folds (hyperparameter selection)\n",
      "Total model fits: 3 × 648 × 3 = 5,832\n",
      "\n",
      "🚀 STEP 3: Running Nested Cross-Validation\n",
      "----------------------------------------\n",
      "\n",
      "📊 Outer Fold 1/3\n",
      "   Inner training: 1036 samples\n",
      "   Outer validation: 519 samples\n",
      "   🏭 Vendor Analysis (Fold 1):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   🔍 Running grid search...\n",
      "   ✅ Best inner CV score: 0.9969\n",
      "   🎯 Best parameters: {'class_weight': 'balanced', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "   📈 Overall validation score: 0.9968\n",
      "   👁️  Seen vendor accuracy: 0.9623\n",
      "\n",
      "📊 Outer Fold 2/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 2):\n",
      "      Training vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Callsign', 'Cheq', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (8)\n",
      "      Unseen vendors: ['Callsign', 'GroupIB', 'Threatmark'] (3)\n",
      "   🔍 Running grid search...\n",
      "   ✅ Best inner CV score: 0.9961\n",
      "   🎯 Best parameters: {'class_weight': None, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "   📈 Overall validation score: 0.9978\n",
      "   👁️  Seen vendor accuracy: 0.9388\n",
      "   🆕 Unseen vendor accuracy: 0.6667\n",
      "\n",
      "📊 Outer Fold 3/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 3):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   🔍 Running grid search...\n",
      "   ✅ Best inner CV score: 0.9980\n",
      "   🎯 Best parameters: {'class_weight': None, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "   📈 Overall validation score: 0.9952\n",
      "   👁️  Seen vendor accuracy: 0.9423\n",
      "\n",
      "⏱️  Nested CV completed in 0.8 minutes\n",
      "\n",
      "📊 STEP 4: Nested CV Results Analysis\n",
      "----------------------------------------\n",
      "Nested CV Performance: 0.9966 ± 0.0011\n",
      "Individual fold scores: ['0.9968', '0.9978', '0.9952']\n",
      "\n",
      "🔍 Parameter Selection Frequency:\n",
      "   class_weight:\n",
      "      None: 2/3 folds\n",
      "      balanced: 1/3 folds\n",
      "   max_depth:\n",
      "      10: 3/3 folds\n",
      "   max_features:\n",
      "      sqrt: 3/3 folds\n",
      "   min_samples_leaf:\n",
      "      2: 2/3 folds\n",
      "      1: 1/3 folds\n",
      "   min_samples_split:\n",
      "      2: 2/3 folds\n",
      "      5: 1/3 folds\n",
      "   n_estimators:\n",
      "      50: 1/3 folds\n",
      "      200: 1/3 folds\n",
      "      100: 1/3 folds\n",
      "\n",
      "🎯 STEP 5: Final Parameter Selection\n",
      "----------------------------------------\n",
      "Final parameters (most frequent): {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': None}\n",
      "\n",
      "🔧 Alternative: Grid search on full training data\n",
      "Alternative parameters: {'class_weight': 'balanced', 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Alternative CV score: 0.9974\n",
      "\n",
      "✅ Using alternative parameters (similar performance, simpler approach)\n",
      "\n",
      "🏁 FINAL MODEL TRAINING AND EVALUATION\n",
      "==================================================\n",
      "Splitting 232 positives and 1997 negatives...\n",
      "High volume vendor 'Iovation': 81 scripts -> 57 train, 24 test\n",
      "High volume vendor 'Forter': 53 scripts -> 38 train, 15 test\n",
      "High volume vendor 'Human': 27 scripts -> 19 train, 8 test\n",
      "High volume vendor 'BioCatch': 21 scripts -> 15 train, 6 test\n",
      "Medium volume vendor 'PingOne': 5 scripts -> all to train\n",
      "Medium volume vendor 'Nudata': 6 scripts -> all to train\n",
      "Medium volume vendor 'Yofi': 8 scripts -> all to train\n",
      "Medium volume vendor 'Sardine': 6 scripts -> all to test\n",
      "Medium volume vendor 'Behaviosec': 9 scripts -> all to test\n",
      "Low volume vendor 'Cheq': 4 scripts -> all to train\n",
      "Low volume vendor 'Callsign': 1 scripts -> all to train\n",
      "Low volume vendor 'Feedzai': 2 scripts -> all to train\n",
      "Low volume vendor 'Threatmark': 1 scripts -> all to train\n",
      "Low volume vendor 'GroupIB': 1 scripts -> all to train\n",
      "Low volume vendor 'Utarget': 1 scripts -> all to test\n",
      "Low volume vendor 'Accertify': 3 scripts -> all to test\n",
      "Low volume vendor 'Datadome': 1 scripts -> all to test\n",
      "Low volume vendor 'Transmit': 2 scripts -> all to test\n",
      "\n",
      "Final split:\n",
      "Train: 157 positives + 1398 negatives = 1555 total\n",
      "Test: 75 positives + 599 negatives = 674 total\n",
      "Training final model with parameters: {'class_weight': 'balanced', 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Using sample weights for vendor balancing: ✅\n",
      "\n",
      "📈 FINAL TEST SET PERFORMANCE:\n",
      "   Accuracy: 0.9674\n",
      "   ROC AUC: 0.9755\n",
      "\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       599\n",
      "           1       0.92      0.77      0.84        75\n",
      "\n",
      "    accuracy                           0.97       674\n",
      "   macro avg       0.95      0.88      0.91       674\n",
      "weighted avg       0.97      0.97      0.97       674\n",
      "\n",
      "\n",
      "🏭 FINAL TEST SET VENDOR ANALYSIS:\n",
      "--------------------------------------------------\n",
      "Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "Test vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Datadome', 'Forter', 'Human', 'Iovation', 'Sardine', 'Transmit', 'Utarget']\n",
      "Seen vendors in test: ['BioCatch', 'Forter', 'Human', 'Iovation'] (4)\n",
      "Unseen vendors in test: ['Accertify', 'Behaviosec', 'Datadome', 'Sardine', 'Transmit', 'Utarget'] (6)\n",
      "\n",
      "👁️  SEEN VENDOR PERFORMANCE:\n",
      "   Overall seen vendor accuracy: 0.9245\n",
      "   BioCatch: 1.0000 (6 samples)\n",
      "   Forter: 1.0000 (15 samples)\n",
      "   Human: 0.7500 (8 samples)\n",
      "   Iovation: 0.9167 (24 samples)\n",
      "\n",
      "🆕 UNSEEN VENDOR PERFORMANCE:\n",
      "   Overall unseen vendor accuracy: 0.4091\n",
      "   Accertify: 0.0000 (3 samples)\n",
      "   Behaviosec: 0.7778 (9 samples)\n",
      "   Datadome: 1.0000 (1 samples)\n",
      "   Sardine: 0.0000 (6 samples)\n",
      "   Transmit: 0.0000 (2 samples)\n",
      "   Utarget: 1.0000 (1 samples)\n",
      "\n",
      "📊 VENDOR PERFORMANCE SUMMARY:\n",
      "   Seen vendors: 0.9245\n",
      "   Unseen vendors: 0.4091\n",
      "   Performance gap (seen - unseen): +0.5154\n",
      "   ❌ Large generalization gap - features may be vendor-specific\n",
      "\n",
      "🎉 HYPERPARAMETER TUNING COMPLETE!\n",
      "   Nested CV Score: 0.9966 ± 0.0011\n",
      "   Final Test Accuracy: 0.9674\n",
      "   Final Test AUC: 0.9755\n",
      "   Best Parameters: {'class_weight': 'balanced', 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "   Final Seen Vendor Accuracy: 0.9245\n",
      "   Final Unseen Vendor Accuracy: 0.4091\n",
      "\n",
      "📊 VENDOR GENERALIZATION ANALYSIS:\n",
      "========================================\n",
      "This analysis shows how well your model generalizes to:\n",
      "- SEEN vendors: Vendors present in training (with different scripts)\n",
      "- UNSEEN vendors: Vendors completely absent from training\n",
      "Good generalization = small gap between seen and unseen performance\n"
     ]
    }
   ],
   "source": [
    "# Cell: Hyperparameter Tuning with Nested Cross-Validation (Fixed)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import time\n",
    "\n",
    "def hyperparameter_tuning_nested_cv(features_df, selected_features, \n",
    "                                   target_col='label', metadata_cols=['script_id', 'label', 'vendor'],\n",
    "                                   random_state=42):\n",
    "    \"\"\"\n",
    "    Proper hyperparameter tuning using nested CV on training data only\n",
    "    \n",
    "    Outer loop: Evaluates model performance\n",
    "    Inner loop: Selects best hyperparameters\n",
    "    Test set: Never touches hyperparameter selection\n",
    "    \"\"\"\n",
    "    print(\"🔧 HYPERPARAMETER TUNING WITH NESTED CV\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"📋 Strategy:\")\n",
    "    print(\"   1. Use ONLY training data for hyperparameter tuning\")\n",
    "    print(\"   2. Inner CV: Find best parameters\")\n",
    "    print(\"   3. Outer CV: Evaluate performance with best parameters\")\n",
    "    print(\"   4. Final model: Train on all training data with best parameters\")\n",
    "    print(\"   5. Test set: Used ONLY for final unbiased evaluation\")\n",
    "    print()\n",
    "    \n",
    "    # Get your existing vendor-aware split\n",
    "    train_idx, test_idx, split_info = create_vendor_aware_split(features_df)\n",
    "    \n",
    "    # Extract training data only\n",
    "    X_train_full = features_df.loc[train_idx, selected_features].copy()\n",
    "    y_train_full = features_df.loc[train_idx, target_col].copy()\n",
    "    X_test = features_df.loc[test_idx, selected_features].copy()\n",
    "    y_test = features_df.loc[test_idx, target_col].copy()\n",
    "    \n",
    "    print(f\"Training data: {X_train_full.shape}\")\n",
    "    print(f\"Test data: {X_test.shape}\")\n",
    "    print(f\"Features: {len(selected_features)}\")\n",
    "    print()\n",
    "    \n",
    "    # Define Hyperparameter Grid\n",
    "    print(\"🎯 STEP 1: Defining Hyperparameter Grid\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [10, 15, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'class_weight': ['balanced', None]\n",
    "    }\n",
    "    \n",
    "    # Calculate total combinations\n",
    "    total_combinations = 1\n",
    "    for param, values in param_grid.items():\n",
    "        total_combinations *= len(values)\n",
    "        print(f\"   {param}: {values}\")\n",
    "    \n",
    "    print(f\"\\nTotal parameter combinations: {total_combinations}\")\n",
    "    print(\"⚠️  This will take some time - using 3-fold CV for speed\")\n",
    "    \n",
    "    # Nested Cross-Validation Setup\n",
    "    print(f\"\\n🔧 STEP 2: Nested Cross-Validation Setup\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Outer CV: Evaluates model performance (fewer folds for speed)\n",
    "    outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Inner CV: Selects best hyperparameters\n",
    "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state + 1)\n",
    "    \n",
    "    print(f\"Outer CV: {outer_cv.n_splits} folds (performance evaluation)\")\n",
    "    print(f\"Inner CV: {inner_cv.n_splits} folds (hyperparameter selection)\")\n",
    "    print(f\"Total model fits: {outer_cv.n_splits} × {total_combinations} × {inner_cv.n_splits} = {outer_cv.n_splits * total_combinations * inner_cv.n_splits:,}\")\n",
    "    \n",
    "    # Run Nested Cross-Validation\n",
    "    print(f\"\\n🚀 STEP 3: Running Nested Cross-Validation\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Store results\n",
    "    nested_scores = []\n",
    "    best_params_per_fold = []\n",
    "    vendor_analysis_per_fold = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for fold, (train_idx_inner, val_idx_inner) in enumerate(outer_cv.split(X_train_full, y_train_full)):\n",
    "        print(f\"\\n📊 Outer Fold {fold + 1}/{outer_cv.n_splits}\")\n",
    "        \n",
    "        # Split training data for this outer fold\n",
    "        X_train_inner = X_train_full.iloc[train_idx_inner]\n",
    "        y_train_inner = y_train_full.iloc[train_idx_inner]\n",
    "        X_val_outer = X_train_full.iloc[val_idx_inner]\n",
    "        y_val_outer = y_train_full.iloc[val_idx_inner]\n",
    "        \n",
    "        print(f\"   Inner training: {X_train_inner.shape[0]} samples\")\n",
    "        print(f\"   Outer validation: {X_val_outer.shape[0]} samples\")\n",
    "        \n",
    "        # Analyze vendor distribution for this fold\n",
    "        # Convert to actual DataFrame indices\n",
    "        actual_train_indices = [train_idx[i] for i in train_idx_inner]\n",
    "        actual_val_indices = [train_idx[i] for i in val_idx_inner]\n",
    "        \n",
    "        train_df_inner = features_df.loc[actual_train_indices]\n",
    "        val_df_outer = features_df.loc[actual_val_indices]\n",
    "        \n",
    "        # Get vendors in training and validation for this fold\n",
    "        train_positives_inner = train_df_inner[train_df_inner[target_col] == 1]\n",
    "        val_positives_outer = val_df_outer[val_df_outer[target_col] == 1]\n",
    "        \n",
    "        train_vendors_fold = set(train_positives_inner['vendor'].dropna().unique())\n",
    "        val_vendors_fold = set(val_positives_outer['vendor'].dropna().unique())\n",
    "        \n",
    "        # Classify vendors as seen/unseen for this fold\n",
    "        seen_vendors_fold = val_vendors_fold.intersection(train_vendors_fold)\n",
    "        unseen_vendors_fold = val_vendors_fold - train_vendors_fold\n",
    "        \n",
    "        print(f\"   🏭 Vendor Analysis (Fold {fold + 1}):\")\n",
    "        print(f\"      Training vendors: {sorted(train_vendors_fold)}\")\n",
    "        print(f\"      Validation vendors: {sorted(val_vendors_fold)}\")\n",
    "        print(f\"      Seen vendors: {sorted(seen_vendors_fold)} ({len(seen_vendors_fold)})\")\n",
    "        print(f\"      Unseen vendors: {sorted(unseen_vendors_fold)} ({len(unseen_vendors_fold)})\")\n",
    "        \n",
    "        # Inner CV: Grid Search for best parameters\n",
    "        rf_inner = RandomForestClassifier(random_state=random_state, n_jobs=-1)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=rf_inner,\n",
    "            param_grid=param_grid,\n",
    "            cv=inner_cv,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        print(f\"   🔍 Running grid search...\")\n",
    "        grid_search.fit(X_train_inner, y_train_inner)\n",
    "        \n",
    "        # Get best parameters for this fold\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score_inner = grid_search.best_score_\n",
    "        best_params_per_fold.append(best_params)\n",
    "        \n",
    "        print(f\"   ✅ Best inner CV score: {best_score_inner:.4f}\")\n",
    "        print(f\"   🎯 Best parameters: {best_params}\")\n",
    "        \n",
    "        # Evaluate on outer validation set\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred_outer_proba = best_model.predict_proba(X_val_outer)[:, 1]\n",
    "        y_pred_outer = best_model.predict(X_val_outer)\n",
    "        outer_score = roc_auc_score(y_val_outer, y_pred_outer_proba)\n",
    "        nested_scores.append(outer_score)\n",
    "        \n",
    "        # Calculate vendor-specific accuracies for this fold\n",
    "        val_df_with_preds = val_df_outer.copy()\n",
    "        val_df_with_preds['predictions'] = y_pred_outer\n",
    "        val_positives_with_preds = val_df_with_preds[val_df_with_preds[target_col] == 1]\n",
    "        \n",
    "        seen_accuracy = None\n",
    "        unseen_accuracy = None\n",
    "        \n",
    "        if seen_vendors_fold:\n",
    "            seen_data = val_positives_with_preds[val_positives_with_preds['vendor'].isin(seen_vendors_fold)]\n",
    "            if len(seen_data) > 0:\n",
    "                seen_accuracy = (seen_data['predictions'] == seen_data[target_col]).mean()\n",
    "        \n",
    "        if unseen_vendors_fold:\n",
    "            unseen_data = val_positives_with_preds[val_positives_with_preds['vendor'].isin(unseen_vendors_fold)]\n",
    "            if len(unseen_data) > 0:\n",
    "                unseen_accuracy = (unseen_data['predictions'] == unseen_data[target_col]).mean()\n",
    "        \n",
    "        print(f\"   📈 Overall validation score: {outer_score:.4f}\")\n",
    "        if seen_accuracy is not None:\n",
    "            print(f\"   👁️  Seen vendor accuracy: {seen_accuracy:.4f}\")\n",
    "        if unseen_accuracy is not None:\n",
    "            print(f\"   🆕 Unseen vendor accuracy: {unseen_accuracy:.4f}\")\n",
    "        \n",
    "        # Store vendor analysis\n",
    "        vendor_analysis_per_fold.append({\n",
    "            'fold': fold + 1,\n",
    "            'train_vendors': sorted(train_vendors_fold),\n",
    "            'val_vendors': sorted(val_vendors_fold),\n",
    "            'seen_vendors': sorted(seen_vendors_fold),\n",
    "            'unseen_vendors': sorted(unseen_vendors_fold),\n",
    "            'n_seen': len(seen_vendors_fold),\n",
    "            'n_unseen': len(unseen_vendors_fold),\n",
    "            'seen_accuracy': seen_accuracy,\n",
    "            'unseen_accuracy': unseen_accuracy,\n",
    "            'overall_score': outer_score\n",
    "        })\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"\\n⏱️  Nested CV completed in {elapsed_time/60:.1f} minutes\")\n",
    "    \n",
    "    # Analyze Results\n",
    "    print(f\"\\n📊 STEP 4: Nested CV Results Analysis\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    nested_cv_mean = np.mean(nested_scores)\n",
    "    nested_cv_std = np.std(nested_scores)\n",
    "    \n",
    "    print(f\"Nested CV Performance: {nested_cv_mean:.4f} ± {nested_cv_std:.4f}\")\n",
    "    print(f\"Individual fold scores: {[f'{score:.4f}' for score in nested_scores]}\")\n",
    "    \n",
    "    # Analyze parameter frequency\n",
    "    print(f\"\\n🔍 Parameter Selection Frequency:\")\n",
    "    param_counts = {}\n",
    "    for params in best_params_per_fold:\n",
    "        for param, value in params.items():\n",
    "            if param not in param_counts:\n",
    "                param_counts[param] = {}\n",
    "            if value not in param_counts[param]:\n",
    "                param_counts[param][value] = 0\n",
    "            param_counts[param][value] += 1\n",
    "    \n",
    "    for param, value_counts in param_counts.items():\n",
    "        print(f\"   {param}:\")\n",
    "        for value, count in sorted(value_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"      {value}: {count}/{len(best_params_per_fold)} folds\")\n",
    "    \n",
    "    # Select Final Best Parameters\n",
    "    print(f\"\\n🎯 STEP 5: Final Parameter Selection\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Method 1: Most frequent parameters across folds\n",
    "    final_params = {}\n",
    "    for param in param_grid.keys():\n",
    "        values = [params[param] for params in best_params_per_fold]\n",
    "        # Get most frequent value\n",
    "        final_params[param] = max(set(values), key=values.count)\n",
    "    \n",
    "    print(f\"Final parameters (most frequent): {final_params}\")\n",
    "    \n",
    "    # Method 2: Run one final grid search on ALL training data for comparison\n",
    "    print(f\"\\n🔧 Alternative: Grid search on full training data\")\n",
    "    rf_final_gs = RandomForestClassifier(random_state=random_state, n_jobs=-1)\n",
    "    final_grid_search = GridSearchCV(\n",
    "        estimator=rf_final_gs,\n",
    "        param_grid=param_grid,\n",
    "        cv=inner_cv,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    final_grid_search.fit(X_train_full, y_train_full)\n",
    "    alternative_params = final_grid_search.best_params_\n",
    "    alternative_score = final_grid_search.best_score_\n",
    "    \n",
    "    print(f\"Alternative parameters: {alternative_params}\")\n",
    "    print(f\"Alternative CV score: {alternative_score:.4f}\")\n",
    "    \n",
    "    # Choose between methods\n",
    "    if abs(alternative_score - nested_cv_mean) < 0.01:\n",
    "        print(f\"\\n✅ Using alternative parameters (similar performance, simpler approach)\")\n",
    "        chosen_params = alternative_params\n",
    "    else:\n",
    "        print(f\"\\n✅ Using nested CV parameters (more robust)\")\n",
    "        chosen_params = final_params\n",
    "    \n",
    "    return chosen_params, nested_cv_mean, nested_cv_std, best_params_per_fold\n",
    "\n",
    "def train_final_model(features_df, selected_features, best_params, \n",
    "                     target_col='label', random_state=42):\n",
    "    \"\"\"\n",
    "    Train final model with best parameters and evaluate on test set\n",
    "    \"\"\"\n",
    "    print(f\"\\n🏁 FINAL MODEL TRAINING AND EVALUATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get your splits again\n",
    "    train_idx, test_idx, split_info = create_vendor_aware_split(features_df)\n",
    "    \n",
    "    X_train = features_df.loc[train_idx, selected_features]\n",
    "    y_train = features_df.loc[train_idx, target_col]\n",
    "    X_test = features_df.loc[test_idx, selected_features]\n",
    "    y_test = features_df.loc[test_idx, target_col]\n",
    "    \n",
    "    # Add sample weights for vendor balancing\n",
    "    sample_weights = create_vendor_weights_fixed(features_df, train_idx)\n",
    "    \n",
    "    print(f\"Training final model with parameters: {best_params}\")\n",
    "    print(f\"Using sample weights for vendor balancing: ✅\")\n",
    "    \n",
    "    # Train final model\n",
    "    final_rf = RandomForestClassifier(**best_params, random_state=random_state, n_jobs=-1)\n",
    "    final_rf.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = final_rf.predict(X_test)\n",
    "    y_pred_proba = final_rf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    test_accuracy = final_rf.score(X_test, y_test)\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\n📈 FINAL TEST SET PERFORMANCE:\")\n",
    "    print(f\"   Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"   ROC AUC: {test_auc:.4f}\")\n",
    "    \n",
    "    print(f\"\\n📋 Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Detailed vendor analysis for final test set\n",
    "    print(f\"\\n🏭 FINAL TEST SET VENDOR ANALYSIS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get vendor information for test set\n",
    "    train_df = features_df.loc[train_idx]\n",
    "    test_df = features_df.loc[test_idx]\n",
    "    \n",
    "    train_positives = train_df[train_df[target_col] == 1]\n",
    "    test_positives = test_df[test_df[target_col] == 1]\n",
    "    \n",
    "    train_vendors = set(train_positives['vendor'].dropna().unique())\n",
    "    test_vendors = set(test_positives['vendor'].dropna().unique())\n",
    "    \n",
    "    # Classify test vendors as seen/unseen\n",
    "    seen_test_vendors = test_vendors.intersection(train_vendors)\n",
    "    unseen_test_vendors = test_vendors - train_vendors\n",
    "    \n",
    "    print(f\"Training vendors: {sorted(train_vendors)}\")\n",
    "    print(f\"Test vendors: {sorted(test_vendors)}\")\n",
    "    print(f\"Seen vendors in test: {sorted(seen_test_vendors)} ({len(seen_test_vendors)})\")\n",
    "    print(f\"Unseen vendors in test: {sorted(unseen_test_vendors)} ({len(unseen_test_vendors)})\")\n",
    "    \n",
    "    # Calculate vendor-specific accuracies\n",
    "    test_df_with_preds = test_df.copy()\n",
    "    test_df_with_preds['predictions'] = y_pred\n",
    "    test_positives_with_preds = test_df_with_preds[test_df_with_preds[target_col] == 1]\n",
    "    \n",
    "    seen_test_accuracy = None\n",
    "    unseen_test_accuracy = None\n",
    "    \n",
    "    if seen_test_vendors:\n",
    "        seen_test_data = test_positives_with_preds[test_positives_with_preds['vendor'].isin(seen_test_vendors)]\n",
    "        if len(seen_test_data) > 0:\n",
    "            seen_test_accuracy = (seen_test_data['predictions'] == seen_test_data[target_col]).mean()\n",
    "            print(f\"\\n👁️  SEEN VENDOR PERFORMANCE:\")\n",
    "            print(f\"   Overall seen vendor accuracy: {seen_test_accuracy:.4f}\")\n",
    "            \n",
    "            # Individual seen vendor performance\n",
    "            for vendor in sorted(seen_test_vendors):\n",
    "                vendor_data = seen_test_data[seen_test_data['vendor'] == vendor]\n",
    "                vendor_accuracy = (vendor_data['predictions'] == vendor_data[target_col]).mean()\n",
    "                vendor_count = len(vendor_data)\n",
    "                print(f\"   {vendor}: {vendor_accuracy:.4f} ({vendor_count} samples)\")\n",
    "    \n",
    "    if unseen_test_vendors:\n",
    "        unseen_test_data = test_positives_with_preds[test_positives_with_preds['vendor'].isin(unseen_test_vendors)]\n",
    "        if len(unseen_test_data) > 0:\n",
    "            unseen_test_accuracy = (unseen_test_data['predictions'] == unseen_test_data[target_col]).mean()\n",
    "            print(f\"\\n🆕 UNSEEN VENDOR PERFORMANCE:\")\n",
    "            print(f\"   Overall unseen vendor accuracy: {unseen_test_accuracy:.4f}\")\n",
    "            \n",
    "            # Individual unseen vendor performance\n",
    "            for vendor in sorted(unseen_test_vendors):\n",
    "                vendor_data = unseen_test_data[unseen_test_data['vendor'] == vendor]\n",
    "                vendor_accuracy = (vendor_data['predictions'] == vendor_data[target_col]).mean()\n",
    "                vendor_count = len(vendor_data)\n",
    "                print(f\"   {vendor}: {vendor_accuracy:.4f} ({vendor_count} samples)\")\n",
    "    \n",
    "    # Summary comparison\n",
    "    print(f\"\\n📊 VENDOR PERFORMANCE SUMMARY:\")\n",
    "    if seen_test_accuracy is not None:\n",
    "        print(f\"   Seen vendors: {seen_test_accuracy:.4f}\")\n",
    "    if unseen_test_accuracy is not None:\n",
    "        print(f\"   Unseen vendors: {unseen_test_accuracy:.4f}\")\n",
    "    if seen_test_accuracy is not None and unseen_test_accuracy is not None:\n",
    "        performance_gap = seen_test_accuracy - unseen_test_accuracy\n",
    "        print(f\"   Performance gap (seen - unseen): {performance_gap:+.4f}\")\n",
    "        \n",
    "        if performance_gap < 0.05:\n",
    "            print(f\"   ✅ Good generalization to unseen vendors!\")\n",
    "        elif performance_gap < 0.15:\n",
    "            print(f\"   ⚠️  Moderate generalization gap\")\n",
    "        else:\n",
    "            print(f\"   ❌ Large generalization gap - features may be vendor-specific\")\n",
    "    \n",
    "    return final_rf, test_accuracy, test_auc, seen_test_accuracy, unseen_test_accuracy\n",
    "\n",
    "# ================================================================= \n",
    "# RUN HYPERPARAMETER TUNING\n",
    "# =================================================================\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "\n",
    "# Run nested CV hyperparameter tuning\n",
    "best_params, cv_mean, cv_std, all_fold_params = hyperparameter_tuning_nested_cv(\n",
    "    agnostic_features_df, \n",
    "    feature_cols,  # Use your selected features\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train final model\n",
    "final_model, final_accuracy, final_auc, seen_acc, unseen_acc = train_final_model(\n",
    "    agnostic_features_df,\n",
    "    feature_cols,\n",
    "    best_params,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n🎉 HYPERPARAMETER TUNING COMPLETE!\")\n",
    "print(f\"   Nested CV Score: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "print(f\"   Final Test Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"   Final Test AUC: {final_auc:.4f}\")\n",
    "print(f\"   Best Parameters: {best_params}\")\n",
    "\n",
    "if seen_acc is not None:\n",
    "    print(f\"   Final Seen Vendor Accuracy: {seen_acc:.4f}\")\n",
    "if unseen_acc is not None:\n",
    "    print(f\"   Final Unseen Vendor Accuracy: {unseen_acc:.4f}\")\n",
    "\n",
    "print(f\"\\n📊 VENDOR GENERALIZATION ANALYSIS:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"This analysis shows how well your model generalizes to:\")\n",
    "print(\"- SEEN vendors: Vendors present in training (with different scripts)\")\n",
    "print(\"- UNSEEN vendors: Vendors completely absent from training\")\n",
    "print(\"Good generalization = small gap between seen and unseen performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: xgboost in /home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages (3.0.2)\n",
      "Requirement already satisfied: lightgbm in /home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy in /home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages (from xgboost) (2.21.5)\n",
      "Requirement already satisfied: scipy in /home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages (from xgboost) (1.15.2)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters: Random Forest {'class_weight': 'balanced', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 MULTI-MODEL HYPERPARAMETER TUNING\n",
      "============================================================\n",
      "🎯 Testing 7 models: ['naive_bayes', 'logistic_regression', 'random_forest', 'xgboost', 'lightgbm', 'gradient_boosting', 'svm_rbf']\n",
      "📊 Quick mode: OFF\n",
      "\n",
      "Splitting 232 positives and 1997 negatives...\n",
      "High volume vendor 'Iovation': 81 scripts -> 57 train, 24 test\n",
      "High volume vendor 'Forter': 53 scripts -> 38 train, 15 test\n",
      "High volume vendor 'Human': 27 scripts -> 19 train, 8 test\n",
      "High volume vendor 'BioCatch': 21 scripts -> 15 train, 6 test\n",
      "Medium volume vendor 'PingOne': 5 scripts -> all to train\n",
      "Medium volume vendor 'Nudata': 6 scripts -> all to train\n",
      "Medium volume vendor 'Yofi': 8 scripts -> all to train\n",
      "Medium volume vendor 'Sardine': 6 scripts -> all to test\n",
      "Medium volume vendor 'Behaviosec': 9 scripts -> all to test\n",
      "Low volume vendor 'Cheq': 4 scripts -> all to train\n",
      "Low volume vendor 'Callsign': 1 scripts -> all to train\n",
      "Low volume vendor 'Feedzai': 2 scripts -> all to train\n",
      "Low volume vendor 'Threatmark': 1 scripts -> all to train\n",
      "Low volume vendor 'GroupIB': 1 scripts -> all to train\n",
      "Low volume vendor 'Utarget': 1 scripts -> all to test\n",
      "Low volume vendor 'Accertify': 3 scripts -> all to test\n",
      "Low volume vendor 'Datadome': 1 scripts -> all to test\n",
      "Low volume vendor 'Transmit': 2 scripts -> all to test\n",
      "\n",
      "Final split:\n",
      "Train: 157 positives + 1398 negatives = 1555 total\n",
      "Test: 75 positives + 599 negatives = 674 total\n",
      "Training data: (1555, 12)\n",
      "Test data: (674, 12)\n",
      "Features: 12\n",
      "\n",
      "\n",
      "============================================================\n",
      "🔧 MODEL 1/7: NAIVE_BAYES\n",
      "============================================================\n",
      "📝 Assumes feature independence\n",
      "🔧 Needs scaling: False\n",
      "⚖️  Supports sample weights: True\n",
      "🎯 Parameter combinations: 5\n",
      "⏱️  Estimated fits: 45\n",
      "\n",
      "📊 Fold 1/3\n",
      "   Inner training: 1036 samples\n",
      "   Outer validation: 519 samples\n",
      "   🏭 Vendor Analysis (Fold 1):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   ✅ Best inner CV: 0.9795\n",
      "   📈 Overall validation score: 0.9826\n",
      "   👁️  Seen vendor accuracy: 0.9811\n",
      "   ⏱️  Fold time: 0.0 min\n",
      "\n",
      "📊 Fold 2/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 2):\n",
      "      Training vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Callsign', 'Cheq', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (8)\n",
      "      Unseen vendors: ['Callsign', 'GroupIB', 'Threatmark'] (3)\n",
      "   ✅ Best inner CV: 0.9802\n",
      "   📈 Overall validation score: 0.9825\n",
      "   👁️  Seen vendor accuracy: 1.0000\n",
      "   🆕 Unseen vendor accuracy: 1.0000\n",
      "   ⏱️  Fold time: 0.0 min\n",
      "\n",
      "📊 Fold 3/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 3):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   ✅ Best inner CV: 0.9774\n",
      "   📈 Overall validation score: 0.9735\n",
      "   👁️  Seen vendor accuracy: 0.9423\n",
      "   ⏱️  Fold time: 0.0 min\n",
      "\n",
      "📊 NAIVE_BAYES RESULTS:\n",
      "   Nested CV: 0.9795 ± 0.0043\n",
      "   Fold scores: ['0.9826', '0.9825', '0.9735']\n",
      "   Total time: 0.0 minutes\n",
      "\n",
      "============================================================\n",
      "🔧 MODEL 2/7: LOGISTIC_REGRESSION\n",
      "============================================================\n",
      "📝 Linear model, needs feature scaling\n",
      "🔧 Needs scaling: True\n",
      "⚖️  Supports sample weights: True\n",
      "🎯 Parameter combinations: 80\n",
      "⏱️  Estimated fits: 720\n",
      "🔧 Logistic Regression: Created 50 valid parameter combinations\n",
      "\n",
      "📊 Fold 1/3\n",
      "   Inner training: 1036 samples\n",
      "   Outer validation: 519 samples\n",
      "   🏭 Vendor Analysis (Fold 1):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Best inner CV: 0.9898\n",
      "   📈 Overall validation score: 0.9894\n",
      "   👁️  Seen vendor accuracy: 0.9623\n",
      "   ⏱️  Fold time: 0.0 min\n",
      "\n",
      "📊 Fold 2/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 2):\n",
      "      Training vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Callsign', 'Cheq', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (8)\n",
      "      Unseen vendors: ['Callsign', 'GroupIB', 'Threatmark'] (3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Best inner CV: 0.9901\n",
      "   📈 Overall validation score: 0.9942\n",
      "   👁️  Seen vendor accuracy: 0.9796\n",
      "   🆕 Unseen vendor accuracy: 0.6667\n",
      "   ⏱️  Fold time: 0.0 min\n",
      "\n",
      "📊 Fold 3/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 3):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/a8tariq/.conda/envs/vv8/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Best inner CV: 0.9942\n",
      "   📈 Overall validation score: 0.9832\n",
      "   👁️  Seen vendor accuracy: 0.9231\n",
      "   ⏱️  Fold time: 0.0 min\n",
      "\n",
      "📊 LOGISTIC_REGRESSION RESULTS:\n",
      "   Nested CV: 0.9889 ± 0.0045\n",
      "   Fold scores: ['0.9894', '0.9942', '0.9832']\n",
      "   Total time: 0.0 minutes\n",
      "\n",
      "============================================================\n",
      "🔧 MODEL 3/7: RANDOM_FOREST\n",
      "============================================================\n",
      "📝 Tree-based, handles mixed data well\n",
      "🔧 Needs scaling: False\n",
      "⚖️  Supports sample weights: True\n",
      "🎯 Parameter combinations: 648\n",
      "⏱️  Estimated fits: 5,832\n",
      "\n",
      "📊 Fold 1/3\n",
      "   Inner training: 1036 samples\n",
      "   Outer validation: 519 samples\n",
      "   🏭 Vendor Analysis (Fold 1):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   ✅ Best inner CV: 0.9967\n",
      "   📈 Overall validation score: 0.9965\n",
      "   👁️  Seen vendor accuracy: 0.9623\n",
      "   ⏱️  Fold time: 0.1 min\n",
      "\n",
      "📊 Fold 2/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 2):\n",
      "      Training vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Callsign', 'Cheq', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (8)\n",
      "      Unseen vendors: ['Callsign', 'GroupIB', 'Threatmark'] (3)\n",
      "   ✅ Best inner CV: 0.9960\n",
      "   📈 Overall validation score: 0.9983\n",
      "   👁️  Seen vendor accuracy: 0.9388\n",
      "   🆕 Unseen vendor accuracy: 0.6667\n",
      "   ⏱️  Fold time: 0.1 min\n",
      "\n",
      "📊 Fold 3/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 3):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   ✅ Best inner CV: 0.9978\n",
      "   📈 Overall validation score: 0.9947\n",
      "   👁️  Seen vendor accuracy: 0.9231\n",
      "   ⏱️  Fold time: 0.1 min\n",
      "\n",
      "📊 RANDOM_FOREST RESULTS:\n",
      "   Nested CV: 0.9965 ± 0.0015\n",
      "   Fold scores: ['0.9965', '0.9983', '0.9947']\n",
      "   Total time: 0.4 minutes\n",
      "\n",
      "============================================================\n",
      "🔧 MODEL 4/7: XGBOOST\n",
      "============================================================\n",
      "📝 Gradient boosting, often best performance\n",
      "🔧 Needs scaling: False\n",
      "⚖️  Supports sample weights: True\n",
      "🎯 Parameter combinations: 2187\n",
      "⏱️  Estimated fits: 19,683\n",
      "\n",
      "📊 Fold 1/3\n",
      "   Inner training: 1036 samples\n",
      "   Outer validation: 519 samples\n",
      "   🏭 Vendor Analysis (Fold 1):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   ✅ Best inner CV: 0.9955\n",
      "   📈 Overall validation score: 0.9961\n",
      "   👁️  Seen vendor accuracy: 0.9434\n",
      "   ⏱️  Fold time: 0.2 min\n",
      "\n",
      "📊 Fold 2/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 2):\n",
      "      Training vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Callsign', 'Cheq', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (8)\n",
      "      Unseen vendors: ['Callsign', 'GroupIB', 'Threatmark'] (3)\n",
      "   ✅ Best inner CV: 0.9955\n",
      "   📈 Overall validation score: 0.9929\n",
      "   👁️  Seen vendor accuracy: 0.9388\n",
      "   🆕 Unseen vendor accuracy: 0.6667\n",
      "   ⏱️  Fold time: 0.2 min\n",
      "\n",
      "📊 Fold 3/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 3):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   ✅ Best inner CV: 0.9951\n",
      "   📈 Overall validation score: 0.9927\n",
      "   👁️  Seen vendor accuracy: 0.8846\n",
      "   ⏱️  Fold time: 0.2 min\n",
      "\n",
      "📊 XGBOOST RESULTS:\n",
      "   Nested CV: 0.9939 ± 0.0016\n",
      "   Fold scores: ['0.9961', '0.9929', '0.9927']\n",
      "   Total time: 0.7 minutes\n",
      "\n",
      "============================================================\n",
      "🔧 MODEL 5/7: LIGHTGBM\n",
      "============================================================\n",
      "📝 Fast gradient boosting, simplified for small datasets\n",
      "🔧 Needs scaling: False\n",
      "⚖️  Supports sample weights: True\n",
      "🎯 Parameter combinations: 512\n",
      "⏱️  Estimated fits: 4,608\n",
      "⚠️  LightGBM estimated time: ~38.4 minutes\n",
      "🔧 Using simplified parameter grid and single-threaded models\n",
      "\n",
      "📊 Fold 1/3\n",
      "   Inner training: 1036 samples\n",
      "   Outer validation: 519 samples\n",
      "   🏭 Vendor Analysis (Fold 1):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "Fitting 3 folds for each of 512 candidates, totalling 1536 fits\n",
      "   ✅ Best inner CV: 0.9962\n",
      "   📈 Overall validation score: 0.9947\n",
      "   👁️  Seen vendor accuracy: 0.8868\n",
      "   ⏱️  Fold time: 0.8 min\n",
      "\n",
      "📊 Fold 2/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 2):\n",
      "      Training vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Callsign', 'Cheq', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (8)\n",
      "      Unseen vendors: ['Callsign', 'GroupIB', 'Threatmark'] (3)\n",
      "Fitting 3 folds for each of 512 candidates, totalling 1536 fits\n",
      "   ✅ Best inner CV: 0.9958\n",
      "   📈 Overall validation score: 0.9967\n",
      "   👁️  Seen vendor accuracy: 0.9592\n",
      "   🆕 Unseen vendor accuracy: 0.6667\n",
      "   ⏱️  Fold time: 0.8 min\n",
      "\n",
      "📊 Fold 3/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 3):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "Fitting 3 folds for each of 512 candidates, totalling 1536 fits\n",
      "   ✅ Best inner CV: 0.9964\n",
      "   📈 Overall validation score: 0.9933\n",
      "   👁️  Seen vendor accuracy: 0.9231\n",
      "   ⏱️  Fold time: 0.8 min\n",
      "\n",
      "📊 LIGHTGBM RESULTS:\n",
      "   Nested CV: 0.9949 ± 0.0014\n",
      "   Fold scores: ['0.9947', '0.9967', '0.9933']\n",
      "   Total time: 2.4 minutes\n",
      "\n",
      "============================================================\n",
      "🔧 MODEL 6/7: GRADIENT_BOOSTING\n",
      "============================================================\n",
      "📝 Sklearn gradient boosting\n",
      "🔧 Needs scaling: False\n",
      "⚖️  Supports sample weights: True\n",
      "🎯 Parameter combinations: 243\n",
      "⏱️  Estimated fits: 2,187\n",
      "\n",
      "📊 Fold 1/3\n",
      "   Inner training: 1036 samples\n",
      "   Outer validation: 519 samples\n",
      "   🏭 Vendor Analysis (Fold 1):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   ✅ Best inner CV: 0.9957\n",
      "   📈 Overall validation score: 0.9966\n",
      "   👁️  Seen vendor accuracy: 0.9057\n",
      "   ⏱️  Fold time: 0.1 min\n",
      "\n",
      "📊 Fold 2/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 2):\n",
      "      Training vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Callsign', 'Cheq', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (8)\n",
      "      Unseen vendors: ['Callsign', 'GroupIB', 'Threatmark'] (3)\n",
      "   ✅ Best inner CV: 0.9959\n",
      "   📈 Overall validation score: 0.9974\n",
      "   👁️  Seen vendor accuracy: 0.8980\n",
      "   🆕 Unseen vendor accuracy: 0.6667\n",
      "   ⏱️  Fold time: 0.1 min\n",
      "\n",
      "📊 Fold 3/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 3):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   ✅ Best inner CV: 0.9978\n",
      "   📈 Overall validation score: 0.9937\n",
      "   👁️  Seen vendor accuracy: 0.9038\n",
      "   ⏱️  Fold time: 0.2 min\n",
      "\n",
      "📊 GRADIENT_BOOSTING RESULTS:\n",
      "   Nested CV: 0.9959 ± 0.0016\n",
      "   Fold scores: ['0.9966', '0.9974', '0.9937']\n",
      "   Total time: 0.4 minutes\n",
      "\n",
      "============================================================\n",
      "🔧 MODEL 7/7: SVM_RBF\n",
      "============================================================\n",
      "📝 RBF kernel SVM, needs scaling, slower\n",
      "🔧 Needs scaling: True\n",
      "⚖️  Supports sample weights: True\n",
      "🎯 Parameter combinations: 40\n",
      "⏱️  Estimated fits: 360\n",
      "\n",
      "📊 Fold 1/3\n",
      "   Inner training: 1036 samples\n",
      "   Outer validation: 519 samples\n",
      "   🏭 Vendor Analysis (Fold 1):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   ✅ Best inner CV: 0.9934\n",
      "   📈 Overall validation score: 0.9915\n",
      "   👁️  Seen vendor accuracy: 0.9434\n",
      "   ⏱️  Fold time: 0.0 min\n",
      "\n",
      "📊 Fold 2/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 2):\n",
      "      Training vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Callsign', 'Cheq', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (8)\n",
      "      Unseen vendors: ['Callsign', 'GroupIB', 'Threatmark'] (3)\n",
      "   ✅ Best inner CV: 0.9936\n",
      "   📈 Overall validation score: 0.9955\n",
      "   👁️  Seen vendor accuracy: 0.9592\n",
      "   🆕 Unseen vendor accuracy: 0.6667\n",
      "   ⏱️  Fold time: 0.0 min\n",
      "\n",
      "📊 Fold 3/3\n",
      "   Inner training: 1037 samples\n",
      "   Outer validation: 518 samples\n",
      "   🏭 Vendor Analysis (Fold 3):\n",
      "      Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "      Validation vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi']\n",
      "      Seen vendors: ['BioCatch', 'Cheq', 'Feedzai', 'Forter', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Yofi'] (9)\n",
      "      Unseen vendors: [] (0)\n",
      "   ✅ Best inner CV: 0.9943\n",
      "   📈 Overall validation score: 0.9872\n",
      "   👁️  Seen vendor accuracy: 0.9423\n",
      "   ⏱️  Fold time: 0.0 min\n",
      "\n",
      "📊 SVM_RBF RESULTS:\n",
      "   Nested CV: 0.9914 ± 0.0034\n",
      "   Fold scores: ['0.9915', '0.9955', '0.9872']\n",
      "   Total time: 0.0 minutes\n",
      "\n",
      "============================================================\n",
      "🏆 MODEL COMPARISON SUMMARY\n",
      "============================================================\n",
      "Rank Model                CV Score     Std      Time(min) \n",
      "------------------------------------------------------------\n",
      "1    random_forest        0.9965      0.0015      0.4\n",
      "2    gradient_boosting    0.9959      0.0016      0.4\n",
      "3    lightgbm             0.9949      0.0014      2.4\n",
      "4    xgboost              0.9939      0.0016      0.7\n",
      "5    svm_rbf              0.9914      0.0034      0.0\n",
      "6    logistic_regression  0.9889      0.0045      0.0\n",
      "7    naive_bayes          0.9795      0.0043      0.0\n",
      "\n",
      "🥇 BEST MODEL: RANDOM_FOREST\n",
      "   Score: 0.9965 ± 0.0015\n",
      "   Parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "# Multi-Model Hyperparameter Tuning with Nested Cross-Validation\n",
    "# ASSUMES YOU HAVE YOUR EXISTING FUNCTIONS:\n",
    "# - create_vendor_aware_split()\n",
    "# - create_vendor_weights_fixed()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier  # pip install xgboost\n",
    "from lightgbm import LGBMClassifier  # pip install lightgbm\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration class for different models and their hyperparameter grids\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_model_configs():\n",
    "        \"\"\"\n",
    "        Returns dictionary of model configurations with their parameter grids\n",
    "        Each config includes: model class, param grid, needs scaling, and notes\n",
    "        \"\"\"\n",
    "        \n",
    "        configs = {\n",
    "            'random_forest': {\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [50, 100, 200],\n",
    "                    'max_depth': [10, 15, 20, None],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 4],\n",
    "                    'max_features': ['sqrt', 'log2', None],\n",
    "                    'class_weight': ['balanced', None]\n",
    "                },\n",
    "                'needs_scaling': False,\n",
    "                'supports_sample_weights': True,\n",
    "                'notes': 'Tree-based, handles mixed data well'\n",
    "            },\n",
    "            \n",
    "            'xgboost': {\n",
    "                'model': XGBClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [50, 100, 200],\n",
    "                    'max_depth': [3, 6, 10],\n",
    "                    'learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'subsample': [0.8, 0.9, 1.0],\n",
    "                    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "                    'reg_alpha': [0, 0.1, 1],\n",
    "                    'reg_lambda': [0, 0.1, 1]\n",
    "                },\n",
    "                'needs_scaling': False,\n",
    "                'supports_sample_weights': True,\n",
    "                'notes': 'Gradient boosting, often best performance'\n",
    "            },\n",
    "            \n",
    "            'lightgbm': {\n",
    "                'model': LGBMClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [50, 100],  # Reduced from [50, 100, 200]\n",
    "                    'max_depth': [3, 6],  # Reduced from [3, 6, 10]\n",
    "                    'learning_rate': [0.1, 0.2],  # Reduced from [0.05, 0.1, 0.2]\n",
    "                    'num_leaves': [15, 31],  # Reduced from [10, 20, 31]\n",
    "                    'min_child_samples': [10, 20],  # Reduced from [5, 10, 20]\n",
    "                    'class_weight': ['balanced'],  # Removed None option\n",
    "                    'verbosity': [-1],\n",
    "                    'force_col_wise': [True],\n",
    "                    'n_jobs': [1],  # Force single thread per model (let GridSearchCV handle parallelization)\n",
    "                    'feature_fraction': [0.8, 1.0],  # Add feature subsampling\n",
    "                    'bagging_fraction': [0.8, 1.0],  # Add row subsampling\n",
    "                    'bagging_freq': [0, 5],  # Bagging frequency\n",
    "                    'min_gain_to_split': [0.0, 0.1]  # Minimum gain required to split\n",
    "                },\n",
    "                'needs_scaling': False,\n",
    "                'supports_sample_weights': True,\n",
    "                'notes': 'Fast gradient boosting, simplified for small datasets'\n",
    "            },\n",
    "            \n",
    "            'gradient_boosting': {\n",
    "                'model': GradientBoostingClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [50, 100, 200],\n",
    "                    'max_depth': [3, 5, 7],\n",
    "                    'learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'subsample': [0.8, 0.9, 1.0],\n",
    "                    'max_features': ['sqrt', 'log2', None]\n",
    "                },\n",
    "                'needs_scaling': False,\n",
    "                'supports_sample_weights': True,\n",
    "                'notes': 'Sklearn gradient boosting'\n",
    "            },\n",
    "            \n",
    "            'logistic_regression': {\n",
    "                'model': LogisticRegression,\n",
    "                'params': [\n",
    "                    # L1 and L2 with liblinear\n",
    "                    {\n",
    "                        'penalty': ['l1', 'l2'],\n",
    "                        'solver': ['liblinear'],\n",
    "                        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                        'class_weight': ['balanced', None],\n",
    "                        'max_iter': [1000]\n",
    "                    },\n",
    "                    # L1, L2, and ElasticNet with saga\n",
    "                    {\n",
    "                        'penalty': ['l1', 'l2'],\n",
    "                        'solver': ['saga'],\n",
    "                        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                        'class_weight': ['balanced', None],\n",
    "                        'max_iter': [1000]\n",
    "                    },\n",
    "                    # ElasticNet only with saga\n",
    "                    {\n",
    "                        'penalty': ['elasticnet'],\n",
    "                        'solver': ['saga'],\n",
    "                        'l1_ratio': [0.1, 0.5, 0.7, 0.9],\n",
    "                        'C': [0.01, 0.1, 1, 10],\n",
    "                        'class_weight': ['balanced', None],\n",
    "                        'max_iter': [1000]\n",
    "                    }\n",
    "                ],\n",
    "                'needs_scaling': True,\n",
    "                'supports_sample_weights': True,\n",
    "                'notes': 'Linear model, needs feature scaling'\n",
    "            },\n",
    "            \n",
    "            'svm_rbf': {\n",
    "                'model': SVC,\n",
    "                'params': {\n",
    "                    'C': [0.1, 1, 10, 100],\n",
    "                    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "                    'kernel': ['rbf'],\n",
    "                    'class_weight': ['balanced', None],\n",
    "                    'probability': [True]  # Needed for predict_proba\n",
    "                },\n",
    "                'needs_scaling': True,\n",
    "                'supports_sample_weights': True,\n",
    "                'notes': 'RBF kernel SVM, needs scaling, slower'\n",
    "            },\n",
    "            \n",
    "            'svm_linear': {\n",
    "                'model': SVC,\n",
    "                'params': {\n",
    "                    'C': [0.1, 1, 10, 100],\n",
    "                    'kernel': ['linear'],\n",
    "                    'class_weight': ['balanced', None],\n",
    "                    'probability': [True]  # Needed for predict_proba\n",
    "                },\n",
    "                'needs_scaling': True,\n",
    "                'supports_sample_weights': True,\n",
    "                'notes': 'Linear SVM, faster than RBF'\n",
    "            },\n",
    "            \n",
    "            'knn': {\n",
    "                'model': KNeighborsClassifier,\n",
    "                'params': {\n",
    "                    'n_neighbors': [3, 5, 7, 11, 15],\n",
    "                    'weights': ['uniform', 'distance'],\n",
    "                    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "                    'p': [1, 2]  # For minkowski metric\n",
    "                },\n",
    "                'needs_scaling': True,\n",
    "                'supports_sample_weights': False,\n",
    "                'notes': 'Instance-based, sensitive to feature scaling'\n",
    "            },\n",
    "            \n",
    "            'naive_bayes': {\n",
    "                'model': GaussianNB,\n",
    "                'params': {\n",
    "                    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "                },\n",
    "                'needs_scaling': False,\n",
    "                'supports_sample_weights': True,\n",
    "                'notes': 'Assumes feature independence'\n",
    "            },\n",
    "            \n",
    "            'neural_network': {\n",
    "                'model': MLPClassifier,\n",
    "                'params': {\n",
    "                    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "                    'activation': ['relu', 'tanh'],\n",
    "                    'alpha': [0.0001, 0.001, 0.01],\n",
    "                    'learning_rate': ['constant', 'adaptive'],\n",
    "                    'max_iter': [500],\n",
    "                    'early_stopping': [True],\n",
    "                    'validation_fraction': [0.1]\n",
    "                },\n",
    "                'needs_scaling': True,\n",
    "                'supports_sample_weights': False,\n",
    "                'notes': 'Neural network, needs scaling, can be unstable'\n",
    "            },\n",
    "            \n",
    "            'decision_tree': {\n",
    "                'model': DecisionTreeClassifier,\n",
    "                'params': {\n",
    "                    'max_depth': [5, 10, 15, 20, None],\n",
    "                    'min_samples_split': [2, 5, 10, 20],\n",
    "                    'min_samples_leaf': [1, 2, 5, 10],\n",
    "                    'max_features': ['sqrt', 'log2', None],\n",
    "                    'class_weight': ['balanced', None]\n",
    "                },\n",
    "                'needs_scaling': False,\n",
    "                'supports_sample_weights': True,\n",
    "                'notes': 'Single tree, prone to overfitting'\n",
    "            },\n",
    "            \n",
    "            'adaboost': {\n",
    "                'model': AdaBoostClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [50, 100, 200],\n",
    "                    'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "                    'algorithm': ['SAMME', 'SAMME.R']\n",
    "                },\n",
    "                'needs_scaling': False,\n",
    "                'supports_sample_weights': True,\n",
    "                'notes': 'Adaptive boosting'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return configs\n",
    "\n",
    "def multi_model_hyperparameter_tuning(features_df, selected_features, \n",
    "                                     models_to_test=None,\n",
    "                                     target_col='label', \n",
    "                                     metadata_cols=['script_id', 'label', 'vendor'],\n",
    "                                     random_state=42, \n",
    "                                     cv_folds=3,\n",
    "                                     quick_mode=False):\n",
    "    \"\"\"\n",
    "    Run hyperparameter tuning for multiple models using nested CV\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    features_df : DataFrame\n",
    "        Your feature dataframe\n",
    "    selected_features : list\n",
    "        List of feature column names\n",
    "    models_to_test : list or None\n",
    "        List of model names to test. If None, tests a default subset\n",
    "    quick_mode : bool\n",
    "        If True, uses smaller parameter grids for faster testing\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🚀 MULTI-MODEL HYPERPARAMETER TUNING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get model configurations\n",
    "    all_configs = ModelConfig.get_model_configs()\n",
    "    \n",
    "    # Default models to test if none specified\n",
    "    if models_to_test is None:\n",
    "        if quick_mode:\n",
    "            models_to_test = ['random_forest', 'xgboost', 'logistic_regression', 'svm_linear']\n",
    "        else:\n",
    "            models_to_test = ['naive_bayes', 'logistic_regression', 'random_forest', 'xgboost', 'lightgbm', 'gradient_boosting', \n",
    "                            'svm_rbf']\n",
    "    \n",
    "    # Validate model names\n",
    "    invalid_models = [m for m in models_to_test if m not in all_configs]\n",
    "    if invalid_models:\n",
    "        print(f\"❌ Invalid model names: {invalid_models}\")\n",
    "        print(f\"Available models: {list(all_configs.keys())}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"🎯 Testing {len(models_to_test)} models: {models_to_test}\")\n",
    "    print(f\"📊 Quick mode: {'ON' if quick_mode else 'OFF'}\")\n",
    "    print()\n",
    "    \n",
    "    # Get your existing vendor-aware split\n",
    "    train_idx, test_idx, split_info = create_vendor_aware_split(features_df)\n",
    "    \n",
    "    # Extract training data\n",
    "    X_train_full = features_df.loc[train_idx, selected_features].copy()\n",
    "    y_train_full = features_df.loc[train_idx, target_col].copy()\n",
    "    X_test = features_df.loc[test_idx, selected_features].copy()\n",
    "    y_test = features_df.loc[test_idx, target_col].copy()\n",
    "    \n",
    "    print(f\"Training data: {X_train_full.shape}\")\n",
    "    print(f\"Test data: {X_test.shape}\")\n",
    "    print(f\"Features: {len(selected_features)}\")\n",
    "    print()\n",
    "    \n",
    "    # Create sample weights\n",
    "    sample_weights = create_vendor_weights_fixed(features_df, train_idx)\n",
    "    \n",
    "    # Store results for all models\n",
    "    all_results = {}\n",
    "    \n",
    "    # Cross-validation setup\n",
    "    outer_cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    inner_cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_state + 1)\n",
    "    \n",
    "    # Test each model\n",
    "    for model_idx, model_name in enumerate(models_to_test):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"🔧 MODEL {model_idx + 1}/{len(models_to_test)}: {model_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        config = all_configs[model_name]\n",
    "        model_class = config['model']\n",
    "        param_grid = config['params'].copy()\n",
    "        needs_scaling = config['needs_scaling']\n",
    "        supports_weights = config['supports_sample_weights']\n",
    "        \n",
    "        print(f\"📝 {config['notes']}\")\n",
    "        print(f\"🔧 Needs scaling: {needs_scaling}\")\n",
    "        print(f\"⚖️  Supports sample weights: {supports_weights}\")\n",
    "        \n",
    "        # Reduce parameter grid for quick mode\n",
    "        if quick_mode:\n",
    "            param_grid = {k: v[:2] if len(v) > 2 else v for k, v in param_grid.items()}\n",
    "        \n",
    "        # Calculate total combinations (after any parameter grid modifications)\n",
    "        if isinstance(param_grid, list):\n",
    "            # For list of parameter grids, sum up all combinations\n",
    "            total_combinations = 0\n",
    "            for sub_grid in param_grid:\n",
    "                sub_combinations = 1\n",
    "                for param, values in sub_grid.items():\n",
    "                    if isinstance(values, list):\n",
    "                        sub_combinations *= len(values)\n",
    "                total_combinations += sub_combinations\n",
    "        else:\n",
    "            # For single parameter grid\n",
    "            total_combinations = 1\n",
    "            for param, values in param_grid.items():\n",
    "                if isinstance(values, list):\n",
    "                    total_combinations *= len(values)\n",
    "        \n",
    "        print(f\"🎯 Parameter combinations: {total_combinations}\")\n",
    "        print(f\"⏱️  Estimated fits: {outer_cv.n_splits * total_combinations * inner_cv.n_splits:,}\")\n",
    "        \n",
    "        # Special warning for LightGBM\n",
    "        if model_name == 'lightgbm':\n",
    "            estimated_time = total_combinations * outer_cv.n_splits * inner_cv.n_splits * 0.5  # Rough estimate\n",
    "            print(f\"⚠️  LightGBM estimated time: ~{estimated_time/60:.1f} minutes\")\n",
    "            print(f\"🔧 Using simplified parameter grid and single-threaded models\")\n",
    "        \n",
    "        # Handle special parameter constraints\n",
    "        if model_name == 'logistic_regression':\n",
    "            # Create a simplified, valid parameter grid for logistic regression\n",
    "            simple_param_grid = []\n",
    "            \n",
    "            # L2 penalty with liblinear and saga\n",
    "            for C in [0.01, 0.1, 1, 10]:\n",
    "                for solver in ['liblinear', 'saga']:\n",
    "                    for class_weight in ['balanced', None]:\n",
    "                        simple_param_grid.append({\n",
    "                            'penalty': ['l2'],\n",
    "                            'solver': [solver],\n",
    "                            'C': [C],\n",
    "                            'class_weight': [class_weight],\n",
    "                            'max_iter': [1000]\n",
    "                        })\n",
    "            \n",
    "            # L1 penalty with liblinear and saga\n",
    "            for C in [0.01, 0.1, 1, 10]:\n",
    "                for solver in ['liblinear', 'saga']:\n",
    "                    for class_weight in ['balanced', None]:\n",
    "                        simple_param_grid.append({\n",
    "                            'penalty': ['l1'],\n",
    "                            'solver': [solver],\n",
    "                            'C': [C],\n",
    "                            'class_weight': [class_weight],\n",
    "                            'max_iter': [1000]\n",
    "                        })\n",
    "            \n",
    "            # ElasticNet penalty with saga only\n",
    "            if not quick_mode:  # Only include elasticnet in full mode\n",
    "                for C in [0.1, 1, 10]:\n",
    "                    for l1_ratio in [0.1, 0.5, 0.9]:\n",
    "                        for class_weight in ['balanced', None]:\n",
    "                            simple_param_grid.append({\n",
    "                                'penalty': ['elasticnet'],\n",
    "                                'solver': ['saga'],\n",
    "                                'l1_ratio': [l1_ratio],\n",
    "                                'C': [C],\n",
    "                                'class_weight': [class_weight],\n",
    "                                'max_iter': [1000]\n",
    "                            })\n",
    "            \n",
    "            param_grid = simple_param_grid\n",
    "            total_combinations = len(param_grid)\n",
    "            print(f\"🔧 Logistic Regression: Created {total_combinations} valid parameter combinations\")\n",
    "        \n",
    "        # Run nested CV\n",
    "        nested_scores = []\n",
    "        best_params_per_fold = []\n",
    "        fold_times = []\n",
    "        vendor_analysis_per_fold = []\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for fold, (train_idx_inner, val_idx_inner) in enumerate(outer_cv.split(X_train_full, y_train_full)):\n",
    "            fold_start = time.time()\n",
    "            print(f\"\\n📊 Fold {fold + 1}/{outer_cv.n_splits}\")\n",
    "            \n",
    "            # Get fold data\n",
    "            X_train_inner = X_train_full.iloc[train_idx_inner]\n",
    "            y_train_inner = y_train_full.iloc[train_idx_inner]\n",
    "            X_val_outer = X_train_full.iloc[val_idx_inner]\n",
    "            y_val_outer = y_train_full.iloc[val_idx_inner]\n",
    "            \n",
    "            print(f\"   Inner training: {X_train_inner.shape[0]} samples\")\n",
    "            print(f\"   Outer validation: {X_val_outer.shape[0]} samples\")\n",
    "            \n",
    "            # VENDOR ANALYSIS FOR THIS FOLD (same as your original code)\n",
    "            # Convert to actual DataFrame indices\n",
    "            actual_train_indices = [train_idx[i] for i in train_idx_inner]\n",
    "            actual_val_indices = [train_idx[i] for i in val_idx_inner]\n",
    "            \n",
    "            train_df_inner = features_df.loc[actual_train_indices]\n",
    "            val_df_outer = features_df.loc[actual_val_indices]\n",
    "            \n",
    "            # Get vendors in training and validation for this fold\n",
    "            train_positives_inner = train_df_inner[train_df_inner[target_col] == 1]\n",
    "            val_positives_outer = val_df_outer[val_df_outer[target_col] == 1]\n",
    "            \n",
    "            train_vendors_fold = set(train_positives_inner['vendor'].dropna().unique())\n",
    "            val_vendors_fold = set(val_positives_outer['vendor'].dropna().unique())\n",
    "            \n",
    "            # Classify vendors as seen/unseen for this fold\n",
    "            seen_vendors_fold = val_vendors_fold.intersection(train_vendors_fold)\n",
    "            unseen_vendors_fold = val_vendors_fold - train_vendors_fold\n",
    "            \n",
    "            print(f\"   🏭 Vendor Analysis (Fold {fold + 1}):\")\n",
    "            print(f\"      Training vendors: {sorted(train_vendors_fold)}\")\n",
    "            print(f\"      Validation vendors: {sorted(val_vendors_fold)}\")\n",
    "            print(f\"      Seen vendors: {sorted(seen_vendors_fold)} ({len(seen_vendors_fold)})\")\n",
    "            print(f\"      Unseen vendors: {sorted(unseen_vendors_fold)} ({len(unseen_vendors_fold)})\")\n",
    "            \n",
    "            # Get sample weights for this fold\n",
    "            fold_weights = sample_weights[train_idx_inner] if supports_weights else None\n",
    "            \n",
    "            # Apply scaling if needed\n",
    "            if needs_scaling:\n",
    "                scaler = StandardScaler()\n",
    "                X_train_inner_scaled = scaler.fit_transform(X_train_inner)\n",
    "                X_val_outer_scaled = scaler.transform(X_val_outer)\n",
    "            else:\n",
    "                X_train_inner_scaled = X_train_inner\n",
    "                X_val_outer_scaled = X_val_outer\n",
    "            \n",
    "            # Create model instance\n",
    "            model_params = {'random_state': random_state}\n",
    "            if model_name in ['xgboost']:\n",
    "                model_params['verbosity'] = 0\n",
    "                model_params['random_state'] = random_state\n",
    "            elif model_name == 'lightgbm':\n",
    "                model_params['verbosity'] = -1  # Suppress all LightGBM output\n",
    "                model_params['random_state'] = random_state\n",
    "                model_params['force_col_wise'] = True  # Better for small datasets\n",
    "            elif model_name == 'neural_network':\n",
    "                model_params['random_state'] = random_state\n",
    "            elif model_name == 'naive_bayes':\n",
    "                model_params = {}  # Naive Bayes doesn't accept random_state\n",
    "            \n",
    "            model = model_class(**model_params)\n",
    "            \n",
    "            # Grid search\n",
    "            fit_params = {}\n",
    "            if supports_weights and fold_weights is not None:\n",
    "                fit_params['sample_weight'] = fold_weights\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=inner_cv,\n",
    "                scoring='roc_auc',\n",
    "                n_jobs=-1 if model_name not in ['neural_network', 'lightgbm'] else 1,  # Limit LightGBM parallelization\n",
    "                verbose=1 if model_name == 'lightgbm' else 0  # Show progress for LightGBM\n",
    "            )\n",
    "            \n",
    "            # Fit with or without sample weights\n",
    "            if fit_params:\n",
    "                grid_search.fit(X_train_inner_scaled, y_train_inner, **fit_params)\n",
    "            else:\n",
    "                grid_search.fit(X_train_inner_scaled, y_train_inner)\n",
    "            \n",
    "            # Evaluate on outer validation\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_pred_outer_proba = best_model.predict_proba(X_val_outer_scaled)[:, 1]\n",
    "            y_pred_outer = best_model.predict(X_val_outer_scaled)\n",
    "            outer_score = roc_auc_score(y_val_outer, y_pred_outer_proba)\n",
    "            \n",
    "            # VENDOR-SPECIFIC ACCURACY CALCULATION (same as your original)\n",
    "            val_df_with_preds = val_df_outer.copy()\n",
    "            val_df_with_preds['predictions'] = y_pred_outer\n",
    "            val_positives_with_preds = val_df_with_preds[val_df_with_preds[target_col] == 1]\n",
    "            \n",
    "            seen_accuracy = None\n",
    "            unseen_accuracy = None\n",
    "            \n",
    "            if seen_vendors_fold:\n",
    "                seen_data = val_positives_with_preds[val_positives_with_preds['vendor'].isin(seen_vendors_fold)]\n",
    "                if len(seen_data) > 0:\n",
    "                    seen_accuracy = (seen_data['predictions'] == seen_data[target_col]).mean()\n",
    "            \n",
    "            if unseen_vendors_fold:\n",
    "                unseen_data = val_positives_with_preds[val_positives_with_preds['vendor'].isin(unseen_vendors_fold)]\n",
    "                if len(unseen_data) > 0:\n",
    "                    unseen_accuracy = (unseen_data['predictions'] == unseen_data[target_col]).mean()\n",
    "            \n",
    "            nested_scores.append(outer_score)\n",
    "            best_params_per_fold.append(grid_search.best_params_)\n",
    "            \n",
    "            fold_time = time.time() - fold_start\n",
    "            fold_times.append(fold_time)\n",
    "            \n",
    "            print(f\"   ✅ Best inner CV: {grid_search.best_score_:.4f}\")\n",
    "            print(f\"   📈 Overall validation score: {outer_score:.4f}\")\n",
    "            if seen_accuracy is not None:\n",
    "                print(f\"   👁️  Seen vendor accuracy: {seen_accuracy:.4f}\")\n",
    "            if unseen_accuracy is not None:\n",
    "                print(f\"   🆕 Unseen vendor accuracy: {unseen_accuracy:.4f}\")\n",
    "            print(f\"   ⏱️  Fold time: {fold_time/60:.1f} min\")\n",
    "            \n",
    "            # Store vendor analysis (same as your original)\n",
    "            vendor_analysis_per_fold.append({\n",
    "                'fold': fold + 1,\n",
    "                'train_vendors': sorted(train_vendors_fold),\n",
    "                'val_vendors': sorted(val_vendors_fold),\n",
    "                'seen_vendors': sorted(seen_vendors_fold),\n",
    "                'unseen_vendors': sorted(unseen_vendors_fold),\n",
    "                'n_seen': len(seen_vendors_fold),\n",
    "                'n_unseen': len(unseen_vendors_fold),\n",
    "                'seen_accuracy': seen_accuracy,\n",
    "                'unseen_accuracy': unseen_accuracy,\n",
    "                'overall_score': outer_score\n",
    "            })\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Analyze results\n",
    "        nested_cv_mean = np.mean(nested_scores)\n",
    "        nested_cv_std = np.std(nested_scores)\n",
    "        \n",
    "        print(f\"\\n📊 {model_name.upper()} RESULTS:\")\n",
    "        print(f\"   Nested CV: {nested_cv_mean:.4f} ± {nested_cv_std:.4f}\")\n",
    "        print(f\"   Fold scores: {[f'{s:.4f}' for s in nested_scores]}\")\n",
    "        print(f\"   Total time: {total_time/60:.1f} minutes\")\n",
    "        \n",
    "        # Get final parameters (most frequent)\n",
    "        final_params = {}\n",
    "        if isinstance(param_grid, list):\n",
    "            # For list-based param grids (like logistic regression), use the best from the best fold\n",
    "            best_fold_idx = np.argmax(nested_scores)\n",
    "            final_params = best_params_per_fold[best_fold_idx]\n",
    "        else:\n",
    "            # For dictionary-based param grids, find most frequent parameters\n",
    "            for param in param_grid.keys():\n",
    "                values = [params.get(param) for params in best_params_per_fold if param in params]\n",
    "                if values:\n",
    "                    final_params[param] = max(set(values), key=values.count)\n",
    "        \n",
    "        # Store results\n",
    "        all_results[model_name] = {\n",
    "            'nested_cv_mean': nested_cv_mean,\n",
    "            'nested_cv_std': nested_cv_std,\n",
    "            'nested_scores': nested_scores,\n",
    "            'best_params': final_params,\n",
    "            'total_time_minutes': total_time / 60,\n",
    "            'needs_scaling': needs_scaling,\n",
    "            'supports_weights': supports_weights,\n",
    "            'vendor_analysis_per_fold': vendor_analysis_per_fold  # Added vendor analysis\n",
    "        }\n",
    "    \n",
    "    # Summary comparison\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"🏆 MODEL COMPARISON SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Sort by performance\n",
    "    sorted_results = sorted(all_results.items(), \n",
    "                          key=lambda x: x[1]['nested_cv_mean'], \n",
    "                          reverse=True)\n",
    "    \n",
    "    print(f\"{'Rank':<4} {'Model':<20} {'CV Score':<12} {'Std':<8} {'Time(min)':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for rank, (model_name, results) in enumerate(sorted_results, 1):\n",
    "        score = results['nested_cv_mean']\n",
    "        std = results['nested_cv_std']\n",
    "        time_min = results['total_time_minutes']\n",
    "        \n",
    "        print(f\"{rank:<4} {model_name:<20} {score:.4f}      {std:.4f}   {time_min:>6.1f}\")\n",
    "    \n",
    "    # Best model details\n",
    "    best_model_name, best_results = sorted_results[0]\n",
    "    print(f\"\\n🥇 BEST MODEL: {best_model_name.upper()}\")\n",
    "    print(f\"   Score: {best_results['nested_cv_mean']:.4f} ± {best_results['nested_cv_std']:.4f}\")\n",
    "    print(f\"   Parameters: {best_results['best_params']}\")\n",
    "    \n",
    "    return all_results, best_model_name, best_results\n",
    "\n",
    "def train_final_multi_model(features_df, selected_features, model_results, \n",
    "                           target_col='label', random_state=42):\n",
    "    \"\"\"\n",
    "    Train final models for top performers and evaluate on test set\n",
    "    INCLUDES YOUR COMPLETE VENDOR ANALYSIS\n",
    "    \"\"\"\n",
    "    print(f\"\\n🏁 FINAL MODEL EVALUATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get data splits using YOUR function\n",
    "    train_idx, test_idx, split_info = create_vendor_aware_split(features_df)\n",
    "    \n",
    "    X_train = features_df.loc[train_idx, selected_features]\n",
    "    y_train = features_df.loc[train_idx, target_col]\n",
    "    X_test = features_df.loc[test_idx, selected_features]\n",
    "    y_test = features_df.loc[test_idx, target_col]\n",
    "    \n",
    "    # Use YOUR vendor weights function\n",
    "    sample_weights = create_vendor_weights_fixed(features_df, train_idx)\n",
    "    \n",
    "    # Get model configs\n",
    "    all_configs = ModelConfig.get_model_configs()\n",
    "    \n",
    "    # Test top 3 models\n",
    "    sorted_results = sorted(model_results.items(), \n",
    "                          key=lambda x: x[1]['nested_cv_mean'], \n",
    "                          reverse=True)\n",
    "    \n",
    "    final_results = {}\n",
    "    \n",
    "    for rank, (model_name, results) in enumerate(sorted_results[:], 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"🔧 FINAL EVALUATION: {model_name.upper()} (Rank {rank})\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        config = all_configs[model_name]\n",
    "        model_class = config['model']\n",
    "        best_params = results['best_params']\n",
    "        needs_scaling = results['needs_scaling']\n",
    "        supports_weights = results['supports_weights']\n",
    "        \n",
    "        print(f\"CV Score: {results['nested_cv_mean']:.4f} ± {results['nested_cv_std']:.4f}\")\n",
    "        print(f\"Parameters: {best_params}\")\n",
    "        print(f\"Using sample weights: {supports_weights}\")\n",
    "        \n",
    "        # Prepare data\n",
    "        if needs_scaling:\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "        else:\n",
    "            X_train_scaled = X_train\n",
    "            X_test_scaled = X_test\n",
    "        \n",
    "        # Create and train model\n",
    "        model_params = best_params.copy()\n",
    "        model_params['random_state'] = random_state\n",
    "        \n",
    "        if model_name in ['xgboost']:\n",
    "            model_params['verbosity'] = 0\n",
    "        elif model_name == 'lightgbm':\n",
    "            model_params['verbosity'] = -1\n",
    "        \n",
    "        final_model = model_class(**model_params)\n",
    "        \n",
    "        # Train with sample weights if supported\n",
    "        if supports_weights:\n",
    "            final_model.fit(X_train_scaled, y_train, sample_weight=sample_weights)\n",
    "        else:\n",
    "            final_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = final_model.predict(X_test_scaled)\n",
    "        y_pred_proba = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        test_accuracy = final_model.score(X_test_scaled, y_test)\n",
    "        test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        \n",
    "        print(f\"\\n📈 FINAL TEST SET PERFORMANCE:\")\n",
    "        print(f\"   Accuracy: {test_accuracy:.4f}\")\n",
    "        print(f\"   ROC AUC: {test_auc:.4f}\")\n",
    "        \n",
    "        print(f\"\\n📋 Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # YOUR DETAILED VENDOR ANALYSIS FOR FINAL TEST SET\n",
    "        print(f\"\\n🏭 FINAL TEST SET VENDOR ANALYSIS:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Get vendor information for test set\n",
    "        train_df = features_df.loc[train_idx]\n",
    "        test_df = features_df.loc[test_idx]\n",
    "        \n",
    "        train_positives = train_df[train_df[target_col] == 1]\n",
    "        test_positives = test_df[test_df[target_col] == 1]\n",
    "        \n",
    "        train_vendors = set(train_positives['vendor'].dropna().unique())\n",
    "        test_vendors = set(test_positives['vendor'].dropna().unique())\n",
    "        \n",
    "        # Classify test vendors as seen/unseen\n",
    "        seen_test_vendors = test_vendors.intersection(train_vendors)\n",
    "        unseen_test_vendors = test_vendors - train_vendors\n",
    "        \n",
    "        print(f\"Training vendors: {sorted(train_vendors)}\")\n",
    "        print(f\"Test vendors: {sorted(test_vendors)}\")\n",
    "        print(f\"Seen vendors in test: {sorted(seen_test_vendors)} ({len(seen_test_vendors)})\")\n",
    "        print(f\"Unseen vendors in test: {sorted(unseen_test_vendors)} ({len(unseen_test_vendors)})\")\n",
    "        \n",
    "        # Calculate vendor-specific accuracies\n",
    "        test_df_with_preds = test_df.copy()\n",
    "        test_df_with_preds['predictions'] = y_pred\n",
    "        test_positives_with_preds = test_df_with_preds[test_df_with_preds[target_col] == 1]\n",
    "        \n",
    "        seen_test_accuracy = None\n",
    "        unseen_test_accuracy = None\n",
    "        \n",
    "        if seen_test_vendors:\n",
    "            seen_test_data = test_positives_with_preds[test_positives_with_preds['vendor'].isin(seen_test_vendors)]\n",
    "            if len(seen_test_data) > 0:\n",
    "                seen_test_accuracy = (seen_test_data['predictions'] == seen_test_data[target_col]).mean()\n",
    "                print(f\"\\n👁️  SEEN VENDOR PERFORMANCE:\")\n",
    "                print(f\"   Overall seen vendor accuracy: {seen_test_accuracy:.4f}\")\n",
    "                \n",
    "                # Individual seen vendor performance\n",
    "                for vendor in sorted(seen_test_vendors):\n",
    "                    vendor_data = seen_test_data[seen_test_data['vendor'] == vendor]\n",
    "                    vendor_accuracy = (vendor_data['predictions'] == vendor_data[target_col]).mean()\n",
    "                    vendor_count = len(vendor_data)\n",
    "                    print(f\"   {vendor}: {vendor_accuracy:.4f} ({vendor_count} samples)\")\n",
    "        \n",
    "        if unseen_test_vendors:\n",
    "            unseen_test_data = test_positives_with_preds[test_positives_with_preds['vendor'].isin(unseen_test_vendors)]\n",
    "            if len(unseen_test_data) > 0:\n",
    "                unseen_test_accuracy = (unseen_test_data['predictions'] == unseen_test_data[target_col]).mean()\n",
    "                print(f\"\\n🆕 UNSEEN VENDOR PERFORMANCE:\")\n",
    "                print(f\"   Overall unseen vendor accuracy: {unseen_test_accuracy:.4f}\")\n",
    "                \n",
    "                # Individual unseen vendor performance\n",
    "                for vendor in sorted(unseen_test_vendors):\n",
    "                    vendor_data = unseen_test_data[unseen_test_data['vendor'] == vendor]\n",
    "                    vendor_accuracy = (vendor_data['predictions'] == vendor_data[target_col]).mean()\n",
    "                    vendor_count = len(vendor_data)\n",
    "                    print(f\"   {vendor}: {vendor_accuracy:.4f} ({vendor_count} samples)\")\n",
    "        \n",
    "        # Summary comparison\n",
    "        print(f\"\\n📊 VENDOR PERFORMANCE SUMMARY:\")\n",
    "        if seen_test_accuracy is not None:\n",
    "            print(f\"   Seen vendors: {seen_test_accuracy:.4f}\")\n",
    "        if unseen_test_accuracy is not None:\n",
    "            print(f\"   Unseen vendors: {unseen_test_accuracy:.4f}\")\n",
    "        if seen_test_accuracy is not None and unseen_test_accuracy is not None:\n",
    "            performance_gap = seen_test_accuracy - unseen_test_accuracy\n",
    "            print(f\"   Performance gap (seen - unseen): {performance_gap:+.4f}\")\n",
    "            \n",
    "            if performance_gap < 0.05:\n",
    "                print(f\"   ✅ Good generalization to unseen vendors!\")\n",
    "            elif performance_gap < 0.15:\n",
    "                print(f\"   ⚠️  Moderate generalization gap\")\n",
    "            else:\n",
    "                print(f\"   ❌ Large generalization gap - features may be vendor-specific\")\n",
    "        \n",
    "        final_results[model_name] = {\n",
    "            'model': final_model,\n",
    "            'scaler': scaler if needs_scaling else None,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'test_auc': test_auc,\n",
    "            'cv_score': results['nested_cv_mean'],\n",
    "            'parameters': best_params,\n",
    "            'seen_vendor_accuracy': seen_test_accuracy,\n",
    "            'unseen_vendor_accuracy': unseen_test_accuracy\n",
    "        }\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "# =================================================================\n",
    "# USAGE EXAMPLES\n",
    "# =================================================================\n",
    "\n",
    "results, best_model, best_config = multi_model_hyperparameter_tuning(\n",
    "    agnostic_features_df,\n",
    "    feature_cols,\n",
    "    models_to_test=None,  # Uses default comprehensive list\n",
    "    quick_mode=False  # Full parameter grids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏁 FINAL MODEL EVALUATION\n",
      "==================================================\n",
      "Splitting 232 positives and 1997 negatives...\n",
      "High volume vendor 'Iovation': 81 scripts -> 57 train, 24 test\n",
      "High volume vendor 'Forter': 53 scripts -> 38 train, 15 test\n",
      "High volume vendor 'Human': 27 scripts -> 19 train, 8 test\n",
      "High volume vendor 'BioCatch': 21 scripts -> 15 train, 6 test\n",
      "Medium volume vendor 'PingOne': 5 scripts -> all to train\n",
      "Medium volume vendor 'Nudata': 6 scripts -> all to train\n",
      "Medium volume vendor 'Yofi': 8 scripts -> all to train\n",
      "Medium volume vendor 'Sardine': 6 scripts -> all to test\n",
      "Medium volume vendor 'Behaviosec': 9 scripts -> all to test\n",
      "Low volume vendor 'Cheq': 4 scripts -> all to train\n",
      "Low volume vendor 'Callsign': 1 scripts -> all to train\n",
      "Low volume vendor 'Feedzai': 2 scripts -> all to train\n",
      "Low volume vendor 'Threatmark': 1 scripts -> all to train\n",
      "Low volume vendor 'GroupIB': 1 scripts -> all to train\n",
      "Low volume vendor 'Utarget': 1 scripts -> all to test\n",
      "Low volume vendor 'Accertify': 3 scripts -> all to test\n",
      "Low volume vendor 'Datadome': 1 scripts -> all to test\n",
      "Low volume vendor 'Transmit': 2 scripts -> all to test\n",
      "\n",
      "Final split:\n",
      "Train: 157 positives + 1398 negatives = 1555 total\n",
      "Test: 75 positives + 599 negatives = 674 total\n",
      "\n",
      "============================================================\n",
      "🔧 FINAL EVALUATION: RANDOM_FOREST (Rank 1)\n",
      "============================================================\n",
      "CV Score: 0.9965 ± 0.0015\n",
      "Parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}\n",
      "Using sample weights: True\n",
      "\n",
      "📈 FINAL TEST SET PERFORMANCE:\n",
      "   Accuracy: 0.9688\n",
      "   ROC AUC: 0.9744\n",
      "\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       599\n",
      "           1       0.91      0.80      0.85        75\n",
      "\n",
      "    accuracy                           0.97       674\n",
      "   macro avg       0.94      0.89      0.92       674\n",
      "weighted avg       0.97      0.97      0.97       674\n",
      "\n",
      "\n",
      "🏭 FINAL TEST SET VENDOR ANALYSIS:\n",
      "--------------------------------------------------\n",
      "Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "Test vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Datadome', 'Forter', 'Human', 'Iovation', 'Sardine', 'Transmit', 'Utarget']\n",
      "Seen vendors in test: ['BioCatch', 'Forter', 'Human', 'Iovation'] (4)\n",
      "Unseen vendors in test: ['Accertify', 'Behaviosec', 'Datadome', 'Sardine', 'Transmit', 'Utarget'] (6)\n",
      "\n",
      "👁️  SEEN VENDOR PERFORMANCE:\n",
      "   Overall seen vendor accuracy: 0.9245\n",
      "   BioCatch: 1.0000 (6 samples)\n",
      "   Forter: 1.0000 (15 samples)\n",
      "   Human: 0.7500 (8 samples)\n",
      "   Iovation: 0.9167 (24 samples)\n",
      "\n",
      "🆕 UNSEEN VENDOR PERFORMANCE:\n",
      "   Overall unseen vendor accuracy: 0.5000\n",
      "   Accertify: 0.0000 (3 samples)\n",
      "   Behaviosec: 0.8889 (9 samples)\n",
      "   Datadome: 1.0000 (1 samples)\n",
      "   Sardine: 0.0000 (6 samples)\n",
      "   Transmit: 0.5000 (2 samples)\n",
      "   Utarget: 1.0000 (1 samples)\n",
      "\n",
      "📊 VENDOR PERFORMANCE SUMMARY:\n",
      "   Seen vendors: 0.9245\n",
      "   Unseen vendors: 0.5000\n",
      "   Performance gap (seen - unseen): +0.4245\n",
      "   ❌ Large generalization gap - features may be vendor-specific\n",
      "\n",
      "============================================================\n",
      "🔧 FINAL EVALUATION: GRADIENT_BOOSTING (Rank 2)\n",
      "============================================================\n",
      "CV Score: 0.9959 ± 0.0016\n",
      "Parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.1, 'subsample': 0.8, 'max_features': 'sqrt'}\n",
      "Using sample weights: True\n",
      "\n",
      "📈 FINAL TEST SET PERFORMANCE:\n",
      "   Accuracy: 0.9733\n",
      "   ROC AUC: 0.9875\n",
      "\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       599\n",
      "           1       0.93      0.83      0.87        75\n",
      "\n",
      "    accuracy                           0.97       674\n",
      "   macro avg       0.95      0.91      0.93       674\n",
      "weighted avg       0.97      0.97      0.97       674\n",
      "\n",
      "\n",
      "🏭 FINAL TEST SET VENDOR ANALYSIS:\n",
      "--------------------------------------------------\n",
      "Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "Test vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Datadome', 'Forter', 'Human', 'Iovation', 'Sardine', 'Transmit', 'Utarget']\n",
      "Seen vendors in test: ['BioCatch', 'Forter', 'Human', 'Iovation'] (4)\n",
      "Unseen vendors in test: ['Accertify', 'Behaviosec', 'Datadome', 'Sardine', 'Transmit', 'Utarget'] (6)\n",
      "\n",
      "👁️  SEEN VENDOR PERFORMANCE:\n",
      "   Overall seen vendor accuracy: 0.9245\n",
      "   BioCatch: 1.0000 (6 samples)\n",
      "   Forter: 1.0000 (15 samples)\n",
      "   Human: 0.7500 (8 samples)\n",
      "   Iovation: 0.9167 (24 samples)\n",
      "\n",
      "🆕 UNSEEN VENDOR PERFORMANCE:\n",
      "   Overall unseen vendor accuracy: 0.5909\n",
      "   Accertify: 0.0000 (3 samples)\n",
      "   Behaviosec: 0.7778 (9 samples)\n",
      "   Datadome: 1.0000 (1 samples)\n",
      "   Sardine: 0.3333 (6 samples)\n",
      "   Transmit: 1.0000 (2 samples)\n",
      "   Utarget: 1.0000 (1 samples)\n",
      "\n",
      "📊 VENDOR PERFORMANCE SUMMARY:\n",
      "   Seen vendors: 0.9245\n",
      "   Unseen vendors: 0.5909\n",
      "   Performance gap (seen - unseen): +0.3336\n",
      "   ❌ Large generalization gap - features may be vendor-specific\n",
      "\n",
      "============================================================\n",
      "🔧 FINAL EVALUATION: LIGHTGBM (Rank 3)\n",
      "============================================================\n",
      "CV Score: 0.9949 ± 0.0014\n",
      "Parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.2, 'num_leaves': 15, 'min_child_samples': 10, 'class_weight': 'balanced', 'verbosity': -1, 'force_col_wise': True, 'n_jobs': 1, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'min_gain_to_split': 0.0}\n",
      "Using sample weights: True\n",
      "\n",
      "📈 FINAL TEST SET PERFORMANCE:\n",
      "   Accuracy: 0.9748\n",
      "   ROC AUC: 0.9779\n",
      "\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       599\n",
      "           1       0.93      0.84      0.88        75\n",
      "\n",
      "    accuracy                           0.97       674\n",
      "   macro avg       0.95      0.92      0.93       674\n",
      "weighted avg       0.97      0.97      0.97       674\n",
      "\n",
      "\n",
      "🏭 FINAL TEST SET VENDOR ANALYSIS:\n",
      "--------------------------------------------------\n",
      "Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "Test vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Datadome', 'Forter', 'Human', 'Iovation', 'Sardine', 'Transmit', 'Utarget']\n",
      "Seen vendors in test: ['BioCatch', 'Forter', 'Human', 'Iovation'] (4)\n",
      "Unseen vendors in test: ['Accertify', 'Behaviosec', 'Datadome', 'Sardine', 'Transmit', 'Utarget'] (6)\n",
      "\n",
      "👁️  SEEN VENDOR PERFORMANCE:\n",
      "   Overall seen vendor accuracy: 0.9434\n",
      "   BioCatch: 1.0000 (6 samples)\n",
      "   Forter: 1.0000 (15 samples)\n",
      "   Human: 0.8750 (8 samples)\n",
      "   Iovation: 0.9167 (24 samples)\n",
      "\n",
      "🆕 UNSEEN VENDOR PERFORMANCE:\n",
      "   Overall unseen vendor accuracy: 0.5909\n",
      "   Accertify: 0.0000 (3 samples)\n",
      "   Behaviosec: 0.8889 (9 samples)\n",
      "   Datadome: 1.0000 (1 samples)\n",
      "   Sardine: 0.5000 (6 samples)\n",
      "   Transmit: 0.0000 (2 samples)\n",
      "   Utarget: 1.0000 (1 samples)\n",
      "\n",
      "📊 VENDOR PERFORMANCE SUMMARY:\n",
      "   Seen vendors: 0.9434\n",
      "   Unseen vendors: 0.5909\n",
      "   Performance gap (seen - unseen): +0.3525\n",
      "   ❌ Large generalization gap - features may be vendor-specific\n",
      "\n",
      "============================================================\n",
      "🔧 FINAL EVALUATION: XGBOOST (Rank 4)\n",
      "============================================================\n",
      "CV Score: 0.9939 ± 0.0016\n",
      "Parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.2, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Using sample weights: True\n",
      "\n",
      "📈 FINAL TEST SET PERFORMANCE:\n",
      "   Accuracy: 0.9659\n",
      "   ROC AUC: 0.9761\n",
      "\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       599\n",
      "           1       0.91      0.77      0.83        75\n",
      "\n",
      "    accuracy                           0.97       674\n",
      "   macro avg       0.94      0.88      0.91       674\n",
      "weighted avg       0.96      0.97      0.96       674\n",
      "\n",
      "\n",
      "🏭 FINAL TEST SET VENDOR ANALYSIS:\n",
      "--------------------------------------------------\n",
      "Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "Test vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Datadome', 'Forter', 'Human', 'Iovation', 'Sardine', 'Transmit', 'Utarget']\n",
      "Seen vendors in test: ['BioCatch', 'Forter', 'Human', 'Iovation'] (4)\n",
      "Unseen vendors in test: ['Accertify', 'Behaviosec', 'Datadome', 'Sardine', 'Transmit', 'Utarget'] (6)\n",
      "\n",
      "👁️  SEEN VENDOR PERFORMANCE:\n",
      "   Overall seen vendor accuracy: 0.9057\n",
      "   BioCatch: 1.0000 (6 samples)\n",
      "   Forter: 1.0000 (15 samples)\n",
      "   Human: 0.6250 (8 samples)\n",
      "   Iovation: 0.9167 (24 samples)\n",
      "\n",
      "🆕 UNSEEN VENDOR PERFORMANCE:\n",
      "   Overall unseen vendor accuracy: 0.4545\n",
      "   Accertify: 0.0000 (3 samples)\n",
      "   Behaviosec: 0.8889 (9 samples)\n",
      "   Datadome: 1.0000 (1 samples)\n",
      "   Sardine: 0.0000 (6 samples)\n",
      "   Transmit: 0.0000 (2 samples)\n",
      "   Utarget: 1.0000 (1 samples)\n",
      "\n",
      "📊 VENDOR PERFORMANCE SUMMARY:\n",
      "   Seen vendors: 0.9057\n",
      "   Unseen vendors: 0.4545\n",
      "   Performance gap (seen - unseen): +0.4511\n",
      "   ❌ Large generalization gap - features may be vendor-specific\n",
      "\n",
      "============================================================\n",
      "🔧 FINAL EVALUATION: SVM_RBF (Rank 5)\n",
      "============================================================\n",
      "CV Score: 0.9914 ± 0.0034\n",
      "Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True}\n",
      "Using sample weights: True\n",
      "\n",
      "📈 FINAL TEST SET PERFORMANCE:\n",
      "   Accuracy: 0.9763\n",
      "   ROC AUC: 0.9881\n",
      "\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       599\n",
      "           1       0.87      0.92      0.90        75\n",
      "\n",
      "    accuracy                           0.98       674\n",
      "   macro avg       0.93      0.95      0.94       674\n",
      "weighted avg       0.98      0.98      0.98       674\n",
      "\n",
      "\n",
      "🏭 FINAL TEST SET VENDOR ANALYSIS:\n",
      "--------------------------------------------------\n",
      "Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "Test vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Datadome', 'Forter', 'Human', 'Iovation', 'Sardine', 'Transmit', 'Utarget']\n",
      "Seen vendors in test: ['BioCatch', 'Forter', 'Human', 'Iovation'] (4)\n",
      "Unseen vendors in test: ['Accertify', 'Behaviosec', 'Datadome', 'Sardine', 'Transmit', 'Utarget'] (6)\n",
      "\n",
      "👁️  SEEN VENDOR PERFORMANCE:\n",
      "   Overall seen vendor accuracy: 0.9623\n",
      "   BioCatch: 1.0000 (6 samples)\n",
      "   Forter: 1.0000 (15 samples)\n",
      "   Human: 0.7500 (8 samples)\n",
      "   Iovation: 1.0000 (24 samples)\n",
      "\n",
      "🆕 UNSEEN VENDOR PERFORMANCE:\n",
      "   Overall unseen vendor accuracy: 0.8182\n",
      "   Accertify: 0.0000 (3 samples)\n",
      "   Behaviosec: 1.0000 (9 samples)\n",
      "   Datadome: 1.0000 (1 samples)\n",
      "   Sardine: 0.8333 (6 samples)\n",
      "   Transmit: 1.0000 (2 samples)\n",
      "   Utarget: 1.0000 (1 samples)\n",
      "\n",
      "📊 VENDOR PERFORMANCE SUMMARY:\n",
      "   Seen vendors: 0.9623\n",
      "   Unseen vendors: 0.8182\n",
      "   Performance gap (seen - unseen): +0.1441\n",
      "   ⚠️  Moderate generalization gap\n",
      "\n",
      "============================================================\n",
      "🔧 FINAL EVALUATION: LOGISTIC_REGRESSION (Rank 6)\n",
      "============================================================\n",
      "CV Score: 0.9889 ± 0.0045\n",
      "Parameters: {'C': 10, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Using sample weights: True\n",
      "\n",
      "📈 FINAL TEST SET PERFORMANCE:\n",
      "   Accuracy: 0.9496\n",
      "   ROC AUC: 0.9762\n",
      "\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       599\n",
      "           1       0.72      0.89      0.80        75\n",
      "\n",
      "    accuracy                           0.95       674\n",
      "   macro avg       0.85      0.92      0.88       674\n",
      "weighted avg       0.96      0.95      0.95       674\n",
      "\n",
      "\n",
      "🏭 FINAL TEST SET VENDOR ANALYSIS:\n",
      "--------------------------------------------------\n",
      "Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "Test vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Datadome', 'Forter', 'Human', 'Iovation', 'Sardine', 'Transmit', 'Utarget']\n",
      "Seen vendors in test: ['BioCatch', 'Forter', 'Human', 'Iovation'] (4)\n",
      "Unseen vendors in test: ['Accertify', 'Behaviosec', 'Datadome', 'Sardine', 'Transmit', 'Utarget'] (6)\n",
      "\n",
      "👁️  SEEN VENDOR PERFORMANCE:\n",
      "   Overall seen vendor accuracy: 0.9811\n",
      "   BioCatch: 1.0000 (6 samples)\n",
      "   Forter: 1.0000 (15 samples)\n",
      "   Human: 0.8750 (8 samples)\n",
      "   Iovation: 1.0000 (24 samples)\n",
      "\n",
      "🆕 UNSEEN VENDOR PERFORMANCE:\n",
      "   Overall unseen vendor accuracy: 0.6818\n",
      "   Accertify: 0.0000 (3 samples)\n",
      "   Behaviosec: 1.0000 (9 samples)\n",
      "   Datadome: 1.0000 (1 samples)\n",
      "   Sardine: 0.5000 (6 samples)\n",
      "   Transmit: 0.5000 (2 samples)\n",
      "   Utarget: 1.0000 (1 samples)\n",
      "\n",
      "📊 VENDOR PERFORMANCE SUMMARY:\n",
      "   Seen vendors: 0.9811\n",
      "   Unseen vendors: 0.6818\n",
      "   Performance gap (seen - unseen): +0.2993\n",
      "   ❌ Large generalization gap - features may be vendor-specific\n",
      "\n",
      "============================================================\n",
      "🔧 FINAL EVALUATION: NAIVE_BAYES (Rank 7)\n",
      "============================================================\n",
      "CV Score: 0.9795 ± 0.0043\n",
      "Parameters: {'var_smoothing': 1e-09}\n",
      "Using sample weights: True\n",
      "\n",
      "📈 FINAL TEST SET PERFORMANCE:\n",
      "   Accuracy: 0.9347\n",
      "   ROC AUC: 0.9703\n",
      "\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       599\n",
      "           1       0.63      0.97      0.77        75\n",
      "\n",
      "    accuracy                           0.93       674\n",
      "   macro avg       0.82      0.95      0.87       674\n",
      "weighted avg       0.96      0.93      0.94       674\n",
      "\n",
      "\n",
      "🏭 FINAL TEST SET VENDOR ANALYSIS:\n",
      "--------------------------------------------------\n",
      "Training vendors: ['BioCatch', 'Callsign', 'Cheq', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Threatmark', 'Yofi']\n",
      "Test vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Datadome', 'Forter', 'Human', 'Iovation', 'Sardine', 'Transmit', 'Utarget']\n",
      "Seen vendors in test: ['BioCatch', 'Forter', 'Human', 'Iovation'] (4)\n",
      "Unseen vendors in test: ['Accertify', 'Behaviosec', 'Datadome', 'Sardine', 'Transmit', 'Utarget'] (6)\n",
      "\n",
      "👁️  SEEN VENDOR PERFORMANCE:\n",
      "   Overall seen vendor accuracy: 0.9811\n",
      "   BioCatch: 1.0000 (6 samples)\n",
      "   Forter: 1.0000 (15 samples)\n",
      "   Human: 0.8750 (8 samples)\n",
      "   Iovation: 1.0000 (24 samples)\n",
      "\n",
      "🆕 UNSEEN VENDOR PERFORMANCE:\n",
      "   Overall unseen vendor accuracy: 0.9545\n",
      "   Accertify: 1.0000 (3 samples)\n",
      "   Behaviosec: 1.0000 (9 samples)\n",
      "   Datadome: 1.0000 (1 samples)\n",
      "   Sardine: 0.8333 (6 samples)\n",
      "   Transmit: 1.0000 (2 samples)\n",
      "   Utarget: 1.0000 (1 samples)\n",
      "\n",
      "📊 VENDOR PERFORMANCE SUMMARY:\n",
      "   Seen vendors: 0.9811\n",
      "   Unseen vendors: 0.9545\n",
      "   Performance gap (seen - unseen): +0.0266\n",
      "   ✅ Good generalization to unseen vendors!\n"
     ]
    }
   ],
   "source": [
    "final_models = train_final_multi_model(agnostic_features_df, feature_cols, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏭 TRAINING PRODUCTION MODEL ON FULL DATASET\n",
      "============================================================\n",
      "📅 Training timestamp: 2025-06-01 19:45:31\n",
      "🎯 Using optimal hyperparameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': None}\n",
      "\n",
      "📋 Methodology:\n",
      "   ✅ Hyperparameters optimized on training data only (nested CV)\n",
      "   ✅ Test set provided unbiased generalization estimate\n",
      "   ✅ Production model uses same hyperparameters (no leakage)\n",
      "   ✅ Training on full dataset maximizes pattern recognition\n",
      "\n",
      "📊 Full dataset statistics:\n",
      "   Total samples: 2,229\n",
      "   Features: 12\n",
      "   Positive samples (malware): -1,521 (-68.2%)\n",
      "   Negative samples (benign): 244 (168.2%)\n",
      "\n",
      "🔧 Creating vendor-balanced sample weights...\n",
      "📊 Vendor distribution in full dataset:\n",
      "   Iovation: 81 samples (34.9%)\n",
      "   Forter: 53 samples (22.8%)\n",
      "   Human: 27 samples (11.6%)\n",
      "   BioCatch: 21 samples (9.1%)\n",
      "   Behaviosec: 9 samples (3.9%)\n",
      "   Yofi: 8 samples (3.4%)\n",
      "   Sardine: 6 samples (2.6%)\n",
      "   Nudata: 6 samples (2.6%)\n",
      "   PingOne: 5 samples (2.2%)\n",
      "   Cheq: 4 samples (1.7%)\n",
      "   Accertify: 3 samples (1.3%)\n",
      "   Feedzai: 2 samples (0.9%)\n",
      "   Transmit: 2 samples (0.9%)\n",
      "   Datadome: 1 samples (0.4%)\n",
      "   Callsign: 1 samples (0.4%)\n",
      "   Threatmark: 1 samples (0.4%)\n",
      "   GroupIB: 1 samples (0.4%)\n",
      "   Utarget: 1 samples (0.4%)\n",
      "\n",
      "⚖️  Vendor weights:\n",
      "   Iovation: 1.00x\n",
      "   Forter: 1.53x\n",
      "   Human: 3.00x\n",
      "   BioCatch: 3.86x\n",
      "   Behaviosec: 9.00x\n",
      "   Yofi: 10.12x\n",
      "   Sardine: 13.50x\n",
      "   Nudata: 13.50x\n",
      "   PingOne: 16.20x\n",
      "   Cheq: 20.25x\n",
      "   Accertify: 27.00x\n",
      "   Feedzai: 40.50x\n",
      "   Transmit: 40.50x\n",
      "   Datadome: 81.00x\n",
      "   Callsign: 81.00x\n",
      "   Threatmark: 81.00x\n",
      "   GroupIB: 81.00x\n",
      "   Utarget: 81.00x\n",
      "✅ Sample weights created - range: 1.00 to 81.00\n",
      "\n",
      "🚀 Training Random Forest with optimal parameters...\n",
      "   Trees: 50\n",
      "   Max depth: 10\n",
      "   Min samples split: 2\n",
      "   Min samples leaf: 1\n",
      "   Max features: sqrt\n",
      "   Class weight: None\n",
      "   Using sample weights: ✅\n",
      "   Random state: 42 (reproducible)\n",
      "\n",
      "⏳ Training in progress...\n",
      "✅ Training completed!\n",
      "\n",
      "📈 PRODUCTION MODEL ANALYSIS:\n",
      "   Model type: Random Forest Classifier\n",
      "   Trees in forest: 50\n",
      "   Actual max depth: 10\n",
      "   Features used: 12\n",
      "\n",
      "🔝 TOP 15 MOST IMPORTANT FEATURES:\n",
      "   fp_approach_diversity                   : 0.2172\n",
      "   uses_canvas_fp                          : 0.2106\n",
      "   collection_intensity                    : 0.1621\n",
      "   complexity_tier                         : 0.1316\n",
      "   interaction_diversity                   : 0.0795\n",
      "   uses_screen_fp                          : 0.0458\n",
      "   tracks_device_motion                    : 0.0395\n",
      "   tracks_coordinates                      : 0.0344\n",
      "   sophistication_score                    : 0.0252\n",
      "   tracks_mouse                            : 0.0205\n",
      "   tracks_timing                           : 0.0174\n",
      "   uses_audio_fp                           : 0.0164\n",
      "\n",
      "📊 TRAINING SET PERFORMANCE (verification only - NOT generalization):\n",
      "   Accuracy: 0.8928\n",
      "   Confusion Matrix:\n",
      "      True Neg: 1,731  |  False Pos: 2\n",
      "      False Neg: 214  |  True Pos: 29\n",
      "\n",
      "🏭 VENDOR COVERAGE ANALYSIS:\n",
      "   Total vendors in production model: 18\n",
      "   Vendors: ['Accertify', 'Behaviosec', 'BioCatch', 'Callsign', 'Cheq', 'Datadome', 'Feedzai', 'Forter', 'GroupIB', 'Human', 'Iovation', 'Nudata', 'PingOne', 'Sardine', 'Threatmark', 'Transmit', 'Utarget', 'Yofi']\n",
      "\n",
      "   Vendor-specific training performance:\n",
      "     Accertify      : 1.0000 (3 samples)\n",
      "     Behaviosec     : 1.0000 (9 samples)\n",
      "     BioCatch       : 1.0000 (21 samples)\n",
      "     Callsign       : 1.0000 (1 samples)\n",
      "     Cheq           : 1.0000 (4 samples)\n",
      "     Datadome       : 1.0000 (1 samples)\n",
      "     Feedzai        : 1.0000 (2 samples)\n",
      "     Forter         : 1.0000 (53 samples)\n",
      "     GroupIB        : 1.0000 (1 samples)\n",
      "     Human          : 0.9630 (27 samples)\n",
      "     Iovation       : 0.9877 (81 samples)\n",
      "     Nudata         : 1.0000 (6 samples)\n",
      "     PingOne        : 1.0000 (5 samples)\n",
      "     Sardine        : 1.0000 (6 samples)\n",
      "     Threatmark     : 1.0000 (1 samples)\n",
      "     Transmit       : 1.0000 (2 samples)\n",
      "     Utarget        : 1.0000 (1 samples)\n",
      "     Yofi           : 1.0000 (8 samples)\n",
      "\n",
      "💾 CREATING PRODUCTION MODEL PACKAGE:\n",
      "   ✅ Full package saved to: malware_classifier_production_20250601_194532.pkl\n",
      "   ✅ Joblib format saved to: malware_classifier_production_20250601_194532.joblib\n",
      "   ✅ Model only saved to: malware_classifier_model_only_20250601_194532.pkl\n",
      "   📝 Feature list saved to: malware_classifier_features_20250601_194532.txt\n",
      "\n",
      "🎉 PRODUCTION MODEL TRAINING COMPLETE!\n",
      "\n",
      "📦 FILES CREATED:\n",
      "   🔹 malware_classifier_production_20250601_194532.pkl - Full production package (RECOMMENDED)\n",
      "   🔹 malware_classifier_production_20250601_194532.joblib - Alternative format\n",
      "   🔹 malware_classifier_model_only_20250601_194532.pkl - Model only (lightweight)\n",
      "   🔹 malware_classifier_features_20250601_194532.txt - Feature reference\n",
      "\n",
      "🚀 USAGE:\n",
      "   # Load the full package\n",
      "   import pickle\n",
      "   with open('malware_classifier_production_20250601_194532.pkl', 'rb') as f:\n",
      "       package = pickle.load(f)\n",
      "   model = package['model']\n",
      "   features = package['feature_columns']\n",
      "\n",
      "   # Or load just the model\n",
      "   import joblib\n",
      "   model = joblib.load('malware_classifier_model_only_20250601_194532.pkl')\n",
      "\n",
      "✅ Your production model is ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "# Train Production Model with Optimal Hyperparameters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "def create_vendor_weights_full_dataset(features_df, target_col='label'):\n",
    "    \"\"\"\n",
    "    Create sample weights for the full dataset to balance vendors\n",
    "    \"\"\"\n",
    "    # Get positive samples (malware)\n",
    "    positive_samples = features_df[features_df[target_col] == 1].copy()\n",
    "    \n",
    "    if 'vendor' not in positive_samples.columns:\n",
    "        print(\"⚠️  No vendor column found, using uniform weights\")\n",
    "        return np.ones(len(features_df))\n",
    "    \n",
    "    # Calculate vendor frequencies\n",
    "    vendor_counts = positive_samples['vendor'].value_counts()\n",
    "    total_positive = len(positive_samples)\n",
    "    \n",
    "    print(f\"📊 Vendor distribution in full dataset:\")\n",
    "    for vendor, count in vendor_counts.items():\n",
    "        percentage = (count / total_positive) * 100\n",
    "        print(f\"   {vendor}: {count} samples ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Create weights to balance vendors\n",
    "    max_count = vendor_counts.max()\n",
    "    vendor_weights = {vendor: max_count / count for vendor, count in vendor_counts.items()}\n",
    "    \n",
    "    print(f\"\\n⚖️  Vendor weights:\")\n",
    "    for vendor, weight in vendor_weights.items():\n",
    "        print(f\"   {vendor}: {weight:.2f}x\")\n",
    "    \n",
    "    # Apply weights\n",
    "    sample_weights = np.ones(len(features_df))\n",
    "    \n",
    "    for idx, row in features_df.iterrows():\n",
    "        if row[target_col] == 1 and 'vendor' in row and pd.notna(row['vendor']):\n",
    "            vendor = row['vendor']\n",
    "            if vendor in vendor_weights:\n",
    "                sample_weights[idx] = vendor_weights[vendor]\n",
    "    \n",
    "    print(f\"✅ Sample weights created - range: {sample_weights.min():.2f} to {sample_weights.max():.2f}\")\n",
    "    return sample_weights\n",
    "\n",
    "# Your optimal hyperparameters from nested CV\n",
    "optimal_hyperparameters = {\n",
    "    'n_estimators': 50,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'sqrt',\n",
    "    'class_weight': None\n",
    "}\n",
    "\n",
    "print(\"🏭 TRAINING PRODUCTION MODEL ON FULL DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"📅 Training timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"🎯 Using optimal hyperparameters: {optimal_hyperparameters}\")\n",
    "print()\n",
    "print(\"📋 Methodology:\")\n",
    "print(\"   ✅ Hyperparameters optimized on training data only (nested CV)\")\n",
    "print(\"   ✅ Test set provided unbiased generalization estimate\")\n",
    "print(\"   ✅ Production model uses same hyperparameters (no leakage)\")\n",
    "print(\"   ✅ Training on full dataset maximizes pattern recognition\")\n",
    "print()\n",
    "\n",
    "# Prepare full dataset\n",
    "X_full = agnostic_features_df[feature_cols].copy()\n",
    "y_full = agnostic_features_df['label'].copy()\n",
    "\n",
    "print(f\"📊 Full dataset statistics:\")\n",
    "print(f\"   Total samples: {len(X_full):,}\")\n",
    "print(f\"   Features: {len(feature_cols)}\")\n",
    "print(f\"   Positive samples (malware): {y_full.sum():,} ({y_full.mean()*100:.1f}%)\")\n",
    "print(f\"   Negative samples (benign): {(~y_full.astype(bool)).sum():,} ({(1-y_full.mean())*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Create sample weights for vendor balancing\n",
    "print(\"🔧 Creating vendor-balanced sample weights...\")\n",
    "sample_weights = create_vendor_weights_full_dataset(agnostic_features_df, 'label')\n",
    "print()\n",
    "\n",
    "# Initialize production model with optimal hyperparameters\n",
    "production_model = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    class_weight=None,\n",
    "    random_state=42,  # Ensure reproducibility\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "print(f\"🚀 Training Random Forest with optimal parameters...\")\n",
    "print(f\"   Trees: {production_model.n_estimators}\")\n",
    "print(f\"   Max depth: {production_model.max_depth}\")\n",
    "print(f\"   Min samples split: {production_model.min_samples_split}\")\n",
    "print(f\"   Min samples leaf: {production_model.min_samples_leaf}\")\n",
    "print(f\"   Max features: {production_model.max_features}\")\n",
    "print(f\"   Class weight: {production_model.class_weight}\")\n",
    "print(f\"   Using sample weights: ✅\")\n",
    "print(f\"   Random state: 42 (reproducible)\")\n",
    "print()\n",
    "\n",
    "# Train the model\n",
    "print(\"⏳ Training in progress...\")\n",
    "production_model.fit(X_full, y_full, sample_weight=sample_weights)\n",
    "print(\"✅ Training completed!\")\n",
    "print()\n",
    "\n",
    "# Model analysis\n",
    "print(f\"📈 PRODUCTION MODEL ANALYSIS:\")\n",
    "print(f\"   Model type: Random Forest Classifier\")\n",
    "print(f\"   Trees in forest: {production_model.n_estimators}\")\n",
    "print(f\"   Actual max depth: {production_model.max_depth}\")\n",
    "print(f\"   Features used: {len(feature_cols)}\")\n",
    "print()\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': production_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"🔝 TOP 15 MOST IMPORTANT FEATURES:\")\n",
    "for idx, row in feature_importance.head(15).iterrows():\n",
    "    print(f\"   {row['feature']:<40}: {row['importance']:.4f}\")\n",
    "print()\n",
    "\n",
    "# Training set performance (for verification only)\n",
    "y_pred_train = production_model.predict(X_full)\n",
    "y_pred_proba_train = production_model.predict_proba(X_full)[:, 1]\n",
    "train_accuracy = production_model.score(X_full, y_full)\n",
    "\n",
    "print(f\"📊 TRAINING SET PERFORMANCE (verification only - NOT generalization):\")\n",
    "print(f\"   Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"   Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_full, y_pred_train)\n",
    "print(f\"      True Neg: {cm[0,0]:,}  |  False Pos: {cm[0,1]:,}\")\n",
    "print(f\"      False Neg: {cm[1,0]:,}  |  True Pos: {cm[1,1]:,}\")\n",
    "print()\n",
    "\n",
    "# Vendor-specific analysis\n",
    "print(f\"🏭 VENDOR COVERAGE ANALYSIS:\")\n",
    "positive_samples = agnostic_features_df[agnostic_features_df['label'] == 1]\n",
    "if 'vendor' in positive_samples.columns:\n",
    "    vendors = positive_samples['vendor'].dropna().unique()\n",
    "    print(f\"   Total vendors in production model: {len(vendors)}\")\n",
    "    print(f\"   Vendors: {sorted(vendors)}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"   Vendor-specific training performance:\")\n",
    "    for vendor in sorted(vendors):\n",
    "        vendor_data = positive_samples[positive_samples['vendor'] == vendor]\n",
    "        vendor_X = vendor_data[feature_cols]\n",
    "        vendor_y_true = vendor_data['label']\n",
    "        vendor_y_pred = production_model.predict(vendor_X)\n",
    "        vendor_acc = (vendor_y_pred == vendor_y_true).mean()\n",
    "        print(f\"     {vendor:<15}: {vendor_acc:.4f} ({len(vendor_data):,} samples)\")\n",
    "print()\n",
    "\n",
    "# Create comprehensive model package\n",
    "print(f\"💾 CREATING PRODUCTION MODEL PACKAGE:\")\n",
    "\n",
    "# Model metadata\n",
    "model_metadata = {\n",
    "    'model_type': 'RandomForestClassifier',\n",
    "    'hyperparameters': optimal_hyperparameters,\n",
    "    'feature_columns': feature_cols,\n",
    "    'n_features': len(feature_cols),\n",
    "    'training_timestamp': datetime.now().isoformat(),\n",
    "    'total_training_samples': len(X_full),\n",
    "    'positive_samples': int(y_full.sum()),\n",
    "    'negative_samples': int((~y_full.astype(bool)).sum()),\n",
    "    'vendor_weighted': True,\n",
    "    'random_state': 42,\n",
    "    'training_accuracy': float(train_accuracy),\n",
    "    'methodology': 'Hyperparameters from nested CV on training data, model trained on full dataset',\n",
    "    'purpose': 'Production malware classification',\n",
    "    'vendors_included': sorted(vendors) if 'vendor' in positive_samples.columns else None\n",
    "}\n",
    "\n",
    "# Complete model package\n",
    "production_package = {\n",
    "    'model': production_model,\n",
    "    'metadata': model_metadata,\n",
    "    'feature_importance': feature_importance.to_dict('records'),\n",
    "    'feature_columns': feature_cols,\n",
    "    'sample_weights_used': True,\n",
    "    'hyperparameters': optimal_hyperparameters\n",
    "}\n",
    "\n",
    "# Save with multiple formats for flexibility\n",
    "save_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Main pickle file (recommended for production)\n",
    "pickle_path = f'malware_classifier_production_{save_timestamp}.pkl'\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(production_package, f)\n",
    "\n",
    "# Alternative joblib format (also good)\n",
    "joblib_path = f'malware_classifier_production_{save_timestamp}.joblib'\n",
    "joblib.dump(production_package, joblib_path)\n",
    "\n",
    "# Just the model (lightweight option)\n",
    "model_only_path = f'malware_classifier_model_only_{save_timestamp}.pkl'\n",
    "joblib.dump(production_model, model_only_path)\n",
    "\n",
    "print(f\"   ✅ Full package saved to: {pickle_path}\")\n",
    "print(f\"   ✅ Joblib format saved to: {joblib_path}\")\n",
    "print(f\"   ✅ Model only saved to: {model_only_path}\")\n",
    "\n",
    "# Save feature list for reference\n",
    "feature_list_path = f'malware_classifier_features_{save_timestamp}.txt'\n",
    "with open(feature_list_path, 'w') as f:\n",
    "    f.write(\"# Malware Classifier Production Model - Feature List\\n\")\n",
    "    f.write(f\"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"# Model: Random Forest with {optimal_hyperparameters}\\n\")\n",
    "    f.write(f\"# Total features: {len(feature_cols)}\\n\")\n",
    "    f.write(f\"# Training samples: {len(X_full):,}\\n\\n\")\n",
    "    \n",
    "    f.write(\"FEATURES (in order):\\n\")\n",
    "    for i, feature in enumerate(feature_cols, 1):\n",
    "        importance = feature_importance[feature_importance['feature'] == feature]['importance'].iloc[0]\n",
    "        f.write(f\"{i:3d}. {feature:<40} (importance: {importance:.4f})\\n\")\n",
    "\n",
    "print(f\"   📝 Feature list saved to: {feature_list_path}\")\n",
    "print()\n",
    "\n",
    "print(\"🎉 PRODUCTION MODEL TRAINING COMPLETE!\")\n",
    "print()\n",
    "print(\"📦 FILES CREATED:\")\n",
    "print(f\"   🔹 {pickle_path} - Full production package (RECOMMENDED)\")\n",
    "print(f\"   🔹 {joblib_path} - Alternative format\")\n",
    "print(f\"   🔹 {model_only_path} - Model only (lightweight)\")\n",
    "print(f\"   🔹 {feature_list_path} - Feature reference\")\n",
    "print()\n",
    "print(\"🚀 USAGE:\")\n",
    "print(\"   # Load the full package\")\n",
    "print(f\"   import pickle\")\n",
    "print(f\"   with open('{pickle_path}', 'rb') as f:\")\n",
    "print(f\"       package = pickle.load(f)\")\n",
    "print(f\"   model = package['model']\")\n",
    "print(f\"   features = package['feature_columns']\")\n",
    "print()\n",
    "print(\"   # Or load just the model\")\n",
    "print(f\"   import joblib\")\n",
    "print(f\"   model = joblib.load('{model_only_path}')\")\n",
    "print()\n",
    "print(\"✅ Your production model is ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vv8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
